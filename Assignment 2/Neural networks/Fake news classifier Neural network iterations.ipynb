{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(fbfkjb)\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk \n",
    "import re\n",
    "from pandas_profiling import ProfileReport\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns \n",
    "import sklearn.metrics\n",
    "import sklearn\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "from sklearn.metrics import classification_report\n",
    "from nltk.corpus import stopwords\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from spellchecker import SpellChecker\n",
    "#import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "#nltk.download(\"stopwords\")\n",
    "\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "#############################\n",
    "### Get Data ##\n",
    "\n",
    "# train= pd.read_csv('train.csv')\n",
    "# test=pd.read_csv('test.csv')\n",
    "# # concat all\n",
    "# df=pd.concat([train,test])\n",
    "\n",
    "\n",
    "# spell = SpellChecker()\n",
    "# def correct_spellings(x, spell=spell):\n",
    "#     \"\"\"correct the missplled words of a given tweet\"\"\"\n",
    "#     x = x.split()\n",
    "#     misspelled = spell.unknown(x)\n",
    "#     result = map(lambda word : spell.correction(word) if word in  misspelled else word, x)\n",
    "#     return \" \".join(result)\n",
    "\n",
    "def tweets_cleaning(x, correct_spelling=False, remove_emojis=True, remove_stop_words=True):\n",
    "    \"\"\"Apply function to a clean a tweet\"\"\"\n",
    "    x = x.lower().strip()\n",
    "    # romove urls\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    x = url.sub(r'',x)\n",
    "    # remove html tags\n",
    "    html = re.compile(r'<.*?>')\n",
    "    x = html.sub(r'',x)\n",
    "    # remove punctuation\n",
    "    operator = str.maketrans('','',string.punctuation) #????\n",
    "    x = x.translate(operator)\n",
    "    if correct_spelling:\n",
    "        x = correct_spellings(x)\n",
    "    if remove_emojis:\n",
    "        x = x.encode('ascii', 'ignore').decode('utf8').strip()\n",
    "    if remove_stop_words:\n",
    "        x = ' '.join([word for word in x.split(' ') if word not in stop_words])\n",
    "    return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# x_train=pd.read_csv(\"TEXT_X_train.csv\")\n",
    "# x_test=pd.read_csv(\"TEXT_X_test.csv\")\n",
    "\n",
    "\n",
    "y_train=pd.read_csv(\"TEXTlabel_train.csv\")\n",
    "y_test =pd.read_csv(\"TEXTlabel_test .csv\") \n",
    "\n",
    "# x_train.shape\n",
    "\n",
    "# # X_test=X_test.drop('Unnamed: 0',axis=1)\n",
    "# y_train=pd.read_csv(\"TEXTlabel_train.csv\")\n",
    "# y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_test=x_test.drop('Unnamed: 0',axis=1)\n",
    "# x_train=x_train.drop('Unnamed: 0',axis=1)\n",
    "y_test=y_test.drop('Unnamed: 0',axis=1)\n",
    "y_train=y_train.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_cv=pd.read_csv(\"TEXT_X_V.csv\")\n",
    "y_cv=pd.read_csv(\"TEXTlabel_V.csv\")\n",
    "x_cv=x_cv.drop('Unnamed: 0',axis=1)\n",
    "y_cv=y_cv.drop('Unnamed: 0',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "import gensim\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score,roc_curve, auc\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(  hidden_layers,learning_rate):\n",
    "  # Initialize the constructor\n",
    "    model =  keras.Sequential()\n",
    "      # Add an input layer\n",
    "    activation='sigmoid'\n",
    "    model.add(layers.Dense(256, activation=activation, input_shape=(512,)))\n",
    "    for i in range(hidden_layers):\n",
    "          # Add one hidden layer\n",
    "        model.add(layers.Dense(8, activation=activation))\n",
    "\n",
    "      # Add an output layer \n",
    "    model.add(layers.Dense(1, activation=activation))\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "      #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=\n",
    "      ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# joblib.dump(DTmodel, 'DTgrid_NLP.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"news_articles.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6176610978520286"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1294/2095"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Fake    1294\n",
       "Real     801\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from tempfile import TemporaryFile\n",
    "\n",
    "# outfile = TemporaryFile()\n",
    "xtrain_tfidf_ngram=np.load(\"xtrain_tfidf_ngram.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# _ = outfile.seek(0) # Only needed here to simulate closing & reopening file\n",
    "\n",
    "# np.load(outfile)\n",
    "xvalid_tfidf_ngram=np.load(\"xvalid_tfidf_ngram.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector_X = xtrain_tfidf_ngram  #//shape - (3,6)\n",
    "tfidf_vector_valid= xvalid_tfidf_ngram\n",
    "# None] #//shape - (3,6,1) \n",
    "# tfidf_vector_valid = tfidf_vector_valid[:, :, None] #//shape - (3,6,1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vector_X.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_shape= [x_train.shape[1]]\n",
    "\n",
    "# NNmodel = create_model(optimizer='adam', activation = 'sigmoid', hidden_layers=1,learning_rate=0.01)\n",
    "\n",
    "# # Create model\n",
    "# model = keras.Sequential([\n",
    "#     layers.Dense(256, activation='relu', input_shape=tfidf_vector_X.shape[1:]),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.5),\n",
    "    \n",
    "#     layers.Dense(256, activation='relu'),    \n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.5),\n",
    "    \n",
    "#     layers.Dense(1, activation='sigmoid'),\n",
    "# ])\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01)\n",
    "\n",
    "# model.compile(\n",
    "#     optimizer=opt,\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=['binary_accuracy'],\n",
    "    \n",
    "# )\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "model =  KerasClassifier(build_fn=create_model, verbose = False)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid={'learning_rate':[0.1,0.001,0.01,0.05,0.05,0.5],'hidden_layers':[2,4,6,8,10]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridNN = GridSearchCV(estimator = model, param_grid = param_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': False,\n",
       " 'build_fn': <function __main__.create_model(hidden_layers, learning_rate)>}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = gridNN.fit(\n",
    "     xtrain_tfidf_ngram, y_train,\n",
    "    validation_data=(xvalid_tfidf_ngram,y_cv),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "#     callbacks=[early_stopping],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': 4, 'learning_rate': 0.01}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6340700149536133\n"
     ]
    }
   ],
   "source": [
    "print(history.best_score_)\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'history'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-be7117cf5533>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Cross-entropy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val_accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'history'"
     ]
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "predictions = gridNN.predict(xvalid_tfidf_ngram)\n",
    "\n",
    "# Plotting\n",
    "cm = metrics.confusion_matrix(y_cv, predictions)\n",
    "# plt.figure(figsize=(9,9))\n",
    "# sns.heatmap(cm, annot=True, fmt=\"d\", linewidths=.5, square = True, cmap = 'Blues_r');\n",
    "# plt.ylabel('Actual label');\n",
    "# plt.xlabel('Predicted label');\n",
    "# all_sample_title = 'Accuracy Score: {0}%'.format(round(history_df['accuracy'].iloc[-1]*100,1))\n",
    "# plt.title(all_sample_title, size = 15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy_Score: 62.184189079054605 %\n",
      "Training Recall: 0.0 %\n",
      "Training precision_score: 0.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 0.0 %\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, gridNN.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, gridNN.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, gridNN.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, gridNN.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TP:  0\n",
      "TN:  265\n",
      "FP:  0\n",
      "FN:  144\n",
      "Accuracy_Score Test: 64.30317848410758 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# print('Confusion matrix: \\n', cm)\n",
    "print('TP: ', cm[1,1])\n",
    "print('TN: ', cm[0,0])\n",
    "print('FP: ', cm[0,1])\n",
    "print('FN: ', cm[1,0])\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_test, model))\n",
    "print('Accuracy_Score Test:',metrics.accuracy_score(y_test, gridNN.predict(xvalid_tfidf_ngram))*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision_score: 0.0 %\n",
      "recall_score: 0.0 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "print('precision_score:',metrics.precision_score(y_cv, gridNN.predict(xvalid_tfidf_ngram))*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv, gridNN.predict(xvalid_tfidf_ngram))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_modelWithDropBatch(  hidden_layers,learning_rate):\n",
    "  # Initialize the constructor\n",
    "    model =  keras.Sequential()\n",
    "      # Add an input layer\n",
    "    activation='sigmoid'\n",
    "    model.add(layers.Dense(256, activation=activation, input_shape=(512,)))\n",
    "    for i in range(hidden_layers):\n",
    "          # Add one hidden layer\n",
    "        model.add(layers.BatchNormalization())\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(8, activation='relu'))\n",
    "\n",
    "      # Add an output layer \n",
    "    model.add(layers.Dense(1, activation=activation))\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "      #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=\n",
    "      ['accuracy'])\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(  hidden_layers,learning_rate):\n",
    "  # Initialize the constructor\n",
    "    model =  keras.Sequential()\n",
    "      # Add an input layer\n",
    "    activation='sigmoid'\n",
    "    model.add(layers.Dense(256, activation=activation, input_shape=(512,)))\n",
    "    for i in range(hidden_layers):\n",
    "          # Add one hidden layer\n",
    "        model.add(layers.Dense(8, activation=activation))\n",
    "\n",
    "      # Add an output layer \n",
    "    model.add(layers.Dense(1, activation=activation))\n",
    "    opt = keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "      #compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=\n",
    "      ['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': False,\n",
       " 'build_fn': <function __main__.create_modelWithDropBatch(hidden_layers, learning_rate)>}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime of the program is 2006.8955833911896\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': 4, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6585266351699829\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "model_Batch_drop_relu =  KerasClassifier(build_fn=create_modelWithDropBatch, verbose = False)  \n",
    "\n",
    "param_grid={'learning_rate':[0.1,0.001,0.01,0.05,0.05,0.5],'hidden_layers':[2,4,6,8,10]}\n",
    "\n",
    "gridNN_Batch_drop_relu = GridSearchCV(estimator = model_Batch_drop_relu, param_grid = param_grid)\n",
    "\n",
    "model_Batch_drop_relu.get_params()\n",
    "# starting time\n",
    "start = time.time()\n",
    "# df_run_stats_ga, df_run_curves_ga = ga.run()\n",
    "# sleeping for 1 sec to get 10 sec runtime\n",
    "\n",
    "history_Batch_drop_relu = gridNN_Batch_drop_relu.fit(\n",
    "     xtrain_tfidf_ngram, y_train,\n",
    "    validation_data=(xvalid_tfidf_ngram,y_cv),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "#     callbacks=[early_stopping],\n",
    ")\n",
    "time.sleep(1)\n",
    "\n",
    "# program body ends\n",
    "\n",
    "# end time\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "history_Batch_drop_relu.best_params_\n",
    "\n",
    "print(history_Batch_drop_relu.best_score_)\n",
    "# print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_SVM1 = gridNN_Batch_drop_relu.predict(xvalid_tfidf_ngram)\n",
    "y_pred_SVM1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x432 with 0 Axes>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Confusion_matrix')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 33.0, 'Predicted Class')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "Text(51.0, 0.5, 'Actual class')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion matrix: \n",
      " [[209  56]\n",
      " [ 75  69]]\n",
      "TP:  69\n",
      "TN:  209\n",
      "FP:  56\n",
      "FN:  75\n",
      "TP:  69\n",
      "TN:  209\n",
      "FP:  56\n",
      "FN:  75\n",
      "Accuracy_Score: 67.97066014669927 %\n",
      "precision_score: 55.2 %\n",
      "recall_score: 47.91666666666667 %\n"
     ]
    }
   ],
   "source": [
    "y_pred_SVM = gridNN_Batch_drop_relu.predict(xvalid_tfidf_ngram)\n",
    "\n",
    "conf_mat_svm = metrics.confusion_matrix(y_cv['label'], y_pred_SVM)\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(conf_mat_svm,annot=True)\n",
    "plt.title(\"Confusion_matrix\")\n",
    "plt.xlabel(\"Predicted Class\")\n",
    "plt.ylabel(\"Actual class\")\n",
    "plt.show()\n",
    "print('Confusion matrix: \\n', conf_mat_svm)\n",
    "print('TP: ', conf_mat_svm[1,1])\n",
    "print('TN: ', conf_mat_svm[0,0])\n",
    "print('FP: ', conf_mat_svm[0,1])\n",
    "print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "\n",
    "# print('Confusion matrix: \\n', cm)\n",
    "print('TP: ', conf_mat_svm[1,1])\n",
    "print('TN: ', conf_mat_svm[0,0])\n",
    "print('FP: ', conf_mat_svm[0,1])\n",
    "print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_test, model))\n",
    "print('Accuracy_Score:',metrics.accuracy_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "\n",
    "print('precision_score:',metrics.precision_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv['label'], y_pred_SVM)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy_Score: 82.72208638956805 %\n",
      "Training Recall: 81.03448275862068 %\n",
      "Training precision_score: 75.2 %\n",
      "Training F1 Score: 78.00829875518671 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 104ms/step - loss: 0.9062 - accuracy: 0.4780 - val_loss: 0.6448 - val_accuracy: 0.6479\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6752 - accuracy: 0.6098 - val_loss: 0.6244 - val_accuracy: 0.6479\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6755 - accuracy: 0.6229 - val_loss: 0.6286 - val_accuracy: 0.6479\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6341 - accuracy: 0.6231 - val_loss: 0.6345 - val_accuracy: 0.6479\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6321 - accuracy: 0.6237 - val_loss: 0.6351 - val_accuracy: 0.6479\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6244 - accuracy: 0.6215 - val_loss: 0.6419 - val_accuracy: 0.6479\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6187 - accuracy: 0.6328 - val_loss: 0.6466 - val_accuracy: 0.6479\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5991 - accuracy: 0.6244 - val_loss: 0.6520 - val_accuracy: 0.6479\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5847 - accuracy: 0.6316 - val_loss: 0.6579 - val_accuracy: 0.6528\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.5796 - accuracy: 0.6413 - val_loss: 0.6670 - val_accuracy: 0.6724\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5767 - accuracy: 0.6470 - val_loss: 0.6849 - val_accuracy: 0.4621\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5761 - accuracy: 0.6703 - val_loss: 0.7140 - val_accuracy: 0.4083\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5546 - accuracy: 0.6786 - val_loss: 0.7359 - val_accuracy: 0.4181\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5618 - accuracy: 0.6701 - val_loss: 0.7657 - val_accuracy: 0.4034\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5445 - accuracy: 0.6785 - val_loss: 0.7651 - val_accuracy: 0.4059\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5243 - accuracy: 0.6971 - val_loss: 0.7385 - val_accuracy: 0.4205\n",
      "Epoch 17/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5364 - accuracy: 0.7017 - val_loss: 0.7037 - val_accuracy: 0.4548\n",
      "Epoch 18/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4956 - accuracy: 0.7251 - val_loss: 0.6528 - val_accuracy: 0.5428\n",
      "Epoch 19/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5155 - accuracy: 0.7155 - val_loss: 0.6008 - val_accuracy: 0.6381\n",
      "Epoch 20/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4985 - accuracy: 0.7154 - val_loss: 0.5771 - val_accuracy: 0.6993\n",
      "Epoch 21/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4943 - accuracy: 0.7090 - val_loss: 0.6014 - val_accuracy: 0.6430\n",
      "Epoch 22/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4773 - accuracy: 0.7258 - val_loss: 0.6315 - val_accuracy: 0.5721\n",
      "Epoch 23/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4705 - accuracy: 0.7364 - val_loss: 0.5984 - val_accuracy: 0.6406\n",
      "Epoch 24/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4744 - accuracy: 0.7420 - val_loss: 0.5881 - val_accuracy: 0.7017\n",
      "Epoch 25/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4696 - accuracy: 0.7527 - val_loss: 0.5871 - val_accuracy: 0.7164\n",
      "Epoch 26/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4539 - accuracy: 0.7668 - val_loss: 0.5837 - val_accuracy: 0.7017\n",
      "Epoch 27/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4581 - accuracy: 0.7630 - val_loss: 0.5859 - val_accuracy: 0.7017\n",
      "Epoch 28/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4287 - accuracy: 0.7730 - val_loss: 0.5935 - val_accuracy: 0.6797\n",
      "Epoch 29/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4276 - accuracy: 0.7753 - val_loss: 0.5852 - val_accuracy: 0.7017\n",
      "Epoch 30/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4377 - accuracy: 0.7687 - val_loss: 0.5931 - val_accuracy: 0.7066\n",
      "Epoch 31/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4265 - accuracy: 0.7757 - val_loss: 0.6162 - val_accuracy: 0.6430\n",
      "Epoch 32/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4293 - accuracy: 0.7660 - val_loss: 0.5782 - val_accuracy: 0.6993\n",
      "Epoch 33/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4276 - accuracy: 0.7711 - val_loss: 0.6119 - val_accuracy: 0.6748\n",
      "Epoch 34/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4211 - accuracy: 0.7823 - val_loss: 0.6643 - val_accuracy: 0.6650\n",
      "Epoch 35/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4224 - accuracy: 0.7773 - val_loss: 0.6508 - val_accuracy: 0.6699\n",
      "Epoch 36/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3884 - accuracy: 0.7917 - val_loss: 0.6332 - val_accuracy: 0.6944\n",
      "Epoch 37/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3623 - accuracy: 0.8077 - val_loss: 0.6476 - val_accuracy: 0.6968\n",
      "Epoch 38/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3795 - accuracy: 0.7863 - val_loss: 0.6838 - val_accuracy: 0.6822\n",
      "Epoch 39/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3735 - accuracy: 0.7983 - val_loss: 0.7087 - val_accuracy: 0.6773\n",
      "Epoch 40/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3600 - accuracy: 0.8063 - val_loss: 0.7502 - val_accuracy: 0.6724\n",
      "Epoch 41/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3768 - accuracy: 0.7954 - val_loss: 0.7198 - val_accuracy: 0.6724\n",
      "Epoch 42/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3714 - accuracy: 0.7996 - val_loss: 0.7757 - val_accuracy: 0.6699\n",
      "Epoch 43/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3766 - accuracy: 0.7932 - val_loss: 0.8208 - val_accuracy: 0.6675\n",
      "Epoch 44/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3673 - accuracy: 0.7981 - val_loss: 0.7178 - val_accuracy: 0.6773\n",
      "Epoch 45/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3653 - accuracy: 0.7973 - val_loss: 0.7265 - val_accuracy: 0.6944\n",
      "Epoch 46/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3822 - accuracy: 0.7921 - val_loss: 0.7348 - val_accuracy: 0.6944\n",
      "Epoch 47/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3567 - accuracy: 0.8109 - val_loss: 0.7074 - val_accuracy: 0.6846\n",
      "Epoch 48/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3572 - accuracy: 0.8076 - val_loss: 0.7761 - val_accuracy: 0.6773\n",
      "Epoch 49/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3496 - accuracy: 0.8191 - val_loss: 0.8030 - val_accuracy: 0.6699\n",
      "Epoch 50/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3289 - accuracy: 0.8356 - val_loss: 0.8914 - val_accuracy: 0.6797\n",
      "Epoch 51/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3421 - accuracy: 0.8135 - val_loss: 0.8031 - val_accuracy: 0.6870\n",
      "Epoch 52/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3386 - accuracy: 0.8392 - val_loss: 0.7653 - val_accuracy: 0.6797\n",
      "Epoch 53/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3234 - accuracy: 0.8431 - val_loss: 1.0229 - val_accuracy: 0.6797\n",
      "Epoch 54/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3300 - accuracy: 0.8449 - val_loss: 1.3114 - val_accuracy: 0.6577\n",
      "Epoch 55/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3021 - accuracy: 0.8532 - val_loss: 1.3243 - val_accuracy: 0.6601\n",
      "Epoch 56/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3284 - accuracy: 0.8253 - val_loss: 1.0182 - val_accuracy: 0.6699\n",
      "Epoch 57/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3263 - accuracy: 0.8252 - val_loss: 0.7672 - val_accuracy: 0.7017\n",
      "Epoch 58/200\n",
      "3/3 [==============================] - 0s 77ms/step - loss: 0.3027 - accuracy: 0.8492 - val_loss: 0.7900 - val_accuracy: 0.7164\n",
      "Epoch 59/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3132 - accuracy: 0.8448 - val_loss: 0.9130 - val_accuracy: 0.6846\n",
      "Epoch 60/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3051 - accuracy: 0.8483 - val_loss: 1.0681 - val_accuracy: 0.6724\n",
      "Epoch 61/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2956 - accuracy: 0.8590 - val_loss: 0.9800 - val_accuracy: 0.6601\n",
      "Epoch 62/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2961 - accuracy: 0.8572 - val_loss: 0.9044 - val_accuracy: 0.6748\n",
      "Epoch 63/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2874 - accuracy: 0.8460 - val_loss: 1.0156 - val_accuracy: 0.6797\n",
      "Epoch 64/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2742 - accuracy: 0.8633 - val_loss: 1.0573 - val_accuracy: 0.6919\n",
      "Epoch 65/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3014 - accuracy: 0.8502 - val_loss: 1.0104 - val_accuracy: 0.6748\n",
      "Epoch 66/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2825 - accuracy: 0.8547 - val_loss: 1.0061 - val_accuracy: 0.6699\n",
      "Epoch 67/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2935 - accuracy: 0.8681 - val_loss: 1.0428 - val_accuracy: 0.6748\n",
      "Epoch 68/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2869 - accuracy: 0.8501 - val_loss: 1.1031 - val_accuracy: 0.6846\n",
      "Epoch 69/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2750 - accuracy: 0.8532 - val_loss: 0.9405 - val_accuracy: 0.6846\n",
      "Epoch 70/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2983 - accuracy: 0.8469 - val_loss: 0.9927 - val_accuracy: 0.6919\n",
      "Epoch 71/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2792 - accuracy: 0.8545 - val_loss: 1.1651 - val_accuracy: 0.6699\n",
      "Epoch 72/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2840 - accuracy: 0.8421 - val_loss: 0.9659 - val_accuracy: 0.6773\n",
      "Epoch 73/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2779 - accuracy: 0.8620 - val_loss: 0.8531 - val_accuracy: 0.7017\n",
      "Epoch 74/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2597 - accuracy: 0.8646 - val_loss: 0.9796 - val_accuracy: 0.6846\n",
      "Epoch 75/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2815 - accuracy: 0.8545 - val_loss: 1.1805 - val_accuracy: 0.6797\n",
      "Epoch 76/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2737 - accuracy: 0.8648 - val_loss: 1.2294 - val_accuracy: 0.6724\n",
      "Epoch 77/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2566 - accuracy: 0.8680 - val_loss: 1.2042 - val_accuracy: 0.6846\n",
      "Epoch 78/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2258 - accuracy: 0.8910 - val_loss: 1.1187 - val_accuracy: 0.6993\n",
      "Epoch 79/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2462 - accuracy: 0.8789 - val_loss: 1.1839 - val_accuracy: 0.6895\n",
      "Epoch 80/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2619 - accuracy: 0.8797 - val_loss: 1.1798 - val_accuracy: 0.6822\n",
      "Epoch 81/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2437 - accuracy: 0.8779 - val_loss: 1.3039 - val_accuracy: 0.6822\n",
      "Epoch 82/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2649 - accuracy: 0.8721 - val_loss: 1.4864 - val_accuracy: 0.6944\n",
      "Epoch 83/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2605 - accuracy: 0.8788 - val_loss: 1.0790 - val_accuracy: 0.6944\n",
      "Epoch 84/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2598 - accuracy: 0.8707 - val_loss: 0.9432 - val_accuracy: 0.6895\n",
      "Epoch 85/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2560 - accuracy: 0.8663 - val_loss: 1.0988 - val_accuracy: 0.6895\n",
      "Epoch 86/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2676 - accuracy: 0.8778 - val_loss: 1.0656 - val_accuracy: 0.6968\n",
      "Epoch 87/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2511 - accuracy: 0.8749 - val_loss: 0.9826 - val_accuracy: 0.6944\n",
      "Epoch 88/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2348 - accuracy: 0.8839 - val_loss: 0.9902 - val_accuracy: 0.7042\n",
      "Epoch 89/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2280 - accuracy: 0.8871 - val_loss: 1.0118 - val_accuracy: 0.7017\n",
      "Epoch 90/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2329 - accuracy: 0.8882 - val_loss: 1.1385 - val_accuracy: 0.7066\n",
      "Epoch 91/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2161 - accuracy: 0.9013 - val_loss: 1.1535 - val_accuracy: 0.7115\n",
      "Epoch 92/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2288 - accuracy: 0.8945 - val_loss: 1.0689 - val_accuracy: 0.7188\n",
      "Epoch 93/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2302 - accuracy: 0.8938 - val_loss: 1.0891 - val_accuracy: 0.7164\n",
      "Epoch 94/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2376 - accuracy: 0.8844 - val_loss: 1.1157 - val_accuracy: 0.7139\n",
      "Epoch 95/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2190 - accuracy: 0.9022 - val_loss: 1.3014 - val_accuracy: 0.6968\n",
      "Epoch 96/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2365 - accuracy: 0.8831 - val_loss: 1.1907 - val_accuracy: 0.7164\n",
      "Epoch 97/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2298 - accuracy: 0.8905 - val_loss: 1.1603 - val_accuracy: 0.6870\n",
      "Epoch 98/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2150 - accuracy: 0.8950 - val_loss: 1.2529 - val_accuracy: 0.7042\n",
      "Epoch 99/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2048 - accuracy: 0.9098 - val_loss: 1.5758 - val_accuracy: 0.6895\n",
      "Epoch 100/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2309 - accuracy: 0.8992 - val_loss: 1.4050 - val_accuracy: 0.6944\n",
      "Epoch 101/200\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.1898 - accuracy: 0.92 - 0s 22ms/step - loss: 0.2004 - accuracy: 0.9081 - val_loss: 1.3114 - val_accuracy: 0.7139\n",
      "Epoch 102/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2096 - accuracy: 0.9050 - val_loss: 1.4788 - val_accuracy: 0.6944\n",
      "Epoch 103/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2391 - accuracy: 0.8902 - val_loss: 1.6579 - val_accuracy: 0.6797\n",
      "Epoch 104/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1912 - accuracy: 0.9101 - val_loss: 1.5890 - val_accuracy: 0.6895\n",
      "Epoch 105/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2177 - accuracy: 0.9027 - val_loss: 1.5058 - val_accuracy: 0.6870\n",
      "Epoch 106/200\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.2147 - accuracy: 0.8954 - val_loss: 1.4436 - val_accuracy: 0.6870\n",
      "Epoch 107/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2235 - accuracy: 0.8888 - val_loss: 1.3680 - val_accuracy: 0.6822\n",
      "Epoch 108/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2296 - accuracy: 0.8909 - val_loss: 1.3100 - val_accuracy: 0.7115\n",
      "Epoch 109/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1814 - accuracy: 0.9165 - val_loss: 1.3493 - val_accuracy: 0.7213\n",
      "Epoch 110/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1909 - accuracy: 0.9128 - val_loss: 1.2810 - val_accuracy: 0.7115\n",
      "Epoch 111/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1935 - accuracy: 0.9146 - val_loss: 1.3097 - val_accuracy: 0.7262\n",
      "Epoch 112/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1927 - accuracy: 0.9094 - val_loss: 1.5006 - val_accuracy: 0.7237\n",
      "Epoch 113/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1987 - accuracy: 0.9077 - val_loss: 1.5881 - val_accuracy: 0.7090\n",
      "Epoch 114/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2373 - accuracy: 0.8943 - val_loss: 1.4693 - val_accuracy: 0.7164\n",
      "Epoch 115/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2170 - accuracy: 0.8980 - val_loss: 1.3347 - val_accuracy: 0.7066\n",
      "Epoch 116/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2163 - accuracy: 0.8936 - val_loss: 1.2734 - val_accuracy: 0.7164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 117/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2005 - accuracy: 0.9099 - val_loss: 1.3432 - val_accuracy: 0.7115\n",
      "Epoch 118/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2132 - accuracy: 0.9036 - val_loss: 1.3809 - val_accuracy: 0.7237\n",
      "Epoch 119/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1997 - accuracy: 0.9107 - val_loss: 1.3727 - val_accuracy: 0.7139\n",
      "Epoch 120/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1818 - accuracy: 0.9144 - val_loss: 1.4686 - val_accuracy: 0.7042\n",
      "Epoch 121/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1984 - accuracy: 0.9064 - val_loss: 1.5146 - val_accuracy: 0.7115\n",
      "Epoch 122/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2129 - accuracy: 0.9090 - val_loss: 1.5381 - val_accuracy: 0.7090\n",
      "Epoch 123/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1893 - accuracy: 0.9103 - val_loss: 1.5144 - val_accuracy: 0.7066\n",
      "Epoch 124/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1820 - accuracy: 0.9157 - val_loss: 1.5866 - val_accuracy: 0.7213\n",
      "Epoch 125/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1827 - accuracy: 0.9218 - val_loss: 1.5141 - val_accuracy: 0.7188\n",
      "Epoch 126/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1734 - accuracy: 0.9177 - val_loss: 1.4339 - val_accuracy: 0.7213\n",
      "Epoch 127/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1856 - accuracy: 0.9101 - val_loss: 1.4503 - val_accuracy: 0.7164\n",
      "Epoch 128/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1744 - accuracy: 0.9215 - val_loss: 1.6248 - val_accuracy: 0.6944\n",
      "Epoch 129/200\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.1651 - accuracy: 0.9221 - val_loss: 1.8404 - val_accuracy: 0.6919\n",
      "Epoch 130/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.2007 - accuracy: 0.9045 - val_loss: 1.7302 - val_accuracy: 0.6944\n",
      "Epoch 131/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1675 - accuracy: 0.9297 - val_loss: 1.6648 - val_accuracy: 0.6822\n",
      "Epoch 132/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1772 - accuracy: 0.9304 - val_loss: 1.5180 - val_accuracy: 0.7090\n",
      "Epoch 133/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1885 - accuracy: 0.9142 - val_loss: 1.4871 - val_accuracy: 0.7237\n",
      "Epoch 134/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1825 - accuracy: 0.9103 - val_loss: 1.4017 - val_accuracy: 0.7139\n",
      "Epoch 135/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1926 - accuracy: 0.9141 - val_loss: 1.5140 - val_accuracy: 0.6993\n",
      "Epoch 136/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2089 - accuracy: 0.9046 - val_loss: 1.4590 - val_accuracy: 0.7164\n",
      "Epoch 137/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2047 - accuracy: 0.9113 - val_loss: 1.3627 - val_accuracy: 0.7237\n",
      "Epoch 138/200\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.1694 - accuracy: 0.9256 - val_loss: 1.3831 - val_accuracy: 0.7090\n",
      "Epoch 139/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1792 - accuracy: 0.9191 - val_loss: 1.4641 - val_accuracy: 0.7090\n",
      "Epoch 140/200\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1801 - accuracy: 0.9182 - val_loss: 1.6417 - val_accuracy: 0.7262\n",
      "Epoch 141/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1763 - accuracy: 0.9221 - val_loss: 1.6206 - val_accuracy: 0.7262\n",
      "Epoch 142/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1779 - accuracy: 0.9148 - val_loss: 1.5756 - val_accuracy: 0.7017\n",
      "Epoch 143/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1677 - accuracy: 0.9147 - val_loss: 1.5441 - val_accuracy: 0.6944\n",
      "Epoch 144/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1711 - accuracy: 0.9226 - val_loss: 1.5682 - val_accuracy: 0.7017\n",
      "Epoch 145/200\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.1552 - accuracy: 0.9326 - val_loss: 1.6920 - val_accuracy: 0.7115\n",
      "Epoch 146/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1519 - accuracy: 0.9358 - val_loss: 1.7147 - val_accuracy: 0.7359\n",
      "Epoch 147/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1596 - accuracy: 0.9291 - val_loss: 1.8508 - val_accuracy: 0.7286\n",
      "Epoch 148/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1735 - accuracy: 0.9193 - val_loss: 1.9754 - val_accuracy: 0.7115\n",
      "Epoch 149/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1707 - accuracy: 0.9247 - val_loss: 1.9358 - val_accuracy: 0.6919\n",
      "Epoch 150/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1655 - accuracy: 0.9259 - val_loss: 1.6506 - val_accuracy: 0.7286\n",
      "Epoch 151/200\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.1821 - accuracy: 0.9184 - val_loss: 1.6356 - val_accuracy: 0.7384\n",
      "Epoch 152/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1657 - accuracy: 0.9277 - val_loss: 1.7758 - val_accuracy: 0.7139\n",
      "Epoch 153/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1627 - accuracy: 0.9296 - val_loss: 1.7195 - val_accuracy: 0.7213\n",
      "Epoch 154/200\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1492 - accuracy: 0.9396 - val_loss: 1.5080 - val_accuracy: 0.7359\n",
      "Epoch 155/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1697 - accuracy: 0.9198 - val_loss: 1.4256 - val_accuracy: 0.7262\n",
      "Epoch 156/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1671 - accuracy: 0.9335 - val_loss: 1.5366 - val_accuracy: 0.7115\n",
      "Epoch 157/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1702 - accuracy: 0.9248 - val_loss: 1.6727 - val_accuracy: 0.7213\n",
      "Epoch 158/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1668 - accuracy: 0.9221 - val_loss: 1.7425 - val_accuracy: 0.7237\n",
      "Epoch 159/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1780 - accuracy: 0.9205 - val_loss: 1.7229 - val_accuracy: 0.7213\n",
      "Epoch 160/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1602 - accuracy: 0.9322 - val_loss: 1.7154 - val_accuracy: 0.7164\n",
      "Epoch 161/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1453 - accuracy: 0.9462 - val_loss: 1.7178 - val_accuracy: 0.7213\n",
      "Epoch 162/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1804 - accuracy: 0.9207 - val_loss: 1.6707 - val_accuracy: 0.7262\n",
      "Epoch 163/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1626 - accuracy: 0.9300 - val_loss: 1.7681 - val_accuracy: 0.7042\n",
      "Epoch 164/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1514 - accuracy: 0.9350 - val_loss: 1.9292 - val_accuracy: 0.6797\n",
      "Epoch 165/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1534 - accuracy: 0.9291 - val_loss: 1.7852 - val_accuracy: 0.7188\n",
      "Epoch 166/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1642 - accuracy: 0.9300 - val_loss: 1.7002 - val_accuracy: 0.7384\n",
      "Epoch 167/200\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1690 - accuracy: 0.9179 - val_loss: 1.7403 - val_accuracy: 0.7090\n",
      "Epoch 168/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1640 - accuracy: 0.9313 - val_loss: 1.7348 - val_accuracy: 0.7066\n",
      "Epoch 169/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1567 - accuracy: 0.9267 - val_loss: 1.7211 - val_accuracy: 0.7335\n",
      "Epoch 170/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1602 - accuracy: 0.9240 - val_loss: 1.8303 - val_accuracy: 0.7359\n",
      "Epoch 171/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1607 - accuracy: 0.9263 - val_loss: 2.0796 - val_accuracy: 0.7115\n",
      "Epoch 172/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1786 - accuracy: 0.9197 - val_loss: 2.1585 - val_accuracy: 0.7115\n",
      "Epoch 173/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1619 - accuracy: 0.9314 - val_loss: 1.9929 - val_accuracy: 0.7335\n",
      "Epoch 174/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1743 - accuracy: 0.9246 - val_loss: 1.7962 - val_accuracy: 0.7359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1640 - accuracy: 0.9241 - val_loss: 1.9944 - val_accuracy: 0.6797\n",
      "Epoch 176/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1659 - accuracy: 0.9287 - val_loss: 1.9305 - val_accuracy: 0.7042\n",
      "Epoch 177/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1657 - accuracy: 0.9195 - val_loss: 1.9152 - val_accuracy: 0.7164\n",
      "Epoch 178/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1676 - accuracy: 0.9264 - val_loss: 1.8104 - val_accuracy: 0.7042\n",
      "Epoch 179/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1540 - accuracy: 0.9361 - val_loss: 1.7382 - val_accuracy: 0.6797\n",
      "Epoch 180/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1788 - accuracy: 0.9261 - val_loss: 1.5961 - val_accuracy: 0.6944\n",
      "Epoch 181/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1546 - accuracy: 0.9328 - val_loss: 1.7495 - val_accuracy: 0.7090\n",
      "Epoch 182/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1676 - accuracy: 0.9274 - val_loss: 2.0068 - val_accuracy: 0.7017\n",
      "Epoch 183/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1549 - accuracy: 0.9344 - val_loss: 2.1087 - val_accuracy: 0.6895\n",
      "Epoch 184/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1410 - accuracy: 0.9330 - val_loss: 2.0235 - val_accuracy: 0.7115\n",
      "Epoch 185/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1339 - accuracy: 0.9376 - val_loss: 2.2145 - val_accuracy: 0.7017\n",
      "Epoch 186/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1327 - accuracy: 0.9438 - val_loss: 2.5571 - val_accuracy: 0.6797\n",
      "Epoch 187/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1398 - accuracy: 0.9374 - val_loss: 2.5031 - val_accuracy: 0.7115\n",
      "Epoch 188/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1351 - accuracy: 0.9376 - val_loss: 2.5519 - val_accuracy: 0.7139\n",
      "Epoch 189/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1559 - accuracy: 0.9362 - val_loss: 2.6697 - val_accuracy: 0.6870\n",
      "Epoch 190/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1284 - accuracy: 0.9502 - val_loss: 2.5413 - val_accuracy: 0.6846\n",
      "Epoch 191/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1506 - accuracy: 0.9368 - val_loss: 2.2592 - val_accuracy: 0.7042\n",
      "Epoch 192/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1260 - accuracy: 0.9426 - val_loss: 2.0256 - val_accuracy: 0.7311\n",
      "Epoch 193/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1322 - accuracy: 0.9414 - val_loss: 2.0048 - val_accuracy: 0.7115\n",
      "Epoch 194/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1366 - accuracy: 0.9389 - val_loss: 2.3825 - val_accuracy: 0.6553\n",
      "Epoch 195/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1343 - accuracy: 0.9392 - val_loss: 2.5733 - val_accuracy: 0.6650\n",
      "Epoch 196/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1591 - accuracy: 0.9379 - val_loss: 2.4018 - val_accuracy: 0.6919\n",
      "Epoch 197/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1334 - accuracy: 0.9410 - val_loss: 2.5365 - val_accuracy: 0.7017\n",
      "Epoch 198/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1570 - accuracy: 0.9324 - val_loss: 2.6452 - val_accuracy: 0.6944\n",
      "Epoch 199/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1722 - accuracy: 0.9245 - val_loss: 2.4587 - val_accuracy: 0.6919\n",
      "Epoch 200/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1211 - accuracy: 0.9436 - val_loss: 2.3601 - val_accuracy: 0.6870\n"
     ]
    }
   ],
   "source": [
    "bestNN=create_modelWithDropBatch(hidden_layers= 2, learning_rate= 0.05)\n",
    "history2 = bestNN.fit(\n",
    "     xtrain_tfidf_ngram, y_train,\n",
    "    validation_data=(xvalid_tfidf_ngram,y_cv),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "#     callbacks=[early_stopping],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "10secnds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Cross-entropy'}>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Accuracy'}>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAEICAYAAABPgw/pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAABMT0lEQVR4nO2dd3gc1dX/P1e9d1mybNly77gCNmCb3sGETugJEGrIG0JCQgovIb8EeANJCKGEUEMIBAg4YDABjI0pBtvIvclNVrF679q9vz/ujHYl7ap5V6tyPs+jZ3bv3Jk5O5K+c/bcc89VWmsEQRCEwU9QoA0QBEEQfIMIuiAIwhBBBF0QBGGIIIIuCIIwRBBBFwRBGCKIoAuCIAwRRNAFQRCGCCLoQkBQSn1bKbVeKVWrlCpUSr2nlDoh0Hb1FqXUdUqptYG2QxBABF0IAEqpHwJ/AP4fkAaMAf4CLPPQN6RfjfMDSqngQNsgDA9E0IV+RSkVD9wP3Ka1flNrXae1btFa/0drfbdS6j6l1OtKqb8rpaqB65RSGUqp5UqpcqVUjlLqRrfzHWN5+tVKqSKl1CNWe4R1jjKlVKVS6mulVFoXdn1HKbVDKVWhlFqplBrrtk8rpW5WSu2xzvW4MkwDngQWWd80Kq3+zyulnlBKrVBK1QEnKaWmKaU+sY7fppQ63+38zyulnlRK/VcpVaOUWm1f37rW7zvYulwp9T8++HUIQw2ttfzIT7/9AGcCrUCIl/33AS3ABRiHIxJYg/HgI4A5QAlwstX/C+Bq63UMsNB6/T3gP0AUEAzMB+K8XHMZkANMA0KAnwOfu+3XwDtAAubbRAlwprXvOmBth/M9D1QBx1ufIdY6/8+AMOBkoAaY4ta/BlgChAN/tM8JHAMUAEHW+xSgHkgL9O9Sfgbej3joQn+TDJRqrVu76POF1votrbUTI2DHAz/RWjdqrbOBZ4BrrL4twESlVIrWulZr/aVbezIwUWvt0Fpv0FpXe7nezcBvtdY7LLv+HzDH3UsHfqe1rtRa5wKrMA+Wrnhba/2Z9RnmYB42v9NaN2utP8Y8IK5w6/+u1nqN1roJuBfj9Wdqrb/CPBxOsfpdDnyitS7q5vrCMEQEXehvyoCUbmLjh9xeZwDlWusat7aDwCjr9XeBycBOK6xyrtX+ErAS+KdSqkAp9ZBSKlQptdgKj9QqpbZZfccCf7TCIZVAOaDcrgFw2O11PUagu6LjZzhkibunz9Cuv9a61rIhw2p6AbjKen2V9dkEoRODfsBJGHR8ATRhQiqve+njXgK0AEhSSsW6ifoYIB9Aa70HuEIpFQRcCLyulErWWtcB/wv8r1IqC1gB7NJa/43OYnwI+I3W+uU+fB5v5Uo7foZMpVSQm6iPAXa79cm0XyilYoAk6ziAvwNblVKzMWGht/pgpzAMEA9d6Fe01lXAL4HHlVIXKKWiLM/5LKXUQx76HwI+B35rDXQehfHK/w6glLpKKZVqCWWldZhTKXWSUmqWlWFSjQnBODue3+JJ4KdKqRnWOeOVUpf08CMVAaOVUmFd9FmH8ep/bH3WE4HzgH+69TlbKXWCdZ5fA19anx2tdR7wNcYzf0Nr3dBD24Rhhgi60O9orX8P/BAz+FiC8ZBvx7vneQWQhfFY/w38Smv9obXvTGCbUqoWM5h4uSV46ZhvANXADmA1XkIVWut/Aw9iwjPVwFbgrB5+nI+BbcBhpVSpl/M3YwT8LKAUM8B7jdZ6p1u3fwC/woRa5uMKsdi8AMzy9hkEAUBpLQtcCEIgUUo9D+RprX/eRZ8lmG8lY7X80wpeEA9dEAY4SqlQ4E7gGRFzoStE0AVhAGNNXqoERmJm1wqCVyTkIgiCMEQQD10QBGGIELA89JSUFJ2VlRWoywuCIAxKNmzYUKq1TvW0L2CCnpWVxfr16wN1eUEQhEGJUuqgt30SchEEQRgiiKALgiAMEUTQBUEQhggDqjhXS0sLeXl5NDY2BtqUAU1ERASjR48mNDQ00KYIgjCAGFCCnpeXR2xsLFlZWSilAm3OgERrTVlZGXl5eYwbNy7Q5giCMIAYUCGXxsZGkpOTRcy7QClFcnKyfIsRBKETA0rQARHzHiD3SBAETww4QRcEQRiw5H4JBdmBtsIrIugdiInpbmUxQRCGLW/fDit/FmgrvCKCLgiC0BNaGqF8L5Tu7r6vO1rDV3+F8v3+scsNEXQvaK25++67mTlzJrNmzeLVV18FoLCwkCVLljBnzhxmzpzJp59+isPh4Lrrrmvr++ijjwbYekEQfE7ZHtBOqCuBhsqeH1dTCCt+BN/83W+m2QyotEV3/vc/29heUO3Tc07PiONX583oUd8333yT7OxsNm3aRGlpKUcffTRLlizhH//4B2eccQb33nsvDoeD+vp6srOzyc/PZ+vWrQBUVlb61G5BEAYAJbtcr8tyYPSCnh132OgCNYW+t6kD4qF7Ye3atVxxxRUEBweTlpbG0qVL+frrrzn66KN57rnnuO+++9iyZQuxsbGMHz+effv2cccdd/D+++8TFxcXaPMFQfA1xTtcr3sTdimyBL26wLf2eGDAeug99aT7myVLlrBmzRreffddrrvuOn74wx9yzTXXsGnTJlauXMmTTz7Ja6+9xrPPPhtoUwVB8CUlOyFxHFQdgtI9PT+uaJvZioceOBYvXsyrr76Kw+GgpKSENWvWcMwxx3Dw4EHS0tK48cYbueGGG9i4cSOlpaU4nU4uuugiHnjgATZu3Bho8wVB8DXFOyB9lhH1st4Iuu2h+1/QB6yHHmi+9a1v8cUXXzB79myUUjz00EOkp6fzwgsv8PDDDxMaGkpMTAwvvvgi+fn5XH/99TidTgB++9vfBth6QRB8SksjVOyHWReDsxVKc7z3Xfso7P8Urn7THFe6B0KjoKkKmusgLNpvZoqgd6C2thYwszEffvhhHn744Xb7r732Wq699tpOx4lXLghDjNIc+PT3cO4jZhBUOyF1KrQ0QM6H4HRAUHDn4w5+AQc+BacTSneBdsC4pbD7PeOlp0z0m8kSchEEQfDEvlWw6R+w4x048JlpS58FKZPB0QyVXhYOqikw++tLXRkuk0517fMj3Qq6UipTKbVKKbVdKbVNKXWnhz4nKqWqlFLZ1s8v/WOuIAhCP9FkpU1vegU2PA8Z8yBlEiRmmfbKXM/H1Rw226pDULwdQiJg7Ammzc9x9J6EXFqBu7TWG5VSscAGpdR/tdbbO/T7VGt9ru9NFARBCABNNWa79yOzPf8xs41KMltPk4scLWbiEUBVvgnVJE+E+NGmLdAeuta6UGu90XpdA+wARvnVKkEQhEDTWA1Bls8bHgczLzKvIxPNtqGi8zG2dw5QlWcEPWk8hMeYcwwAD70NpVQWMBdY52H3IqXUJqAA+JHWepuH428CbgIYM2ZMr40VBEHoN5qqjWedMQ9GTHdlp/RU0CtzoeIATDvfvI8d6XcPvceCrpSKAd4AfqC17jgnfyMwVmtdq5Q6G3gLmNTxHFrrp4GnARYsWKD7arQgCILfaaw2XvUlz7VvD42E4HAvgm4JtgqC3M9NimPyBNMWN9LvHnqPslyUUqEYMX9Za/1mx/1a62qtda31egUQqpRK8amlgiAI/UlTDUTEe94XmQiNlZ3bbQ99xHQo3GxeJ1mCHpvh99miPclyUcDfgB1a60e89Em3+qGUOsY6b5kvDR2IdFU7/cCBA8ycObMfrREEwac0WR66JyITvXjohRAUCiNnA1YQItnKO4/LMILf2uwXc6FnIZfjgauBLUqpbKvtZ8AYAK31k8DFwC1KqVagAbhcay0hFUEQBi+N1RAe63lfZKLnLJfqQohNh/hM8z48DqKtYMWIaWaSUckOS/B9T7eCrrVeC3S5iKXW+s/An31lFADv3QOHt/j0lKTPgrN+53X3PffcQ2ZmJrfddhsA9913HyEhIaxatYqKigpaWlp44IEHWLZsWa8u29jYyC233ML69esJCQnhkUce4aSTTmLbtm1cf/31NDc343Q6eeONN8jIyODSSy8lLy8Ph8PBL37xCy677LIj+tiCIPSBpmqI6MJD9zSxqMYWdCsRMHkC2GsAZ8w124LswAn6cOKyyy7jBz/4QZugv/baa6xcuZLvf//7xMXFUVpaysKFCzn//PN7tVDz448/jlKKLVu2sHPnTk4//XR2797Nk08+yZ133smVV15Jc3MzDoeDFStWkJGRwbvvvgtAVVWVXz6rIAhdoLWJoXcVcinM7txeU2jKA8RZgm7Hz8EU9QqPs47rXD7EFwxcQe/Ck/YXc+fOpbi4mIKCAkpKSkhMTCQ9PZ3/+Z//Yc2aNQQFBZGfn09RURHp6ek9Pu/atWu54447AJg6dSpjx45l9+7dLFq0iN/85jfk5eVx4YUXMmnSJGbNmsVdd93FT37yE84991wWL17sr48rCII3mutMeMSrh57gPW1x/EmuiUTJbnVbgoKMZ+7HRaallksHLrnkEl5//XVeffVVLrvsMl5++WVKSkrYsGED2dnZpKWl0djY6JNrffvb32b58uVERkZy9tln8/HHHzN58mQ2btzIrFmz+PnPf87999/vk2sJgtAL7FmiXcXQW+pNNcW2Y2pNmCZupJlMNOsSmNZh8vzI2aY+up8GRgeuhx4gLrvsMm688UZKS0tZvXo1r732GiNGjCA0NJRVq1Zx8KCXgjxdsHjxYl5++WVOPvlkdu/eTW5uLlOmTGHfvn2MHz+e73//++Tm5rJ582amTp1KUlISV111FQkJCTzzzDN++JSCIHSJXcfFa8glwWwbKyHU+rZeW2S2MekQHAoXefjfzZgLjia/DYyKoHdgxowZ1NTUMGrUKEaOHMmVV17Jeeedx6xZs1iwYAFTp07t9TlvvfVWbrnlFmbNmkVISAjPP/884eHhvPbaa7z00kuEhoaSnp7Oz372M77++mvuvvtugoKCCA0N5YknnvDDpxQEoUsaLUHvKg8dTKZLrCXoTd0cA34fGBVB98CWLa7smpSUFL744guP/eza6Z7IyspqWzQ6IiKC5557rlOfe+65h3vuuadd2xlnnMEZZ5zRF7MFQfAVTVYyQleDotA+jt4WpvE+P6VtYLQ3a5L2AhF0QRCEjvQkhg4dBL2262PADIzeucl1vI8RQT9CtmzZwtVXX92uLTw8nHXrPNUvEwRhUNAWcumFh95sCXpYF4IOrvK7fmDACbrWulc53oFm1qxZZGdn9+s1ZRKuIPiZbgdFPXno9jFdhFz8zIBKW4yIiKCsrEwEqwu01pSVlRERERFoUwRh6NJUAygI8yLO4XGggnsfcvEzA8pDHz16NHl5eZSUlATalAFNREQEo0ePDrQZgjB0seu4BHnxeZUy2SwdQy4qCEKj+sdGDwwoQQ8NDWXcuHGBNkMQhOFOV5UWbTpWXGyqMR59AEPGAyrkIgiCMCBorPI+IGrTsSZ6U21Awy0ggi4IgtCZrgpz2UQlQV2p631zjfeYez8hgi4IgtCRpi5qodtEp0K92zo+TTUBzXABEXRBEITONHZRC90mKtl46HZWnoRcBEEQBiCNVd2HXKJTTaEte1Zpc62EXARBEAYUjhYTSontZs0De2m5eiuO3pO4u58RQRcEQXCntgjQPRD0VLOtcxd08dAFQRAGDjWHzTZ2ZNf9opLN1o6jS8hFEATBB3z6CKzvXKK6T1QXmG13gt7moZdAayM4W2VQVBAE4YhwtBpBz37ZN+frqYfuHkMfAHVcQARdEITBzuFNZlJP5SHfnK+mEIJCXSEVb4RGmhBLXam5PkjIRRAE4Yg4sNZsaw9Da9ORn6+m0AyIeivM5U50igm5dLcgRj8hgi4IwuDGFnRwxb97i9bw4jLY/JpL0HtCVIrx0NtCLuKhC4Ig9A1HKxz8ApInmvdVfQy7VB2CfZ8YQa8u7D5+bhOdaoVcerhakZ8RQRcEYfBix89nX27eV+X17TyFm8320FeWh95TQU+2BkUl5CIIgnBklO4x2ylnm21fB0YLN5ltU5UpzBXXSw99ACw/ByLogiAMZuxqh3EZEJPW95DL4c0QkeB631MPPSoFnC2u2L1kuQiCIPSR+jKztmd4PMRnHkHIZRNMOh2iR5j3PR0UtScXle8324Eu6EqpTKXUKqXUdqXUNqXUnR76KKXUn5RSOUqpzUqpef4xVxAEwY36MrPQRFAQxI/um4deW2Li5iNnw5hjTVtsRs+OtScXle8zYt6TVEc/0pOrtwJ3aa2nAwuB25RS0zv0OQuYZP3cBDzhUysFQRA8UVdqwh4ACZaHbtcn7ymHrfj5yNkw4RSTqRI/qmfHpkyGoBAo2Bhw7xx6IOha60Kt9UbrdQ2wA+j4aZcBL2rDl0CCUqqHQShBEIQ+Ul/umtEZn2lqqthx9Z4K++EtZps+C+ZfB/+zBcKie3ZsQiZc9AyooIAPiAKE9KazUioLmAus67BrFOD+XSfPaivscPxNGA+eMWPG9NJUQRCEDtSXQeoU8zp+tNlW5kJLA/xlEVz9JmQe0/U5aopMHfPIBPM+MrF3Nsz4FgSHuSYXBZAeB3yUUjHAG8APtNbVfbmY1vpprfUCrfWC1NTUvpxCEIRAU7oH1j3d+9CGP6gvc3nocVbcu6YQineY/PTNr/bsHL0V8Y5MPQdmX3Zk5/ABPRJ0pVQoRsxf1lq/6aFLPpDp9n601SYIwlDj62fgvbth/5rA2uF0QkO5a2DSTjWsOWxEHWDXe90/eBrKuy/ENUjoSZaLAv4G7NBaP+Kl23LgGivbZSFQpbUu9NJXEITBTMkus139YGDtaKwE7XSJcXSqiWXXHLZWHQKq86Ewu+vz2JkyQ4CeeOjHA1cDJyulsq2fs5VSNyulbrb6rAD2ATnAX4Fb/WOuIAgBp3SPyeg4+Bns/zRwdtiDn7agBwWbPPJay0MPjTYCv+u9bs4zdDz0bgdFtdZrAdVNHw3c5iujBEEYoDTVQnUeLLkbPn8Mdr8P4xb79hqOFnhqKZz4E5i+zHu/joIOEJtmPPSgEEgaZwY71z8LE0+DzKO9nKccIoePhy4IgmAos2qnpM8yQtpQ6ftrVOdD8bbuY/QeBX2k8c5rDptSAOf8HkKj4LmzIH9D53O0NpvB0yHioYugC4LQc+xiWClTTGZIQ4Xvr1GZa7b2dHpv1JWabTtBTzdpiDWHzeu06XDjx2a9z5yPOp+jodw6x9Dw0HuVhy4IwjCndLepnZI03hSzaqz0/TXsiokV3Qi6Jw89Jt2sIKSCXPVYolOMvYc3d3GOoSHo4qELgtBzSnaZ2HRImJmI4w8P3a7HUplrFrDwRn2ZCaeERbnaYtMBDdphxN1m5FGuGaHtzmF76BJyEQRhuFG6x9QvAf+HXJytZgDWG56yU9zL3rpXTEyfBRUHoLGqwzksD10GRQVBCDhad+3F+hJHK5TvdRP0BP8MilbmmiwV6DqOXl/aOVQSm+b22l3QjzLbw1vb928QD10QhIHCZ3+Ax4/pn2n4VbngaHat3xmZCK0Npm6KT69zCEYtMK+7iqO7T/u3cffQY9zEPX2W2XYMu0gMXRCEAUPRNuM11/TDxOyyfWabPMFs7fonvvTSnQ6oyjd1yYPDuvbQaw67FqSwsWeLQnsPPSbN7Osk6OVmklRIuG/sDzAi6IIwmLGnuBdt9/+1yveabZIl6PaSbb6Mo9ccNku6JYw1P9489IYKk68+Ymr7dnu2aGRie5FWynjpdu1zm/ryIeOdgwi6IAxuakvMtmhr1/18Qdle483GWF6x7aH7MnXRznBJGGOyacoPeO5nP8DSZnbeF5vueU3Q0UebbzTuD6D6siEzIAoi6IIwuGnz0Lf5/1rle00+t7Iqgdj1w90F0uk4smvYOejxmZA4znjonsYH7M+bNqPzvtlXmJ+OTDjZFPNyn4E6hCotggi6IAxeHC2uLI3ifgi5lO11xc/BLYZuCfruD+B3Y00MvK9UHjTbhEwj1s21UJbTuV/RVuNZe/LEF94Mx3+/c/uo+aa2y96PXW2eBlYHMSLogjBYsae+RyaaCT+tzf67lqPFpBMmeRL0SrPN+8rURdn6Rt+vU5ZjYuBh0TBmoWnL/bJzv6JtRvBVl3UD2xMcCuOWQM7HLq9fYuiCIAwI7HDLuKVmINEunOUPKg6a2ZfuHnpYrMkosT10OyNly7+8n8fpgE2ves+MKciGjDnmdcpk44Uf+hKa62HvKmisNuco3u45ft4dE04y6Zfl+8wDsKlaYuiCIAwA6qwB0Qknma0/M106ZrgABAWZTJc2QbfSGg9vhpLdns+z+334903w0gWds2OaaqF0F2TMNe+VgsxjjYf+4X3mmIfGwWvXQEu95/h5d4y37tX+Na4BWHst0iGAFOcShMFKbbHZjj3eLOaQ+zkcdYl/rlVmCbq7hw4m7GJnuZTvg6nnws53YevrcNLPOp8n50MIiTAhkydOcK3DmTTBDLhqp0vQwYRddr9nwj1Tzoa4UbD+b2ZfXwQ9cZy5flkOJGaZtoShs2C9CLogDFbskEtchvHSd70P5zzSu7hyT2isgo0vmmJXHQcQ7QJd9eVG2MceZ0IvngphaW0EfcIpsOhWWP0QfPp7s08FwyJrjZyRc1zH2HF0pwPO+I0R/VkXm4HNkbN7/1mCgoyQl+93DcAmju39eQYoIuiCMFipKzF54WHRMOUs2PkOFG5yxaB9gdbw2rUmPn/Vm50fFpGJJlPEjp8njjN54PbDxp3SPcbTPv4HkHWC+WmsNp/jsfnw5RPmoRHnlrmSMdd8xunLjJiDEXlb6PtC0niTDllx0NSMiRvV93MNMCSGLgiDldpiM50dYNIZgDIxal9SlgP7VsEpv4TxSzvvj0w0A5x2/DxpvJl4ZIeD3Mn50Gwnnupqi4gzYZxJp5mBXfdwC5jZnt9bY1Ye8hWJ48wDqOKAiZ8HBfvu3AFGBF0QBiu1Ra4CVDGpMHpB9wsi95aSXWabdYLn/fagaPk+QJlwRswIY1vHCUH7PoHkSZ5DHEffaLaevl0kT4DQyD6Z75Gkcaao2KGvTHmBIYQIuiB0RdF2M3jnyeMMNHUlRshtJpwChdkmxc9XlFqCnjzJ8/7IRBNjL9tjQhehEeYh42juXBKgZKdZaMITE0+FM34L86/zleXeSRpnttV5Qyp+DiLogtA1uZ9D0RaTuTHQqC1qX20wxRJde7Cvp2x9E75+xvO+0j0Qm2FCI55IngBo2PZvl1Da3xrcH4KtzSZNMGlCp1MAZrBy0a3tKyT6CzsWD+KhC8Kwwp7Gbsd/BwqOFhPqcK/5bafhVRzo3bk+fwzevQu++EvnfSW7IHWy92NnXQon/8KkG9pphHbxLndBrzhg+nRMewwE8ZkmqwZc92yIIIIuCF1RZS2Btu8T/06t7y22WMa4eei2OHVVQ9wT1QUQFAorfwr7P3W1a20tOTfF+7FBQbDkR3DHRjjpXtNmf2twz3TxNDEpUASHmloxMKRy0EEEXRC6pjrfpLY110LuF4G2xkW19c3BPeUuKtlMx++Nh97abIT3uNtNxsznj7ldo8DUZunKQ7dJGucKy3jy0L1NTAoUdthFQi6CMIyoyoOJpxkPNue/vT9+y+tm0Ya+ojXs+W/nsrT2N4d4N0FXVpZJbwS99jCgjcAdfQPsWWm8cnANiKb0QNDdiUw096ujhx6RMHAKYaVMgfD49t9whgAi6IIARnQ3vtS+zek0XmrqFDORxb2Odk+oyoc3vgtfPd13u/atgpcvNgOX7njy0AGSsrpeh9OTjWBmmy74jln27csnTJtdj6WrkIsnlDKx/Y4e+kDxzgGW/hiuX+H7WbUBRgRdEAA2/ROW3w41bl5lXYmZ7BI/GsYsMtPZG6t7fs5D68y2eGff7cr5yGz3ftS+vSrfzKCMiG/fnphlZkA6nT07f9uDYbTxVmdfYab5F++EA5+a8/fFi40ZAXVugl6+b2DEz22ikiC9D9UaBzgi6IIArpxpO5QBJk8ZjBc8dpHJ0sj7qufnPGT1LTkCQd+7yrV1n6hTnWfs6uhhJmaBo8kKpfSA6gKzjcsw21N+CeEx8OL5ppTAsTf3zYuNSXOFXFoazX0dSB76EEUEXRDA5XlXuwm6HY6IH2XWo1TBnhdb8IbtoVfsN6LWU2qL4eMHzKSm4m2QOtUIdPGO9rbFe6hBkmjlgvc006U63wyk2gOa0Slw2q+NGE85G5be03O73YlJdYVcKvZj4vQi6P6mW0FXSj2rlCpWSnlchVYpdaJSqkoplW39/NL3ZgqCn2msMtt2HrpbOCI81qwaf7CHmS4tDaYueOI449n3dPGJlgZ45XJY8zA8f45pO/U+s3VfOq063+VVu9PbXPRqDw+GuVeZQlwX/c2kJfaFmDQrZOWAUjsWP7Fv5xJ6TE9+W88DZ3bT51Ot9Rzr5/4jN0sQ+hlPgl6VZ2pn25kZY4+D/PXQ2tT9+Qq+AWcrzLvavLdronTHirshfwPMv95awDjFFN5KmWIGSMFKNSw2D5qOJIwxaZbuoaGS3fDvm83DoiPVBZ0fDErBxFMgLKpnNnsiJs08yOrLTO1zFWS+aQh+pVtB11qvAcr7wRZBCBxNVsilo4fuHqceswhaG43gdocdbpn9bROqcQ+XeKPyEGS/DAtvhfP+AGf/n4lpBwWZSocHvzAzRGsKAO055BIcCnOvNgOb+RtN2/a3YNMrnssXVOX7p3ysvXhzZa4R9CQfF9gSPOKrGPoipdQmpdR7Simvy4gopW5SSq1XSq0vKSnx0aWFIU1lLnzxuP+v481DdxfN8UtNfnVP6rqU5hhRixtpBgN7MjBq11NZeKvZHnMjzL/WvB57HLTUmXrnVV5SFm1O+18zW3P59022S9E20775tfb9HC0mVu4PQR8132xzv7QWdJ7u+2sInfCFoG8ExmqtZwOPAW9566i1flprvUBrvSA1NdVbN0Fwkf0KrPyZWRHHn9iCbsfNwRp4zHS9j4g3or7znc6lYTtSU+jyUlOndC/oLQ2w8QWYeo5rWro7Y4832wNrXZkp3tbCjIiHE+8xRcVKdri+HeR8CHWl7W1Ee47FHylxI834Qc5/TTx/RB+WixN6zRELuta6Wmtda71eAYQqpVKO2DJBAJfANtf69zp2lkttkYmRO1pNZklH73XquUagbK/XG+0EfZq1ynwXsffdK02xLbsueEdiRpgZmwc/a59O6Y1xS8x2/xqzSMXUc0E7TFVEm+48/SNl7HGmBg66b+t/Cr3miAVdKZWulAkyKqWOsc5ZdqTnFQTA8iKB5jr/XcPRYsIZdl2P6gJzXe3sHKeeeg6gjJfeFTWFrqXUkieac1V0UdY272sIDjci6I2xx5sQRt5644WHx3jvmzTe1GbZ+JIR8pkXmQfC7pWuPgVWjN1f4ZAxi1yvJeTSL/QkbfEV4AtgilIqTyn1XaXUzUqpm60uFwNblVKbgD8Bl2vd3fdRQeghdnihyY8eelON2dpeZFVe+5RFd2JGQOYxXa8M1NJgvG27trc9oaYsx/sxBdkmLTI41Hufscebwdud78C8a7z3AzOQm3msyWMH89lGH2Oyb+x/zwOfmbCIP0Iu4Ho4hUZDQpZ/riG0o9tForXWV3Sz/8/An31mkSC4Ywu6P0Mu9izRtBmwa4URdFtYPWWSTDgZPvmdiet7KjZlF+OyQy52ZT+7hGxHnA6z0tDsLv/VYMJJkDYL5lzhGjjtijGLjPgHh5ssk4w5kP138/niRpnFO6ac0/15+krSeJO+GJ/Z93x2oVd0K+iCEDBaGkwuNvhZ0K0B0RHTzLY6zxSpAs/x5XFL4ZPfmgHK6ed33t9R0KOSIDLJu4delmM+36h5XdsZnQK3rO26jztjFppt6mQIDoEM6/wF35hvJQ0VkHV8z8/XW5SCcx7pOjQk+BQRdGHgYnvn4N8Yuj0gGpNu0v3K95vCV+FxnpdeGzXfhBH2r/Ei6JbdtqCDiaOXefHQ7XzxjG4EvbekHwUhkZBmFaFKn2nSLgs2uuqsdBWz9wXTzvXv+YV2iKALAxd7QBT6x0OPiDOLGBdkmwUbvGV/hIQZIdy/2vN+20OPcxf0CbCvQ/+mWlN//MCn5gFhrwnqK0LC4KrXXamXIeFmcLLgG/OtIG7UkFvgYbgjgS1h4OLuoftzULRN0OON912yw0zV9xQ/txm3xNQocbfRpqbQlAyISHC1JU0wnrv7N42P/hde/46ZHZoxB4KCffFp2pN1QvuV7TPmmlDRjv/A9AuGXD3w4Y4IujBwcZ/k48+Qiz3t3xZ0u5iWt4k7YAYoAfZ80HlfdaHJcHEXSzvTpXyf2VYchPXPmfzwo2+A4+448s/REzLmmRozU881M0qFIYWEXISBS3WhiWNrp59j6FWAMmVk3ePYnopf2aTNNFkc2/5tsl5eXAYXPAljjjUhl9gOqYBtqYt7TXri6odMwaqzHur6m4CvmXmhuZ9zvt11iqQwKBEPXRi42CViw2LMYsX+orHaPDiCgkwd73hrJfiuhFYpmHGhGRh9/6fG8978qtlXU+jKQbexa4GX7jHhoy2vmUqM/SnmYMoAL7jexNOFIYcI+nAlfyM8tRT+84NAW+KdmkJL0KP976G7L+Vmpw92NyV+xreMt7vzHUCZxZy1bj/t3yY8BkZMNyVwD6wFRzNMO8+nH0MQRNCHIyW74ZlTzWSW/PWBtsY71QUmdBEe4ztBb643oRx3GqvapyeOXmC2nopkuZM2w0ynDw4ziw5X5ZpFKFrqO3voYAT84Oew6R8QGtV+arwg+AAR9OFI8XZT32PEdGioCrQ1nmlpNLHo+NEm5OKrLJc1D8NTS9pXS2yqbu+hz78eLnneNcPTG/bEmQv/6pqK/6/rzMzMKWd17j/tPEDD9rdNloyEPQQfI4I+HGmoMNvkCa6UvYFG+V5Am9zssGjf5aGX7TGr0VfmutoaK00M3SY8xoRTesK4xTDjAvPgGTHDPBxO/ZXnnPK0ma4l4iae2scPIAjeEUEfjti1SxKzoKnK1BIZaNhLtqVMtgZFfSTodrjFvfxtxxh6X1l0G8y5Co69xfN+pWCaNbN04ilHfj1B6IAI+nCkocLEfe2BOzsPeyBRugdQZsq8LwdF7YlAxe6CXu0bQZ97JVzweNeFqJb8CK58o/twjiD0ARH04UhDpZnFaM9kbKgMnC3eKN1lBiXDoiwP3QeC7nS4apjYHnpjtfHQo/tpBa2IeJgk4RbBP4igD0caKyEyESITrPcBiqMf+AzWPe15ObeS3Wale7CyXGq7X/atO2qLzWAwuAS9MBvQZkq8IAxyZKbocKShwoi5HWYIhKBrDf+50wxShoTB/Otc+5zW1PvxS837sGiT793SYDz2vmJXQUybZUIuLY1m9R/ovnStIAwCxEMfjjRUGg/dDrnYg6T9yYG1RrRjR8KKu+HwFte+qlxobXRlioRZ9bSPNOxiD4hOOtU8IEp2Qv4GE8/2tFCFIAwyRNCHI20x9AB66BueM9e/4SPjrW953bQ31UDRdvPaDrm0CfoRTv+3y/HaKYOHtxhBHzX/yM4rCAMECbkMRzrG0Pt7ULS+HLYvh6O/a2qZjJwNh9aZAcpHZ5pUSoBUW9CjzfaIPfQCCAoxa20mjIHVDxqRH7XgyM4rCAME8dCHG45Wk6YYmWA8XxXsPw+9sRpW3mum27tTthecLTDeKkE7ZqGpLbPrPSPmsy6FxXe5wiD2EmZHOlu0usCEeIJD4dw/QNUh0z5aBF0YGoigDzds8Y5MNBNdIuL9F0Pftwq++LNZjNidWnvNTaveSeax4Ggy0/Ijk+BbT8Ipv3T1720M3dFqzvV5h7XLawpcufcTTzGTgMLjXEu0CcIgR0Iuww172r89IBoR7z8PvSrPbGuK2rfXdBB0ezHjsj1w1OWdV+5pE/QeeOgtjfDyxWZZt7AYOPZms0AymEHRtOmuvuf9EU75BYRG9PwzCcIARjz04YbtjUcmmm1EvP9i6FXWikO2R25TW2QWd7An88SMgMRx5vWUMzufpy2G3gNBP/iZEfMJp5j+7jNCawrbLzwRHOK5KqIgDFJE0IcbtoduD4hGJvjPQ6/25qEXGjF398THHmdWpJ/gocZJb0IupXvM9uR7zTb3S5cNzbXtF24WhCGGCPpww/bG3T10X8XQV/wYNr7keu/NQ68p6uwZn3QvXPNW+7rkNuEdQi45H0LhZs82lO42nyljnlmgIvdLkxa5/A5Tv2bS6b3+WIIwWBBBH27Y4t0WQ0/wjYdeXQBfPWXW2LRpi6F3DLkchpgOgh4/yqxQ74ngMJNuaGe5vH07vHJF5+wZMIKeMtkM+I5ZaAR97SOwZyWc/hsYMa1vn08QBgEi6MONjiGXrgZFm+t7Xj9lxztma6cCtja7CmF1FPSaIohN67HJKGUtclFjpv/XFJpwztpHOvctyzGCDpC50GS2fHQ/zLwIjrmx59cUhEGICPpwo6HSiKO94ntkgplm39LYud//TWrvcduU7ukcz97+ttlWHnKtq4k2oZ3aIteDwdEKdSWdPfTuiBtlHha21x+dCp/9sf3DorHaXDd5onmfdQKgYMo58K2nzINBEIYwIujDjYYKV7gFvE//L8sxMeucD9u3VxfAE8fDyp+52mqLTa559AhobYD6MpfwjppvHhh2qKeuBNC989ABksebCUkVB837JXebhZb3r3Gz2RoQtT30tOlw2zq49AXXA0wQhjAi6MMNe9q/jbcCXZWWcB76qn37F4+bSUCbXnWFbza9YopdHXOTdWwuVFsDonadFDvTxR4g7a2HnjQBKg5A+T7zfspZZlLQQbdJS6UdBB1M+QARc2GY0K2gK6WeVUoVK6W2etmvlFJ/UkrlKKU2K6WkDulAxi6da9Mm6B08dNsTLttjaq+A2a5/ztQ+aW2Ab142x6191KQbTj7D9HMPjdiCbgu5Ley9zf9OnmDKBRz8zKQ3xo2CzGMg9wtXn9LdZvA0aVzvzi0IQ4SeeOjPAx5me7RxFjDJ+rkJeOLIzRL8RkdBbyvQVdG+n/siynlfm232y9BSB+c/BmMWwZd/gbduNcee+iuzwhCYOHp1vnlYJE0wbXasu+O0/55in2f/anOdoGBjQ8lO86DRGgq+MeukikcuDFO6FXSt9RqgvIsuy4AXteFLIEEpJbM3Bir1ZRCV7HpvF8Cq7/ArrjwIqVNN8S477JK/wQhm2nQ4+efgbIWd78BRl5mKiREJEBbr8tDjR7ti5TUdPPToEb2zO9kS9IYKUykRzGQkcKUm7v0YZlzYu/MKwhDCF7VcRgGH3N7nWW2FHTsqpW7CePGMGTPGB5cWeoXWRrjbCbr1ur6sfd/KXFO0KiQc8ixBL9rmKmSVdQLctcsMkkanmDaljPdcmWtqmqfPgvBYk1VT6xZDj0o2qxT1hpg0a23RWkgYa9oy5pkc9eW3G/tnXQIn/rR35xWEIUS/DopqrZ/WWi/QWi9ITe2nRXkFF41VZk3NSLfVecLjTNzZXdCdTiPKCWNMJcS8DSYHvCwHRrgVt1LKTAgKCXe1xWfC3lVm1aHp55u2mDTX4hLVbhUPe4NSZmUhcHnooREw7TzzgDjtflj2FwiScX5h+OILDz0fyHR7P9pqEwYaDVZYxd1DV8q8dxf02sMmJTBxrAmNfPU0ZFuZLO7VCj0RP9oMmIbFGrEFiMswQg4mEyW9j+VqkyfA4c0uDx3g4mf7di5BGIL4wp1ZDlxjZbssBKq01p3CLcIAoN6DoNvv3QXdHhBNGOuanLPOGuvurna4PTA64wJXlcSUSVC8E1qbTOqhe1phb7AHRhPHdt1PEIYp3XroSqlXgBOBFKVUHvArIBRAa/0ksAI4G8gB6oHr/WWscIS0CXqHBZGjktsPitopiwljTd+RR0HhJgiJcIU9vGGvAzr3alfbiOnQ9KxJOdSOvgv62EWwPtG1eLQgCO3oVtC11ld0s18Dt/nMIsF/2F54J0FPguIdrvdtHrrlbY9bagQ9dUrnxSc6MvlMuHUdjJjqarPj7tveMlt7an5vmXgq/ORA344VhGGAjCANJ+wYeqQnD90t5FJxwMTOQyPN+/FLzbYnS7UFBbUXc3DF3XdaBbzEwxYEvyCCPpRpaWhfi6W+zOSV2/VbbKKSTX6302Hel+5uL7pjFhmBz1rcNzsiE81KQfVlZhse27fzCILQJYNO0LXWVNW34HD2sKzrcGb9c/D3i6Bkl3lfX2bCKx2rDkalmAyWxiqTq166q32cOywafrQb5nQZfesauw65eOeC4DcGnaAv31TA7Ps/4EBZD1eAH87YdU7sZdg6TiqycZ9cVFdihD11Svs+R1p61g67iKALgt8YdIKeGmsmsRRXNwXYkgGO1q4aLPZMT6+Cbk//L3N5833NRPHGiBn+Oa8gCG0MOkEfERsBQHFNYzc9hzlVedbsTAWHLGFvKG9fOtfG3UMvtQS9o4d+pIxZaKbuj1no2/MKgtDGoBP0tDjjoRdVi6B3ie2VTz3HiHRDRefCXDbugl6y2whv3Cjf2pM0Dn6Wb4p4CYLgFwadoMeEhxAVFkzRcA25NFTAU0vhwNqu+x36GkIiYYE1zytvgxVySerc1xb0ulJrQHSSLNcmCIOQQSfoSinS4iKGr4e+4QUozIZd73Xd79A6yJhrFkpWQbD3I7NAhCcPPSzKiL/toaf4ONwiCEK/MOgEHWBEbPjwHBR1tJhCWWCKVHlj+3Io2AiTToXwGBh9jFldCDwLut1ecQBqCiBVBi4FYTAyKAU9LS6CouE4KLrjP2YloMQsKNxsMlk6UpVn6oNnzIVFd5i2pXdDk7XEXMdZojZRSbDzXfN67PE+N10QBP8zSAU9nKLqRrQnQestxTvhrdvg7dtNnHkgs+F5UzBr0e1mUeeqQ537rHsKmutNWVl7EYkJp8AYa3Ufbx56dAqg4eRfSCaKIAxSfFEPvd9Ji4ugscVJTVMrcRFHsH5kSyO8djVU5Zs488534ea1ZtGGgULZXmiqNotC7F8DS39svG8wXnpCh5Wfcj40VQndqyIqBWf8Bt6/x3s4Ze5VJt6++C7/fA5BEPzOoBR01+SixiMT9NW/M3VLrnoD4sfA0yfCmzfCtf/pvqpgf+B0wMuXmHzyuVcDGmZebBaRUEEmjj7tXGisNgOawaFQvB1O+3Xnc42aB9/9wPu1Zl7kt48hCEL/MCgFPS3OTC4qqm5i4og+Fnra9has/QPMucqUZQU4+yF4+zbI/gfMu7qro/uHHcuhfK8R76+eMjnctoedMhn2fQINlZD9slk8wrZ50umBslgQhAAySGPotqD3cWA090vjiWceA2c/7Gqfc6XJCPn412YNzUCiNXz6e1M7/KyHTNusS1z7048yqYnrnzWTh6JTzev4TN/P8hQEYVAwKD30EbH2bNE+pC42VsMbN5qZkFf80+Rg2ygFZ/4WnjkFPv8znBTAFeQ3PAeHt8Cyx2H2t429E0527V/8Q+Oxz7oEYtNMfP2F8413LpOCBGFYMigFPTo8hNjwkL556Ct/BtV5cP37nmdNjl4Ak88ygrrkbggOwC3KWw8rfmxCQbOvMItGTD27fZ8R01wlaQHGLYHvrJRqhoIwjBmUIReAEXHhfL63lP2lPSyjqzV88Av45iU4/k4Yc6z3vvOuhtqi9otD9BeOFvj39yBuJFz4194Nzo451vNDShCEYcGgFfQfnDqZgspGzvjDGrIPVXrv2NoMu96H58+Bz/8ER99gcq27YtLpJib9zUs+tbkTq34Lqx8yNtpsfAHKcuCsh0WcBUHoFYMv5OJ0wK4VnDf7PI4dl8S5j63lF29t5a3bjic4SBlPvHiHiSnbP801Zumzc34PC77bfYw5OBRmXw5fPgG1JRCT6vvPUZkLqx8EtMlmufwfpsrhJ78zMzUnn+H7awqCMKQZfIL+zUvwnzvhlF8yYvFd/Oq0Ubz/1t/59NnlTI9rIjXvQ1R1numbMBZmXghTzjKzJe2Zkz1hzlXw+WOw+VU47vb2+2qKzEDkkbDpn4CGs//PZNU8c5p5kDRUwOm/loFNQRB6jfLJ9Pk+sGDBAr1+/freH+h0wL9vhi2vQcoUdFkOSpvFjZt1MJvD5xN11AUkzDyVjKwjTN975lSTvnjrly6B3fI6vPFdOP8xmHdN786ntTmP1vCnOSbF8Lp3oGg7vHyxEfSLnoXR84/MbkEQhixKqQ1a6wWe9g0+Dz0oGC54wtQkKd2Fmr4M54RTyYuczKf7qnj0wz2Urm2GtTl853gHPz9nGkFBffR2515lvg3kbzQiW1cK7/3Y7Pvvr2DquT2Pc69+GDa+CDd+DCU7TWXDpfeYfWnT4Y4NoIJ79y1CEATBjcHnoXdDfXMr2wqqeTs7n79/mcu5R43k/mUzSYrug1A2VsP/TTbT6y/8K7x6FexeCd96Et68yUzoOe+PnUXd6YSiLaYqYkQ8fPN3MwMV4NhbIH+DEfQ7syEs+gg/sSAIw4mh5aF3Q1RYCEdnJbFgbCIj4yN59L+7WZtTyo/PmMrlR2f2zluPiINFt5oZm7VFZoD19Adg1sVQvh9W/Qb2fmyEOzrVTMdvroODn0HFfgiNNvuKt0HWYojLgHVPmHMve1zEXBAEnzLkPPSO7C6q4edvbeWr/eWMSogkLS6c2qZWkqLDeOyKeW2FvrzidMA/vw273zeFsS56xhVPL9puaqzUlpg65WU5EB5rpt5Pv8BMECrbY46bexXUlcBj8yF9FtzwkZkwJAiC0Au68tCHvKADaK15O7uAD7YfpqqhhZjwENbsLmVschRXLhyLw+HkimPHEB7iZRJPU40p5jXrYgiNPDJj8jeawVB/pEIKgjDkGfaC7olP95Tw3efX0+xwAjBzVBx/+fZ8xiRHdXOkIAhC4BBB90JxTSOtDs22gmp+9K9NhIcE8dgVc1mbU8q8sYmcNGVEQO0TBEHoSFeC3qMgrlLqTKXULqVUjlLqHg/7r1NKlSilsq2fG47U6P5gRGwEGQmRnDY9jX/dvAinhsue/pLHPs7hrtc2Ud3YEmgTBUEQeky3WS5KqWDgceA0IA/4Wim1XGu9vUPXV7XWt3c6wSBhclosr31vIW9szGP6yHhu+8dGHv3vbsalRBMTHsL5szMICZZBTEEQBi49SVs8BsjRWu8DUEr9E1gGdBT0Qc/41BjuPmMqAB9sz+C5zw607Xt8VQ7XHpfFBXNHHdmyd4IgCH6iJy7nKMB9efk8q60jFymlNiulXldKZXo6kVLqJqXUeqXU+pKSkj6Y23/ce840vrd0PMtvP54nr5pPRGgwv3x7Gyf/3yes2FJIbVMrgRp/EARB8ES3g6JKqYuBM7XWN1jvrwaOdQ+vKKWSgVqtdZNS6nvAZVrrkz2f0TAQBkV7yze5Ffz8ra1sK6gGICk6jNmj40mJCWfumESuOCYTJUW1BEHwI0c6UzQfcPe4R1ttbWity9zePgM81FsjBwNzxyTy1m3H88G2IvIq6skprmVLfhVbC6r514Y8csvrSYkJo77Zwe0nTex7DRlBEIQ+0BNB/xqYpJQahxHyy4Fvu3dQSo3UWhdab88HdvjUygFEaHAQ5xw1sl2b06n56ZtbeHL13ra2uuZWfnrWNGqbWvnX+kOMiI3g5KkjKKtrIj0uQgZYBUHwOd0Kuta6VSl1O7ASCAae1VpvU0rdD6zXWi8Hvq+UOh9oBcqB6/xo84AjKEjx2wtnccy4JKaNjOOVr3J5avU+Vu8qobS2idLa5nb9p6bH8uRV88lKiUZrTU1Tqwy0CoJwxAzriUX+wuHU/GVVDt8cqiRIwS0nTqSmsYVvciuJCQ/h8U9yaGxxsHB8Mrnl9eSW1fPGLccxOzMh0KYLgjDAkZmiA4y8inqeWr2Pz/eWkhwdzp7iGqZnxPHyDQsDbZogCAOcYVU+dzAwOjGKX18ws+39s2v3c/8721m7p5QTJqUE0DJBEAYzMjI3ALhy4RhGJURy9+ub2HW4hj9+uIc/fbSH5lZTOExrzaHyehxOjdaanYeraWh2tB3/2teHuPXlDTS2OLxdQhCEYYB46AOA8JBg/nrNAq585kvO+MOatvYVWwo5aeoI1h8o5+sDFUwaEUNSdBjr9pczMj6C754wjqqGFh77OAeAzMTd/PTsaYH6GIIgBBiJoQ8gdh6u5k8f7eGqY8dS29TKQyt3cbCsjqToMC47egzvbCqgvL6ZG04Yx/vbDrM130xwOm16GolRofxrQx7fOX4c6XERLMhKZPboBMmFF4QhhgyKDmIcTo3CpEbavyulzOui6iYaWhxkJUdR1+zg6r+tY1t+dVuN9yWTU/nNBTP5xdtbKa1t4uisJK5dlEVWiix9JwiDFRH0YUZpbRNvfZPPb1bsIEgpwoKDmJ0Zz8bcShxOzZzMBMYmR3Hv2dOIDAvmuc8O0NTq5PgJyRw7PjnQ5guC0AWS5TLMSIkJ54bF40mOCeO5zw7wwAUzOWp0AsU1jTzz6X4251XyzqZCqupbiI8M5c1vTCWHJz/Zy79uXsTB8no2H6rk5GkjWDQ+WerTCMIgQTz0YYqdKglw5ymTuO64LM59bC0V9c3UNzsIUuDUsGxOBv93yWxCO5QqOFRez7r95Sybk0FocBA1jS28nV3A9Iw45mYm8OD7u4iNCOHWEyfIA0EQfIh46EInrjsuiw25FbS0Ovn+KZMIDlL85cp5fOf5r7n2uCxuO2kif/t0P49+uJv8igaOn5jC4kkpTEqL5b0thTzw7g5qm1p5/vP9ZCVHs2pnMXXNDmLDQ7j2uKy2ujYhQYobF49vNzjrdGpW7ylhwdhEYqXkgSD4DPHQhXZordt51C+vO8hf1+zjYHk97n8q88cmcumC0Ty8cjdKwclTRnDGzDR+/PpmSmubWTg+ieSYcN7dXEhIkGJMchSzRyfwnePH8e9v8nn2s/1kxEfwu4uOYsnk1B7ZVlLTxPoD5ZwxI12yd4RhiwyKCkdMTWMLH+0o5kBZHcdNSGH+2ESCrcwbrWkT2G9yK3h81V5+fcEMkqLDeOubfA6UmVLDX+0vp6rBrNN6wZwMthZUk1Ncy2ULMvnledOJDjdfGB1OTW1TK3ERITz32QHe2VzAhNQYVm47THVjKxfOHcWMUfGs3HqYn50zjTlSA0cYRoigCwOC6sYWnvzEhGJ+dPoUmh1O/vjRHp5avZezZo7k95fO5tH/7uaNjfmU1poyw4erG5mcFkNBZSNHjY5n1uh4nlq9D4DosGBanJr7zpshi4sIwwYRdGFA88Qne3nw/Z2MSYoit7yeM2ekM21kHFvyK1kyOZWrF44FaBPsldsOEx0WwoyMOO545RvW5pSyeFIKt5w4gRGxEew8XM0JE1NIiAqjscVBfmUDWkNWchQhwUFordlbUkdKTBgJUWFd2qa1Jr+ygdGJUX6/D4LQE0TQhQGN06m59rmvWLevnN9fOpvzZmf06tiX1x3koZW7qGlsbWuPDgtmfGoM2wqqcFp/4uEhQUxNj6WxxcmuohqUgpkZ8Rw3MZnzjspg5qj4Tud/4J3tPLN2P89ddzQnTR1BdWMLoUFBfJNbwX82F1Be18zRWUncsHi8Vxvf31rIk6v3kZkUxUlTUjnnqJGEhwT3/AYJghsi6MKAp6nVQUVdC+nxEX06vqHZwQfbD9PQ7CArJZpXvsrlcFUjR2clMWFENE4n7CisZnthNa0OzTlHjaSyvoXPckr55lAFLQ5NVnIUTg3HjkvixiXj+WhHMQ++v5PQYEVmUhSXLsjkwfd3tg0Ox0aEEBUWTElNEx/ddSLjPMzALatt4pRHVhNhCfjh6kZSYsK5eel49pbU8dX+Mq5ZlMW3jx3Tlhq6t6SWl744yB0nTyQ5JrxvN9QDTa0OPtlVws7CGr63dDwRofJQGYyIoAtCF1Q1tPDmxjy+2FtGcJDiox3FbeUTlk5O5aqFY7nxRfO3euq0NOaNTSAjPpIzZ6ZT09jK4oc+5pxZGdx3/nTW7Stna0EVDS0OwoKD2JRXxec5pay4czGTRsTwWU4Zf/kkh8/3lhEarJicFsu2gmqOm5DMs9cdzWc5pfzg1WxqGls5fXoaT109v9uxgVaHk9//dzfnzBrZ9i3DvUxEq8PJP78+xB8/2kNJTRMAPz9nWpffKoSBiwi6IPSCg2V1rN5dwsxR8cwenUBwkOKnb25GKcX958/otB7sr9/ZznOf7ScsJIjGFidKQVhwEC0OJ04N3z95Ij88fUq7Y7bmV5EUHcbI+Aj+tT6Pn7y5mYz4SPIrG5g2Mo7Fk1J4es0+rj8+i8zEKIIURIWHEB8ZyoaDFUSEBHHrSROJCA3mmU/38cC7OxiTFMXfrl3A9/6+gX0ldcRFhHDD4vGs2lXMN7mVHJ2VyG0nTeTpNfvYXVTDf+44gezcSo6bkEJ4aBBf7S8nISqUyWmx3XrvWms+3FHM1PRYMpMCP77Q6nASpNSwSGcVQRcEP1Jc08iNL25g+sg4zp+dwezMeKLCQnA4NVUNLSRGhXbrZb/yVS6/XbGDGxaP53tLxxMSFMR3nv+a1btLOvUNDVa0ODTTR8Zx+TGZ/HbFTrJSotlRWE1YcBARoUFcd1wWW/KrWLWrhLiIEH59wUzOn52BUooNByu46InPCQ5SOJya6LBgwkKCqKg3KaUjYsN59LI5tDicOJyak6aMaCeUdU2t/Pytrfz7m3wSo0K5eekE/vFVLvPGJHLf+TP4+5cHGZUQybI5GeRXNlBplZhYtauYHYU1lNc1UVHXQmpcON85Pov5Y5PQWvPe1sPMGhXv8QFR39xKQWUD41NiOol2ZX0zlz31JTWNLXxr3ii+3l9Bamw4D1wwk8RoM+hd1dDCo//dTVldM7+7cBb7SurYV1rLsjmjKK5pZHtBNSdOGdHr331v0FrT1Oo84lCXCLogDAI6TurSWlPd2AoanFpT3dhCWV0zU9JiWbe/rG0SV3RYMB/8cCl/XbOPf60/xIvfPYb5Y5MAyD5USUZCBCNi249N/PytLRRXN3HpgkxWbC2kudXJhfNG0dji5OGVu9hfWtfWd9aoeC6cN4rkmHDW7StjeXYBtc2t3LR4PB9sL2J/aR1ZyVEcKKsnLCSobWGW2aPj2ZLvGpQGSI4OI9nKLtp1uIaqhhbuPXsaMREh/PTNLYQGKy6cO5oL5o4iNiKEHYXVrNxWxKd7SmhqdZIcHcbRWUlMHBEDQGRYMB/uKGJbfjXTM+LIPlTJhNRoDpU3kBgdyujEKKoaWjhc1Uh9sxk0H58aw8GyOlocmttOmsA7mws5WFbPHSdP5IenTe7y4dvU6iBIKUKDg2hqdaA1XgV6T1ENY5OjCQsJ4pNdxTz4/i6Kqhv5+K6l3WZXdYUIuiAMQZxOTV5FA0pBZlIUWmvqmx1tE7T6Sk1jC69+fYjxqdFU1psFVGyBjwgN4owZ6Vx//DjmZCZQVd/CxkMVLJmUyntbC3npi4PcfvJENh6s5IUvDnDRvFHMHZNISU0Tx01IZlJabNt16ptb+dG/NvHe1sOEhwQxJzOBiSNieH1DHo0tzrZ+GfERnD4jnanpsXy5r4zsQ5UcKKtvqzcUEqT44+VzOXtWOuV1zSRFh7E5r4oH398JQHxkKEnRYVxxzBgOlddz5z+zWTolldBgxYoth4kOC+aESSms3FbEWTPTueesqYxJiuok7DnFNVz77NfERoTwyKVzuO0fGwkLDuKt244nMswl6g6n5qH3d/LUmn3MH5vIgqxEnlq9j1EJJqR212mTueOUSX3+/YigC4JwRORXNlBR18yU9NhOhdqOhIZmB5c+9QW55fW8/4PFjIyPpK6plU/3lACKzKRIpo+M6ySuTqcmKEhR39xKq1MT14uaQHVNrUSFBZuJbR/u4dTpacwZncBfPsnhz6tyaGxxEh0WzKjESEYnRjEqIZLaplY+2lFEWEgQtU2tNLY4iQwNpqHFwcXzRxMVFsyW/CqClGJfSS0V9S2cPj2NNXtKaGxxcsn80fzmW7O46aX1bMmr4rN7Tu5z6EUEXRCEAUtji4PaplZSfJii2VcKqxp4d3MheRUN5Fc2kG9to8KCmZERz6/Om86hinoefH8XvzhnGiu2HObZz/YTEqQ4OisJjWZsUjRLp6Ry9qyR7Dxcza7DNW3jF+v2lXHZ01/y62UzuHpRVp9slGqLgiAMWCJCgwdMTvzI+Mhu0zkzk6J4+7YUAGaOimdschQnTRnBmOTOg7lT0+OYmh7X9v6YcUmcPzvjiGLoXSEeuiAIwiCiKw/dd8EwQRAEIaCIoAuCIAwRRNAFQRCGCCLogiAIQ4QeCbpS6kyl1C6lVI5S6h4P+8OVUq9a+9cppbJ8bqkgCILQJd0KulIqGHgcOAuYDlyhlJreodt3gQqt9UTgUeBBXxsqCIIgdE1PPPRjgByt9T6tdTPwT2BZhz7LgBes168DpyhZD0wQBKFf6YmgjwIOub3Ps9o89tFatwJVQLIvDBQEQRB6Rr/OFFVK3QTcZL2tVUrt6uOpUoBS31jlcwaqbWJX7xiodsHAtU3s6h19tWustx09EfR8INPt/WirzVOfPKVUCBAPlHU8kdb6aeDpHlyzS5RS673NlAo0A9U2sat3DFS7YODaJnb1Dn/Y1ZOQy9fAJKXUOKVUGHA5sLxDn+XAtdbri4GPdaBqCgiCIAxTuvXQtdatSqnbgZVAMPCs1nqbUup+YL3WejnwN+AlpVQOUI4RfUEQBKEf6VEMXWu9AljRoe2Xbq8bgUt8a1qXHHHYxo8MVNvErt4xUO2CgWub2NU7fG5XwKotCoIgCL5Fpv4LgiAMEUTQBUEQhgiDTtC7qyvTj3ZkKqVWKaW2K6W2KaXutNrvU0rlK6WyrZ+zA2DbAaXUFuv66622JKXUf5VSe6xtYgDsmuJ2X7KVUtVKqR8E4p4ppZ5VShUrpba6tXm8R8rwJ+tvbrNSal4/2/WwUmqnde1/K6USrPYspVSD2317sp/t8vp7U0r91Lpfu5RSZ/jLri5se9XNrgNKqWyrvT/vmTeN8N/fmdZ60Pxgsmz2AuOBMGATMD1AtowE5lmvY4HdmFo39wE/CvB9OgCkdGh7CLjHen0P8OAA+F0exkyS6Pd7BiwB5gFbu7tHwNnAe4ACFgLr+tmu04EQ6/WDbnZlufcLwP3y+Huz/g82AeHAOOt/Nrg/beuw//fALwNwz7xphN/+zgabh96TujL9gta6UGu90XpdA+ygc0mEgYR7vZ0XgAsCZwoApwB7tdYHA3FxrfUaTIqtO97u0TLgRW34EkhQSo3sL7u01h9oU1ID4EvM5L5+xcv98sYy4J9a6yat9X4gB/O/2++2WTWlLgVe8df1vdGFRvjt72ywCXpP6sr0O8qUC54LrLOabre+Mj0biNAGoIEPlFIblCm3AJCmtS60Xh8G0gJglzuX0/6fLND3DLzfo4H0d/cdjBdnM04p9Y1SarVSanEA7PH0extI92sxUKS13uPW1u/3rING+O3vbLAJ+oBDKRUDvAH8QGtdDTwBTADmAIWYr3v9zQla63mYkse3KaWWuO/U5vtdwPJVlZlxfD7wL6tpINyzdgT6HnlCKXUv0Aq8bDUVAmO01nOBHwL/UErFeTveDwy435sHrqC949Dv98yDRrTh67+zwSboPakr028opUIxv6iXtdZvAmiti7TWDq21E/grfvyq6Q2tdb61LQb+bdlQZH99s7bF/W2XG2cBG7XWRTAw7pmFt3sU8L87pdR1wLnAlZYIYIU0yqzXGzCx6sn9ZVMXv7eA3y8AZepKXQi8arf19z3zpBH48e9ssAl6T+rK9AtWbO5vwA6t9SNu7e4xr28BWzse62e7opVSsfZrzIDaVtrX27kWeLs/7epAO68p0PfMDW/3aDlwjZWFsBCocvvK7HeUUmcCPwbO11rXu7WnKrMADUqp8cAkYF8/2uXt97YcuFyZlczGWXZ91V92uXEqsFNrnWc39Oc986YR+PPvrD9Ge335gxkJ3o15st4bQDtOwHxV2gxkWz9nAy8BW6z25cDIfrZrPCbDYBOwzb5HmPr0HwF7gA+BpADdt2hMJc54t7Z+v2eYB0oh0IKJVX7X2z3CZB08bv3NbQEW9LNdOZjYqv139qTV9yLrd5wNbATO62e7vP7egHut+7ULOKu/f5dW+/PAzR369uc986YRfvs7k6n/giAIQ4TBFnIRBEEQvCCCLgiCMEQQQRcEQRgiiKALgiAMEUTQBUEQhggi6IIgCEMEEXRBEIQhwv8HkdA8VpgswTIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history2.history)\n",
    "history_df.to_csv(\"BackProphistory_df.csv\")\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 1s 107ms/step - loss: 0.7145 - accuracy: 0.5470 - val_loss: 0.6554 - val_accuracy: 0.6479\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7006 - accuracy: 0.6120 - val_loss: 0.6582 - val_accuracy: 0.6406\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6362 - accuracy: 0.6198 - val_loss: 0.6631 - val_accuracy: 0.6479\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6404 - accuracy: 0.6319 - val_loss: 0.6482 - val_accuracy: 0.6479\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6309 - accuracy: 0.6189 - val_loss: 0.6311 - val_accuracy: 0.6479\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6159 - accuracy: 0.6358 - val_loss: 0.6147 - val_accuracy: 0.6675\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.5995 - accuracy: 0.6496 - val_loss: 0.5951 - val_accuracy: 0.6822\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.5942 - accuracy: 0.6522 - val_loss: 0.5876 - val_accuracy: 0.6797\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5803 - accuracy: 0.6812 - val_loss: 0.5796 - val_accuracy: 0.6870\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5771 - accuracy: 0.6837 - val_loss: 0.5724 - val_accuracy: 0.6993\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5773 - accuracy: 0.6817 - val_loss: 0.5772 - val_accuracy: 0.6993\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5652 - accuracy: 0.6637 - val_loss: 0.5839 - val_accuracy: 0.6944\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5524 - accuracy: 0.6940 - val_loss: 0.5823 - val_accuracy: 0.6822\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.5611 - accuracy: 0.6874 - val_loss: 0.5763 - val_accuracy: 0.6895\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5239 - accuracy: 0.6921 - val_loss: 0.5887 - val_accuracy: 0.6748\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5162 - accuracy: 0.7250 - val_loss: 0.6051 - val_accuracy: 0.6724\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.5348 - accuracy: 0.7130 - val_loss: 0.6378 - val_accuracy: 0.6528\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.4884 - accuracy: 0.7346 - val_loss: 0.6847 - val_accuracy: 0.6455\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.4904 - accuracy: 0.7347 - val_loss: 0.7273 - val_accuracy: 0.6479\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4850 - accuracy: 0.7557 - val_loss: 0.7358 - val_accuracy: 0.6479\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4687 - accuracy: 0.7597 - val_loss: 0.7681 - val_accuracy: 0.6479\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.4736 - accuracy: 0.7558 - val_loss: 0.7883 - val_accuracy: 0.6479\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4496 - accuracy: 0.7641 - val_loss: 0.7865 - val_accuracy: 0.6479\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4597 - accuracy: 0.7438 - val_loss: 0.7549 - val_accuracy: 0.6504\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4701 - accuracy: 0.7394 - val_loss: 0.7685 - val_accuracy: 0.6504\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.4500 - accuracy: 0.7428 - val_loss: 0.8149 - val_accuracy: 0.6528\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4238 - accuracy: 0.7863 - val_loss: 0.7831 - val_accuracy: 0.6504\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.4455 - accuracy: 0.7569 - val_loss: 0.7515 - val_accuracy: 0.6650\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.4280 - accuracy: 0.7688 - val_loss: 0.7753 - val_accuracy: 0.6577\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4071 - accuracy: 0.7970 - val_loss: 0.7132 - val_accuracy: 0.6675\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.3971 - accuracy: 0.7938 - val_loss: 0.6860 - val_accuracy: 0.6675\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.4001 - accuracy: 0.8002 - val_loss: 0.7525 - val_accuracy: 0.6601\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.3856 - accuracy: 0.7953 - val_loss: 0.9604 - val_accuracy: 0.6455\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3893 - accuracy: 0.8088 - val_loss: 1.0815 - val_accuracy: 0.6479\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3986 - accuracy: 0.7866 - val_loss: 1.1157 - val_accuracy: 0.6455\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3780 - accuracy: 0.8073 - val_loss: 1.1655 - val_accuracy: 0.6479\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3875 - accuracy: 0.7924 - val_loss: 1.0850 - val_accuracy: 0.6455\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 94ms/step - loss: 0.4083 - accuracy: 0.8021 - val_loss: 1.0766 - val_accuracy: 0.6504\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3714 - accuracy: 0.8119 - val_loss: 1.2872 - val_accuracy: 0.6479\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3642 - accuracy: 0.8202 - val_loss: 1.3754 - val_accuracy: 0.6479\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3926 - accuracy: 0.8007 - val_loss: 1.3451 - val_accuracy: 0.6479\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.3555 - accuracy: 0.8165 - val_loss: 1.1592 - val_accuracy: 0.6553\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3427 - accuracy: 0.8191 - val_loss: 0.9831 - val_accuracy: 0.6553\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3533 - accuracy: 0.7999 - val_loss: 1.0108 - val_accuracy: 0.6601\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3654 - accuracy: 0.8189 - val_loss: 0.9521 - val_accuracy: 0.6601\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3283 - accuracy: 0.8469 - val_loss: 1.3157 - val_accuracy: 0.6577\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3201 - accuracy: 0.8352 - val_loss: 1.3868 - val_accuracy: 0.6553\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.3314 - accuracy: 0.8136 - val_loss: 1.0475 - val_accuracy: 0.6650\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3250 - accuracy: 0.8227 - val_loss: 0.9401 - val_accuracy: 0.6675\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.3467 - accuracy: 0.8254 - val_loss: 1.0419 - val_accuracy: 0.6650\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3048 - accuracy: 0.8369 - val_loss: 1.1830 - val_accuracy: 0.6626\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.3203 - accuracy: 0.8229 - val_loss: 1.0120 - val_accuracy: 0.6748\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2857 - accuracy: 0.8554 - val_loss: 0.9469 - val_accuracy: 0.6773\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2988 - accuracy: 0.8400 - val_loss: 0.9032 - val_accuracy: 0.6675\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2921 - accuracy: 0.8535 - val_loss: 1.1580 - val_accuracy: 0.6748\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3117 - accuracy: 0.8407 - val_loss: 1.2468 - val_accuracy: 0.6601\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2931 - accuracy: 0.8498 - val_loss: 1.2294 - val_accuracy: 0.6601\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.3121 - accuracy: 0.8510 - val_loss: 1.2958 - val_accuracy: 0.6577\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.2987 - accuracy: 0.8634 - val_loss: 1.1722 - val_accuracy: 0.6553\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2998 - accuracy: 0.8420 - val_loss: 1.0104 - val_accuracy: 0.6650\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2974 - accuracy: 0.8419 - val_loss: 1.0795 - val_accuracy: 0.6748\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2902 - accuracy: 0.8631 - val_loss: 1.2551 - val_accuracy: 0.6724\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2892 - accuracy: 0.8624 - val_loss: 1.5190 - val_accuracy: 0.6504\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.3010 - accuracy: 0.8436 - val_loss: 1.5262 - val_accuracy: 0.6455\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2749 - accuracy: 0.8585 - val_loss: 1.4223 - val_accuracy: 0.6601\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2718 - accuracy: 0.8676 - val_loss: 1.3084 - val_accuracy: 0.6601\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2664 - accuracy: 0.8675 - val_loss: 1.5303 - val_accuracy: 0.6626\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2497 - accuracy: 0.8771 - val_loss: 1.8267 - val_accuracy: 0.6577\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2542 - accuracy: 0.8886 - val_loss: 1.6727 - val_accuracy: 0.6650\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2681 - accuracy: 0.8549 - val_loss: 1.7788 - val_accuracy: 0.6650\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2775 - accuracy: 0.8708 - val_loss: 1.5062 - val_accuracy: 0.6724\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2532 - accuracy: 0.8730 - val_loss: 1.6077 - val_accuracy: 0.6528\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2838 - accuracy: 0.8602 - val_loss: 1.7832 - val_accuracy: 0.6504\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2884 - accuracy: 0.8614 - val_loss: 1.2157 - val_accuracy: 0.6553\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2850 - accuracy: 0.8488 - val_loss: 1.1538 - val_accuracy: 0.6626\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2593 - accuracy: 0.8683 - val_loss: 1.5645 - val_accuracy: 0.6601\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2624 - accuracy: 0.8673 - val_loss: 1.6206 - val_accuracy: 0.6626\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2399 - accuracy: 0.8730 - val_loss: 1.6776 - val_accuracy: 0.6577\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2345 - accuracy: 0.8586 - val_loss: 1.9590 - val_accuracy: 0.6601\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2555 - accuracy: 0.8707 - val_loss: 1.9204 - val_accuracy: 0.6601\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2312 - accuracy: 0.8734 - val_loss: 1.7080 - val_accuracy: 0.6675\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2555 - accuracy: 0.8663 - val_loss: 2.1406 - val_accuracy: 0.6601\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2147 - accuracy: 0.8871 - val_loss: 2.2635 - val_accuracy: 0.6626\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2316 - accuracy: 0.8888 - val_loss: 1.9435 - val_accuracy: 0.6626\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2241 - accuracy: 0.8825 - val_loss: 1.9009 - val_accuracy: 0.6601\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2364 - accuracy: 0.8881 - val_loss: 1.9109 - val_accuracy: 0.6626\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.2052 - accuracy: 0.8954 - val_loss: 1.7464 - val_accuracy: 0.6724\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2200 - accuracy: 0.9002 - val_loss: 1.6733 - val_accuracy: 0.6748\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2313 - accuracy: 0.8804 - val_loss: 1.8446 - val_accuracy: 0.6675\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2233 - accuracy: 0.8817 - val_loss: 1.6703 - val_accuracy: 0.6822\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2415 - accuracy: 0.8848 - val_loss: 1.3703 - val_accuracy: 0.6968\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2092 - accuracy: 0.8905 - val_loss: 1.4934 - val_accuracy: 0.6748\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2310 - accuracy: 0.8816 - val_loss: 1.5411 - val_accuracy: 0.6773\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2367 - accuracy: 0.9016 - val_loss: 1.3407 - val_accuracy: 0.6993\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2137 - accuracy: 0.8956 - val_loss: 1.4909 - val_accuracy: 0.6699\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1988 - accuracy: 0.8968 - val_loss: 1.9506 - val_accuracy: 0.6650\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2020 - accuracy: 0.8925 - val_loss: 1.8030 - val_accuracy: 0.6675\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2163 - accuracy: 0.8926 - val_loss: 1.7406 - val_accuracy: 0.6675\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1936 - accuracy: 0.9015 - val_loss: 2.0307 - val_accuracy: 0.6724\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2126 - accuracy: 0.8845 - val_loss: 1.5775 - val_accuracy: 0.6993\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2166 - accuracy: 0.8923 - val_loss: 1.3253 - val_accuracy: 0.7042\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1917 - accuracy: 0.9063 - val_loss: 1.7009 - val_accuracy: 0.6919\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.2480 - accuracy: 0.8785 - val_loss: 1.6412 - val_accuracy: 0.6724\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2100 - accuracy: 0.9019 - val_loss: 1.3824 - val_accuracy: 0.6773\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2238 - accuracy: 0.8975 - val_loss: 1.2560 - val_accuracy: 0.7066\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.2021 - accuracy: 0.9106 - val_loss: 1.4022 - val_accuracy: 0.6919\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2456 - accuracy: 0.8797 - val_loss: 1.3745 - val_accuracy: 0.6797\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2300 - accuracy: 0.8823 - val_loss: 1.5327 - val_accuracy: 0.6870\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1976 - accuracy: 0.9027 - val_loss: 1.6674 - val_accuracy: 0.6797\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2044 - accuracy: 0.8988 - val_loss: 1.5407 - val_accuracy: 0.6870\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.2090 - accuracy: 0.9008 - val_loss: 1.3676 - val_accuracy: 0.6968\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1892 - accuracy: 0.8968 - val_loss: 1.5067 - val_accuracy: 0.6822\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1996 - accuracy: 0.9089 - val_loss: 1.5953 - val_accuracy: 0.6968\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1757 - accuracy: 0.9144 - val_loss: 1.5087 - val_accuracy: 0.7115\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1767 - accuracy: 0.9186 - val_loss: 1.5116 - val_accuracy: 0.7115\n",
      "Epoch 116/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1918 - accuracy: 0.9092 - val_loss: 1.7056 - val_accuracy: 0.6944\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1900 - accuracy: 0.9094 - val_loss: 1.8155 - val_accuracy: 0.6870\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1568 - accuracy: 0.9265 - val_loss: 1.6591 - val_accuracy: 0.6895\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1759 - accuracy: 0.9129 - val_loss: 1.4171 - val_accuracy: 0.6993\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1709 - accuracy: 0.9089 - val_loss: 1.4206 - val_accuracy: 0.6944\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1708 - accuracy: 0.9054 - val_loss: 1.5697 - val_accuracy: 0.7139\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1655 - accuracy: 0.9119 - val_loss: 1.7777 - val_accuracy: 0.6870\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1678 - accuracy: 0.9073 - val_loss: 1.8175 - val_accuracy: 0.6968\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1778 - accuracy: 0.9116 - val_loss: 1.8083 - val_accuracy: 0.7164\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1910 - accuracy: 0.9050 - val_loss: 1.7022 - val_accuracy: 0.6822\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1695 - accuracy: 0.9142 - val_loss: 1.7935 - val_accuracy: 0.6822\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.2020 - accuracy: 0.9027 - val_loss: 1.8469 - val_accuracy: 0.6870\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1741 - accuracy: 0.9102 - val_loss: 1.7008 - val_accuracy: 0.6675\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1876 - accuracy: 0.9057 - val_loss: 1.6221 - val_accuracy: 0.6650\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1619 - accuracy: 0.9138 - val_loss: 1.7712 - val_accuracy: 0.7017\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1754 - accuracy: 0.9152 - val_loss: 1.8383 - val_accuracy: 0.7042\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1615 - accuracy: 0.9282 - val_loss: 1.8460 - val_accuracy: 0.6822\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1657 - accuracy: 0.9243 - val_loss: 1.8085 - val_accuracy: 0.6822\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1742 - accuracy: 0.9138 - val_loss: 1.9365 - val_accuracy: 0.6919\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1623 - accuracy: 0.9226 - val_loss: 2.0446 - val_accuracy: 0.6919\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1694 - accuracy: 0.9201 - val_loss: 1.8770 - val_accuracy: 0.6846\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.1580 - accuracy: 0.9312 - val_loss: 1.7570 - val_accuracy: 0.6773\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1417 - accuracy: 0.9356 - val_loss: 1.7299 - val_accuracy: 0.6846\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1697 - accuracy: 0.9299 - val_loss: 1.7463 - val_accuracy: 0.6968\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1973 - accuracy: 0.9111 - val_loss: 1.7560 - val_accuracy: 0.6846\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1535 - accuracy: 0.9277 - val_loss: 1.6549 - val_accuracy: 0.6748\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1484 - accuracy: 0.9265 - val_loss: 1.5684 - val_accuracy: 0.6895\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1572 - accuracy: 0.9178 - val_loss: 1.6306 - val_accuracy: 0.6919\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1795 - accuracy: 0.9020 - val_loss: 1.7748 - val_accuracy: 0.6870\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1587 - accuracy: 0.9182 - val_loss: 1.8545 - val_accuracy: 0.6968\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1340 - accuracy: 0.9345 - val_loss: 1.8565 - val_accuracy: 0.6993\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1579 - accuracy: 0.9269 - val_loss: 1.7866 - val_accuracy: 0.6993\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1638 - accuracy: 0.9177 - val_loss: 1.8327 - val_accuracy: 0.6846\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1620 - accuracy: 0.9224 - val_loss: 2.1656 - val_accuracy: 0.6919\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1681 - accuracy: 0.9224 - val_loss: 2.1373 - val_accuracy: 0.6968\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1457 - accuracy: 0.9340 - val_loss: 1.8882 - val_accuracy: 0.6944\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1386 - accuracy: 0.9356 - val_loss: 1.7620 - val_accuracy: 0.7042\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1703 - accuracy: 0.9005 - val_loss: 2.0109 - val_accuracy: 0.7017\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1537 - accuracy: 0.9329 - val_loss: 2.1782 - val_accuracy: 0.6944\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1483 - accuracy: 0.9207 - val_loss: 2.3813 - val_accuracy: 0.6919\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1618 - accuracy: 0.9238 - val_loss: 2.4273 - val_accuracy: 0.6870\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1417 - accuracy: 0.9332 - val_loss: 2.4151 - val_accuracy: 0.6822\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1590 - accuracy: 0.9198 - val_loss: 2.2291 - val_accuracy: 0.6944\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1531 - accuracy: 0.9327 - val_loss: 2.0843 - val_accuracy: 0.6944\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1528 - accuracy: 0.9247 - val_loss: 1.9777 - val_accuracy: 0.6846\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1396 - accuracy: 0.9291 - val_loss: 2.0073 - val_accuracy: 0.6919\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1420 - accuracy: 0.9287 - val_loss: 2.0784 - val_accuracy: 0.7017\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1458 - accuracy: 0.9353 - val_loss: 2.0939 - val_accuracy: 0.7017\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1544 - accuracy: 0.9296 - val_loss: 2.2579 - val_accuracy: 0.7090\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1330 - accuracy: 0.9326 - val_loss: 2.4019 - val_accuracy: 0.7042\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1236 - accuracy: 0.9433 - val_loss: 2.6588 - val_accuracy: 0.6870\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1598 - accuracy: 0.9261 - val_loss: 2.7278 - val_accuracy: 0.6846\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1343 - accuracy: 0.9449 - val_loss: 2.5398 - val_accuracy: 0.6870\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1248 - accuracy: 0.9454 - val_loss: 2.3288 - val_accuracy: 0.6846\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1294 - accuracy: 0.9333 - val_loss: 2.3276 - val_accuracy: 0.7017\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1278 - accuracy: 0.9414 - val_loss: 2.4471 - val_accuracy: 0.6968\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1282 - accuracy: 0.9395 - val_loss: 2.6451 - val_accuracy: 0.6724\n",
      "Epoch 173/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1344 - accuracy: 0.9316 - val_loss: 2.8614 - val_accuracy: 0.6846\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.1387 - accuracy: 0.9455 - val_loss: 2.5088 - val_accuracy: 0.6846\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1243 - accuracy: 0.9393 - val_loss: 2.0555 - val_accuracy: 0.6675\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1549 - accuracy: 0.9334 - val_loss: 1.9629 - val_accuracy: 0.6724\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1346 - accuracy: 0.9256 - val_loss: 2.1383 - val_accuracy: 0.6822\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.1496 - accuracy: 0.9340 - val_loss: 2.1088 - val_accuracy: 0.6797\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1243 - accuracy: 0.9359 - val_loss: 2.0199 - val_accuracy: 0.6773\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1315 - accuracy: 0.9329 - val_loss: 2.1826 - val_accuracy: 0.6944\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1293 - accuracy: 0.9410 - val_loss: 2.5630 - val_accuracy: 0.6797\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1259 - accuracy: 0.9450 - val_loss: 2.5932 - val_accuracy: 0.6846\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1273 - accuracy: 0.9489 - val_loss: 2.2642 - val_accuracy: 0.6993\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1468 - accuracy: 0.9297 - val_loss: 1.9496 - val_accuracy: 0.6895\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1510 - accuracy: 0.9290 - val_loss: 1.9511 - val_accuracy: 0.7017\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1571 - accuracy: 0.9201 - val_loss: 2.1077 - val_accuracy: 0.6993\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1315 - accuracy: 0.9395 - val_loss: 2.2857 - val_accuracy: 0.6822\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1169 - accuracy: 0.9380 - val_loss: 2.5456 - val_accuracy: 0.6699\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 78ms/step - loss: 0.1149 - accuracy: 0.9456 - val_loss: 2.8261 - val_accuracy: 0.6895\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1411 - accuracy: 0.9398 - val_loss: 2.7408 - val_accuracy: 0.6846\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1255 - accuracy: 0.9417 - val_loss: 2.7719 - val_accuracy: 0.6797\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1317 - accuracy: 0.9412 - val_loss: 2.9553 - val_accuracy: 0.6895\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1344 - accuracy: 0.9382 - val_loss: 3.1573 - val_accuracy: 0.6773\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1163 - accuracy: 0.9449 - val_loss: 2.9837 - val_accuracy: 0.6675\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1269 - accuracy: 0.9406 - val_loss: 2.7761 - val_accuracy: 0.6748\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1109 - accuracy: 0.9539 - val_loss: 2.5979 - val_accuracy: 0.6895\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1382 - accuracy: 0.9315 - val_loss: 2.6381 - val_accuracy: 0.6797\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1425 - accuracy: 0.9346 - val_loss: 2.5842 - val_accuracy: 0.6822\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1271 - accuracy: 0.9427 - val_loss: 2.5115 - val_accuracy: 0.6675\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1371 - accuracy: 0.9366 - val_loss: 2.5972 - val_accuracy: 0.6626\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1206 - accuracy: 0.9516 - val_loss: 2.6745 - val_accuracy: 0.6724\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1336 - accuracy: 0.9414 - val_loss: 2.6634 - val_accuracy: 0.6675\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1073 - accuracy: 0.9468 - val_loss: 2.7203 - val_accuracy: 0.6797\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1066 - accuracy: 0.9514 - val_loss: 2.8095 - val_accuracy: 0.6919\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1152 - accuracy: 0.9521 - val_loss: 2.7106 - val_accuracy: 0.6895\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1151 - accuracy: 0.9480 - val_loss: 2.6665 - val_accuracy: 0.6968\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1283 - accuracy: 0.9482 - val_loss: 2.7203 - val_accuracy: 0.6993\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1234 - accuracy: 0.9462 - val_loss: 2.6674 - val_accuracy: 0.6822\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1350 - accuracy: 0.9400 - val_loss: 2.5751 - val_accuracy: 0.6601\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1076 - accuracy: 0.9543 - val_loss: 2.5968 - val_accuracy: 0.6870\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1240 - accuracy: 0.9528 - val_loss: 2.5745 - val_accuracy: 0.6870\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1042 - accuracy: 0.9558 - val_loss: 2.5062 - val_accuracy: 0.6797\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1072 - accuracy: 0.9537 - val_loss: 2.5382 - val_accuracy: 0.6797\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1327 - accuracy: 0.9342 - val_loss: 2.3757 - val_accuracy: 0.6699\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1116 - accuracy: 0.9538 - val_loss: 2.3162 - val_accuracy: 0.6724\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1349 - accuracy: 0.9379 - val_loss: 2.3709 - val_accuracy: 0.6870\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1000 - accuracy: 0.9631 - val_loss: 2.3929 - val_accuracy: 0.6870\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1208 - accuracy: 0.9454 - val_loss: 2.3805 - val_accuracy: 0.6919\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1056 - accuracy: 0.9560 - val_loss: 2.5284 - val_accuracy: 0.6846\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1012 - accuracy: 0.9524 - val_loss: 2.7266 - val_accuracy: 0.6919\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1208 - accuracy: 0.9503 - val_loss: 2.6531 - val_accuracy: 0.6919\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1060 - accuracy: 0.9546 - val_loss: 2.5826 - val_accuracy: 0.6773\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1048 - accuracy: 0.9471 - val_loss: 2.5777 - val_accuracy: 0.6773\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1103 - accuracy: 0.9419 - val_loss: 2.7653 - val_accuracy: 0.6773\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1295 - accuracy: 0.9441 - val_loss: 2.8824 - val_accuracy: 0.6919\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0974 - accuracy: 0.9542 - val_loss: 2.9741 - val_accuracy: 0.6993\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1474 - accuracy: 0.9470 - val_loss: 2.6891 - val_accuracy: 0.6822\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1103 - accuracy: 0.9492 - val_loss: 2.6311 - val_accuracy: 0.7017\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1231 - accuracy: 0.9394 - val_loss: 2.6674 - val_accuracy: 0.6944\n",
      "Epoch 230/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1051 - accuracy: 0.9542 - val_loss: 2.6696 - val_accuracy: 0.6895\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0953 - accuracy: 0.9506 - val_loss: 2.7433 - val_accuracy: 0.6870\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.1100 - accuracy: 0.9465 - val_loss: 2.7177 - val_accuracy: 0.7042\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0954 - accuracy: 0.9543 - val_loss: 2.6839 - val_accuracy: 0.7042\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0807 - accuracy: 0.9712 - val_loss: 2.8502 - val_accuracy: 0.6968\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0945 - accuracy: 0.9611 - val_loss: 3.1677 - val_accuracy: 0.6846\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1174 - accuracy: 0.9531 - val_loss: 3.1282 - val_accuracy: 0.6870\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1004 - accuracy: 0.9545 - val_loss: 2.9752 - val_accuracy: 0.6822\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0964 - accuracy: 0.9600 - val_loss: 2.8912 - val_accuracy: 0.6822\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1210 - accuracy: 0.9537 - val_loss: 2.7775 - val_accuracy: 0.6944\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0960 - accuracy: 0.9629 - val_loss: 2.9811 - val_accuracy: 0.7017\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1023 - accuracy: 0.9502 - val_loss: 3.0840 - val_accuracy: 0.6944\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0968 - accuracy: 0.9617 - val_loss: 3.1632 - val_accuracy: 0.6846\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1078 - accuracy: 0.9536 - val_loss: 2.8603 - val_accuracy: 0.6968\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0855 - accuracy: 0.9596 - val_loss: 2.7918 - val_accuracy: 0.7066\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1040 - accuracy: 0.9559 - val_loss: 2.7895 - val_accuracy: 0.7066\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0894 - accuracy: 0.9686 - val_loss: 2.9903 - val_accuracy: 0.6748\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1069 - accuracy: 0.9567 - val_loss: 3.1385 - val_accuracy: 0.6724\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1037 - accuracy: 0.9534 - val_loss: 2.9721 - val_accuracy: 0.6968\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0802 - accuracy: 0.9693 - val_loss: 2.9731 - val_accuracy: 0.6968\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0901 - accuracy: 0.9594 - val_loss: 3.0415 - val_accuracy: 0.6944\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0900 - accuracy: 0.9542 - val_loss: 3.1075 - val_accuracy: 0.6797\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1170 - accuracy: 0.9458 - val_loss: 3.0049 - val_accuracy: 0.7066\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1135 - accuracy: 0.9462 - val_loss: 2.8445 - val_accuracy: 0.7042\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1269 - accuracy: 0.9425 - val_loss: 2.7520 - val_accuracy: 0.6675\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0955 - accuracy: 0.9590 - val_loss: 2.9042 - val_accuracy: 0.6528\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1317 - accuracy: 0.9488 - val_loss: 2.7196 - val_accuracy: 0.6846\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1069 - accuracy: 0.9593 - val_loss: 2.6874 - val_accuracy: 0.6993\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0959 - accuracy: 0.9579 - val_loss: 2.7889 - val_accuracy: 0.6895\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1012 - accuracy: 0.9547 - val_loss: 2.9802 - val_accuracy: 0.6870\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0984 - accuracy: 0.9619 - val_loss: 3.0855 - val_accuracy: 0.6773\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0963 - accuracy: 0.9632 - val_loss: 3.0972 - val_accuracy: 0.6846\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0961 - accuracy: 0.9561 - val_loss: 3.1183 - val_accuracy: 0.6944\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0976 - accuracy: 0.9528 - val_loss: 3.2939 - val_accuracy: 0.6797\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0988 - accuracy: 0.9569 - val_loss: 3.5975 - val_accuracy: 0.6895\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0942 - accuracy: 0.9603 - val_loss: 3.5232 - val_accuracy: 0.6919\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0941 - accuracy: 0.9578 - val_loss: 3.2399 - val_accuracy: 0.6993\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1009 - accuracy: 0.9533 - val_loss: 3.1125 - val_accuracy: 0.7042\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0799 - accuracy: 0.9669 - val_loss: 3.3550 - val_accuracy: 0.6968\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1243 - accuracy: 0.9536 - val_loss: 3.2581 - val_accuracy: 0.6919\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1139 - accuracy: 0.9472 - val_loss: 3.0879 - val_accuracy: 0.7066\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0918 - accuracy: 0.9541 - val_loss: 3.0123 - val_accuracy: 0.7139\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1056 - accuracy: 0.9522 - val_loss: 3.0816 - val_accuracy: 0.6993\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1083 - accuracy: 0.9481 - val_loss: 3.2008 - val_accuracy: 0.6870\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0929 - accuracy: 0.9665 - val_loss: 3.4229 - val_accuracy: 0.6870\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0887 - accuracy: 0.9581 - val_loss: 3.5129 - val_accuracy: 0.6919\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0930 - accuracy: 0.9516 - val_loss: 3.3117 - val_accuracy: 0.7017\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0785 - accuracy: 0.9678 - val_loss: 2.9924 - val_accuracy: 0.6919\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.1049 - accuracy: 0.9603 - val_loss: 3.0966 - val_accuracy: 0.6895\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0903 - accuracy: 0.9606 - val_loss: 3.6479 - val_accuracy: 0.7066\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1144 - accuracy: 0.9584 - val_loss: 3.2439 - val_accuracy: 0.6773\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0954 - accuracy: 0.9638 - val_loss: 2.9544 - val_accuracy: 0.6455\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1476 - accuracy: 0.9480 - val_loss: 2.7814 - val_accuracy: 0.6870\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1166 - accuracy: 0.9472 - val_loss: 3.0833 - val_accuracy: 0.6968\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1173 - accuracy: 0.9557 - val_loss: 2.8730 - val_accuracy: 0.6944\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0945 - accuracy: 0.9668 - val_loss: 2.7519 - val_accuracy: 0.6944\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0815 - accuracy: 0.9739 - val_loss: 2.8075 - val_accuracy: 0.6993\n",
      "Epoch 287/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0850 - accuracy: 0.9684 - val_loss: 2.7634 - val_accuracy: 0.6993\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0851 - accuracy: 0.9695 - val_loss: 2.7788 - val_accuracy: 0.6870\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0861 - accuracy: 0.9668 - val_loss: 2.7367 - val_accuracy: 0.6870\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0694 - accuracy: 0.9775 - val_loss: 2.6900 - val_accuracy: 0.6773\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0789 - accuracy: 0.9625 - val_loss: 2.6681 - val_accuracy: 0.6822\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0734 - accuracy: 0.9703 - val_loss: 2.7429 - val_accuracy: 0.6724\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0809 - accuracy: 0.9652 - val_loss: 2.8023 - val_accuracy: 0.6724\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0748 - accuracy: 0.9717 - val_loss: 2.7917 - val_accuracy: 0.6675\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0673 - accuracy: 0.9669 - val_loss: 2.8646 - val_accuracy: 0.6748\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0691 - accuracy: 0.9719 - val_loss: 2.9946 - val_accuracy: 0.6675\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0748 - accuracy: 0.9719 - val_loss: 3.0449 - val_accuracy: 0.6650\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0657 - accuracy: 0.9699 - val_loss: 2.9018 - val_accuracy: 0.6822\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0662 - accuracy: 0.9730 - val_loss: 2.8013 - val_accuracy: 0.6797\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 82ms/step - loss: 0.0741 - accuracy: 0.9702 - val_loss: 2.9152 - val_accuracy: 0.6773\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0683 - accuracy: 0.9713 - val_loss: 3.1082 - val_accuracy: 0.6748\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0989 - accuracy: 0.9641 - val_loss: 3.0949 - val_accuracy: 0.6846\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0794 - accuracy: 0.9659 - val_loss: 2.9392 - val_accuracy: 0.6895\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0612 - accuracy: 0.9806 - val_loss: 2.9267 - val_accuracy: 0.6822\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0816 - accuracy: 0.9621 - val_loss: 2.9401 - val_accuracy: 0.6797\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0818 - accuracy: 0.9656 - val_loss: 2.8763 - val_accuracy: 0.6944\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0504 - accuracy: 0.9822 - val_loss: 2.9501 - val_accuracy: 0.6870\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0795 - accuracy: 0.9731 - val_loss: 3.2205 - val_accuracy: 0.6577\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0599 - accuracy: 0.9781 - val_loss: 3.2591 - val_accuracy: 0.6773\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0716 - accuracy: 0.9730 - val_loss: 3.3382 - val_accuracy: 0.6944\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0726 - accuracy: 0.9682 - val_loss: 3.5392 - val_accuracy: 0.6675\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0736 - accuracy: 0.9727 - val_loss: 3.6456 - val_accuracy: 0.6406\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.1074 - accuracy: 0.9614 - val_loss: 3.3886 - val_accuracy: 0.6748\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0907 - accuracy: 0.9666 - val_loss: 2.8594 - val_accuracy: 0.6577\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0833 - accuracy: 0.9642 - val_loss: 2.5156 - val_accuracy: 0.6724\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0910 - accuracy: 0.9629 - val_loss: 2.4096 - val_accuracy: 0.6822\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0866 - accuracy: 0.9640 - val_loss: 2.5158 - val_accuracy: 0.6919\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0847 - accuracy: 0.9654 - val_loss: 2.7579 - val_accuracy: 0.6944\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0793 - accuracy: 0.9685 - val_loss: 2.9767 - val_accuracy: 0.6968\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0535 - accuracy: 0.9778 - val_loss: 3.0723 - val_accuracy: 0.6919\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0673 - accuracy: 0.9762 - val_loss: 3.1210 - val_accuracy: 0.6797\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0682 - accuracy: 0.9675 - val_loss: 3.1330 - val_accuracy: 0.6626\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0980 - accuracy: 0.9581 - val_loss: 3.3279 - val_accuracy: 0.6357\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0824 - accuracy: 0.9634 - val_loss: 3.1917 - val_accuracy: 0.6822\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0572 - accuracy: 0.9782 - val_loss: 3.3599 - val_accuracy: 0.6968\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.1012 - accuracy: 0.9568 - val_loss: 3.2929 - val_accuracy: 0.6846\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0703 - accuracy: 0.9744 - val_loss: 3.3775 - val_accuracy: 0.6626\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0834 - accuracy: 0.9656 - val_loss: 3.2865 - val_accuracy: 0.6650\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0785 - accuracy: 0.9728 - val_loss: 3.2704 - val_accuracy: 0.6797\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0836 - accuracy: 0.9699 - val_loss: 3.0775 - val_accuracy: 0.6895\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0765 - accuracy: 0.9685 - val_loss: 2.8646 - val_accuracy: 0.6650\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0704 - accuracy: 0.9748 - val_loss: 2.8812 - val_accuracy: 0.6479\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0773 - accuracy: 0.9698 - val_loss: 2.9274 - val_accuracy: 0.6650\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0707 - accuracy: 0.9741 - val_loss: 3.1237 - val_accuracy: 0.6797\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0694 - accuracy: 0.9768 - val_loss: 3.2349 - val_accuracy: 0.6773\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0575 - accuracy: 0.9791 - val_loss: 3.3915 - val_accuracy: 0.6504\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0775 - accuracy: 0.9684 - val_loss: 3.4276 - val_accuracy: 0.6430\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0431 - accuracy: 0.9836 - val_loss: 3.4770 - val_accuracy: 0.6455\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0799 - accuracy: 0.9681 - val_loss: 3.3929 - val_accuracy: 0.6699\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0689 - accuracy: 0.9720 - val_loss: 3.2702 - val_accuracy: 0.6797\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0646 - accuracy: 0.9691 - val_loss: 3.4036 - val_accuracy: 0.6650\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0721 - accuracy: 0.9726 - val_loss: 3.5732 - val_accuracy: 0.6724\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0600 - accuracy: 0.9764 - val_loss: 3.3809 - val_accuracy: 0.6675\n",
      "Epoch 344/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0647 - accuracy: 0.9743 - val_loss: 3.2919 - val_accuracy: 0.6773\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0635 - accuracy: 0.9774 - val_loss: 3.1990 - val_accuracy: 0.6822\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0739 - accuracy: 0.9698 - val_loss: 2.9897 - val_accuracy: 0.6822\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0689 - accuracy: 0.9689 - val_loss: 2.9383 - val_accuracy: 0.6870\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0671 - accuracy: 0.9741 - val_loss: 2.9991 - val_accuracy: 0.6870\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0525 - accuracy: 0.9818 - val_loss: 3.1357 - val_accuracy: 0.6895\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0636 - accuracy: 0.9780 - val_loss: 3.2403 - val_accuracy: 0.6846\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0653 - accuracy: 0.9793 - val_loss: 3.5076 - val_accuracy: 0.6797\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0785 - accuracy: 0.9717 - val_loss: 3.6876 - val_accuracy: 0.6870\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0560 - accuracy: 0.9769 - val_loss: 3.7896 - val_accuracy: 0.6870\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0512 - accuracy: 0.9800 - val_loss: 3.9110 - val_accuracy: 0.6699\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0605 - accuracy: 0.9813 - val_loss: 3.9677 - val_accuracy: 0.6650\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0712 - accuracy: 0.9744 - val_loss: 3.9468 - val_accuracy: 0.6724\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0811 - accuracy: 0.9716 - val_loss: 3.6874 - val_accuracy: 0.6895\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0590 - accuracy: 0.9774 - val_loss: 3.5666 - val_accuracy: 0.6846\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0696 - accuracy: 0.9769 - val_loss: 3.3523 - val_accuracy: 0.6944\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0626 - accuracy: 0.9766 - val_loss: 3.2374 - val_accuracy: 0.6822\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0585 - accuracy: 0.9765 - val_loss: 3.2436 - val_accuracy: 0.6748\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0698 - accuracy: 0.9667 - val_loss: 3.2150 - val_accuracy: 0.6748\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0575 - accuracy: 0.9764 - val_loss: 3.1605 - val_accuracy: 0.6895\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0707 - accuracy: 0.9745 - val_loss: 3.0922 - val_accuracy: 0.6993\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0607 - accuracy: 0.9770 - val_loss: 3.0035 - val_accuracy: 0.6846\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0838 - accuracy: 0.9682 - val_loss: 3.0205 - val_accuracy: 0.6944\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0646 - accuracy: 0.9744 - val_loss: 3.2596 - val_accuracy: 0.7139\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0834 - accuracy: 0.9713 - val_loss: 2.9996 - val_accuracy: 0.7090\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0604 - accuracy: 0.9755 - val_loss: 2.9147 - val_accuracy: 0.6895\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0565 - accuracy: 0.9762 - val_loss: 2.9540 - val_accuracy: 0.6748\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0442 - accuracy: 0.9855 - val_loss: 3.1397 - val_accuracy: 0.6748\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0626 - accuracy: 0.9726 - val_loss: 3.3228 - val_accuracy: 0.6846\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0536 - accuracy: 0.9791 - val_loss: 3.4560 - val_accuracy: 0.6846\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0596 - accuracy: 0.9744 - val_loss: 3.4938 - val_accuracy: 0.6968\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0415 - accuracy: 0.9854 - val_loss: 3.5053 - val_accuracy: 0.6773\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0600 - accuracy: 0.9717 - val_loss: 3.3867 - val_accuracy: 0.6748\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0588 - accuracy: 0.9748 - val_loss: 3.2854 - val_accuracy: 0.6724\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0369 - accuracy: 0.9852 - val_loss: 3.2437 - val_accuracy: 0.6773\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0751 - accuracy: 0.9757 - val_loss: 3.1807 - val_accuracy: 0.6846\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0691 - accuracy: 0.9757 - val_loss: 3.1350 - val_accuracy: 0.6675\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0478 - accuracy: 0.9809 - val_loss: 3.1414 - val_accuracy: 0.6650\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0810 - accuracy: 0.9772 - val_loss: 3.0130 - val_accuracy: 0.6675\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0612 - accuracy: 0.9723 - val_loss: 2.9112 - val_accuracy: 0.6895\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0482 - accuracy: 0.9780 - val_loss: 2.9180 - val_accuracy: 0.6846\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0509 - accuracy: 0.9815 - val_loss: 3.0358 - val_accuracy: 0.6797\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0507 - accuracy: 0.9809 - val_loss: 3.1885 - val_accuracy: 0.6870\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0536 - accuracy: 0.9808 - val_loss: 3.3945 - val_accuracy: 0.6846\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0421 - accuracy: 0.9849 - val_loss: 3.6134 - val_accuracy: 0.6797\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0546 - accuracy: 0.9778 - val_loss: 3.6694 - val_accuracy: 0.6797\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0501 - accuracy: 0.9779 - val_loss: 3.5478 - val_accuracy: 0.6968\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0545 - accuracy: 0.9756 - val_loss: 3.5428 - val_accuracy: 0.7017\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0705 - accuracy: 0.9731 - val_loss: 3.3721 - val_accuracy: 0.6895\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 3.3783 - val_accuracy: 0.6773\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0488 - accuracy: 0.9821 - val_loss: 3.2765 - val_accuracy: 0.6846\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0483 - accuracy: 0.9786 - val_loss: 3.2872 - val_accuracy: 0.6944\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0683 - accuracy: 0.9742 - val_loss: 3.2506 - val_accuracy: 0.6895\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0601 - accuracy: 0.9724 - val_loss: 3.3960 - val_accuracy: 0.6724\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0756 - accuracy: 0.9736 - val_loss: 3.3404 - val_accuracy: 0.6675\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0601 - accuracy: 0.9792 - val_loss: 3.5028 - val_accuracy: 0.6895\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0687 - accuracy: 0.9743 - val_loss: 3.7263 - val_accuracy: 0.6944\n",
      "Epoch 401/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0557 - accuracy: 0.9796 - val_loss: 3.8160 - val_accuracy: 0.6870\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0832 - accuracy: 0.9627 - val_loss: 3.4431 - val_accuracy: 0.6870\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0868 - accuracy: 0.9681 - val_loss: 2.8929 - val_accuracy: 0.6895\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0694 - accuracy: 0.9758 - val_loss: 2.5075 - val_accuracy: 0.6870\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0585 - accuracy: 0.9767 - val_loss: 2.3980 - val_accuracy: 0.6748\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0882 - accuracy: 0.9552 - val_loss: 2.4818 - val_accuracy: 0.6822\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0558 - accuracy: 0.9766 - val_loss: 2.7811 - val_accuracy: 0.6724\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0589 - accuracy: 0.9777 - val_loss: 3.0921 - val_accuracy: 0.6822\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0610 - accuracy: 0.9768 - val_loss: 3.1471 - val_accuracy: 0.6675\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0464 - accuracy: 0.9817 - val_loss: 3.1278 - val_accuracy: 0.6724\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0586 - accuracy: 0.9739 - val_loss: 3.0551 - val_accuracy: 0.6797\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0478 - accuracy: 0.9791 - val_loss: 3.0925 - val_accuracy: 0.6822\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0606 - accuracy: 0.9710 - val_loss: 3.1379 - val_accuracy: 0.6773\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0581 - accuracy: 0.9786 - val_loss: 3.0104 - val_accuracy: 0.6797\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0602 - accuracy: 0.9758 - val_loss: 2.9001 - val_accuracy: 0.6797\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0593 - accuracy: 0.9770 - val_loss: 2.7862 - val_accuracy: 0.6699\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0714 - accuracy: 0.9759 - val_loss: 2.6968 - val_accuracy: 0.6846\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0669 - accuracy: 0.9703 - val_loss: 2.7990 - val_accuracy: 0.6919\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0641 - accuracy: 0.9793 - val_loss: 2.7553 - val_accuracy: 0.6797\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0384 - accuracy: 0.9852 - val_loss: 2.9444 - val_accuracy: 0.6381\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0850 - accuracy: 0.9695 - val_loss: 2.8027 - val_accuracy: 0.6455\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0606 - accuracy: 0.9736 - val_loss: 2.7579 - val_accuracy: 0.6822\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0580 - accuracy: 0.9818 - val_loss: 2.6998 - val_accuracy: 0.7017\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0688 - accuracy: 0.9713 - val_loss: 2.6005 - val_accuracy: 0.7042\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0533 - accuracy: 0.9798 - val_loss: 2.6684 - val_accuracy: 0.6846\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0377 - accuracy: 0.9866 - val_loss: 2.8108 - val_accuracy: 0.6724\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0561 - accuracy: 0.9783 - val_loss: 2.7884 - val_accuracy: 0.6846\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0466 - accuracy: 0.9838 - val_loss: 2.9007 - val_accuracy: 0.6919\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0696 - accuracy: 0.9760 - val_loss: 2.9658 - val_accuracy: 0.6870\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0434 - accuracy: 0.9845 - val_loss: 3.1179 - val_accuracy: 0.6822\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0410 - accuracy: 0.9827 - val_loss: 3.3547 - val_accuracy: 0.6773\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0422 - accuracy: 0.9867 - val_loss: 3.3028 - val_accuracy: 0.6870\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0467 - accuracy: 0.9848 - val_loss: 3.2985 - val_accuracy: 0.6944\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0486 - accuracy: 0.9812 - val_loss: 3.2483 - val_accuracy: 0.6870\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0678 - accuracy: 0.9743 - val_loss: 3.1619 - val_accuracy: 0.6773\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0505 - accuracy: 0.9837 - val_loss: 3.3218 - val_accuracy: 0.6846\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0453 - accuracy: 0.9885 - val_loss: 3.5295 - val_accuracy: 0.6797\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0479 - accuracy: 0.9797 - val_loss: 3.4872 - val_accuracy: 0.6968\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0469 - accuracy: 0.9871 - val_loss: 3.2203 - val_accuracy: 0.7042\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0595 - accuracy: 0.9795 - val_loss: 3.0454 - val_accuracy: 0.6846\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0522 - accuracy: 0.9775 - val_loss: 2.9783 - val_accuracy: 0.6846\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0711 - accuracy: 0.9766 - val_loss: 3.0240 - val_accuracy: 0.6724\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0533 - accuracy: 0.9754 - val_loss: 3.0719 - val_accuracy: 0.6919\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0435 - accuracy: 0.9840 - val_loss: 3.1759 - val_accuracy: 0.7017\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0571 - accuracy: 0.9754 - val_loss: 2.9263 - val_accuracy: 0.6895\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0484 - accuracy: 0.9840 - val_loss: 2.6392 - val_accuracy: 0.6797\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.0612 - accuracy: 0.9835 - val_loss: 2.5963 - val_accuracy: 0.6773\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0612 - accuracy: 0.9733 - val_loss: 2.5864 - val_accuracy: 0.6773\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0643 - accuracy: 0.9763 - val_loss: 2.5620 - val_accuracy: 0.6724\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0460 - accuracy: 0.9849 - val_loss: 2.6353 - val_accuracy: 0.6797\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0581 - accuracy: 0.9790 - val_loss: 2.5152 - val_accuracy: 0.6968\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0691 - accuracy: 0.9682 - val_loss: 2.4118 - val_accuracy: 0.6846\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0589 - accuracy: 0.9776 - val_loss: 2.3508 - val_accuracy: 0.6919\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0552 - accuracy: 0.9793 - val_loss: 2.2432 - val_accuracy: 0.6895\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0663 - accuracy: 0.9778 - val_loss: 2.3278 - val_accuracy: 0.6895\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 79ms/step - loss: 0.0656 - accuracy: 0.9727 - val_loss: 2.5742 - val_accuracy: 0.7066\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0635 - accuracy: 0.9768 - val_loss: 2.6037 - val_accuracy: 0.7066\n",
      "Epoch 458/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0545 - accuracy: 0.9765 - val_loss: 2.4907 - val_accuracy: 0.7017\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0560 - accuracy: 0.9774 - val_loss: 2.4251 - val_accuracy: 0.6846\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0474 - accuracy: 0.9816 - val_loss: 2.5649 - val_accuracy: 0.6846\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0479 - accuracy: 0.9849 - val_loss: 2.9843 - val_accuracy: 0.6870\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0867 - accuracy: 0.9709 - val_loss: 3.1677 - val_accuracy: 0.6919\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0535 - accuracy: 0.9818 - val_loss: 3.2175 - val_accuracy: 0.6870\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0593 - accuracy: 0.9793 - val_loss: 3.0553 - val_accuracy: 0.6822\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0475 - accuracy: 0.9835 - val_loss: 2.9076 - val_accuracy: 0.6993\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0383 - accuracy: 0.9835 - val_loss: 2.8385 - val_accuracy: 0.6944\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0365 - accuracy: 0.9825 - val_loss: 2.8822 - val_accuracy: 0.6748\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0383 - accuracy: 0.9809 - val_loss: 3.0041 - val_accuracy: 0.6822\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0318 - accuracy: 0.9902 - val_loss: 3.0699 - val_accuracy: 0.6797\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0462 - accuracy: 0.9834 - val_loss: 3.0931 - val_accuracy: 0.6870\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0425 - accuracy: 0.9792 - val_loss: 3.1202 - val_accuracy: 0.6919\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0538 - accuracy: 0.9782 - val_loss: 3.1344 - val_accuracy: 0.6895\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0668 - accuracy: 0.9805 - val_loss: 3.1003 - val_accuracy: 0.6968\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0469 - accuracy: 0.9793 - val_loss: 3.1593 - val_accuracy: 0.6895\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0366 - accuracy: 0.9862 - val_loss: 3.3233 - val_accuracy: 0.6993\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0540 - accuracy: 0.9778 - val_loss: 3.3739 - val_accuracy: 0.6870\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0414 - accuracy: 0.9839 - val_loss: 3.4412 - val_accuracy: 0.7066\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0410 - accuracy: 0.9866 - val_loss: 3.2873 - val_accuracy: 0.6919\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0426 - accuracy: 0.9829 - val_loss: 3.0225 - val_accuracy: 0.6822\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0380 - accuracy: 0.9847 - val_loss: 2.8886 - val_accuracy: 0.6773\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0605 - accuracy: 0.9751 - val_loss: 2.8634 - val_accuracy: 0.6797\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0504 - accuracy: 0.9782 - val_loss: 3.0604 - val_accuracy: 0.6870\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0517 - accuracy: 0.9785 - val_loss: 3.2647 - val_accuracy: 0.6919\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0500 - accuracy: 0.9799 - val_loss: 3.3110 - val_accuracy: 0.6895\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0460 - accuracy: 0.9859 - val_loss: 3.2350 - val_accuracy: 0.6870\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0442 - accuracy: 0.9863 - val_loss: 3.2640 - val_accuracy: 0.6846\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0544 - accuracy: 0.9757 - val_loss: 3.0724 - val_accuracy: 0.6822\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0747 - accuracy: 0.9723 - val_loss: 2.8056 - val_accuracy: 0.6895\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0519 - accuracy: 0.9757 - val_loss: 2.9810 - val_accuracy: 0.7115\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0724 - accuracy: 0.9718 - val_loss: 2.8355 - val_accuracy: 0.6919\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0508 - accuracy: 0.9812 - val_loss: 2.8733 - val_accuracy: 0.6797\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0646 - accuracy: 0.9719 - val_loss: 2.9893 - val_accuracy: 0.6822\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0791 - accuracy: 0.9642 - val_loss: 2.9364 - val_accuracy: 0.6919\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0484 - accuracy: 0.9825 - val_loss: 3.0182 - val_accuracy: 0.6895\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0563 - accuracy: 0.9787 - val_loss: 2.8874 - val_accuracy: 0.7017\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0498 - accuracy: 0.9805 - val_loss: 2.8692 - val_accuracy: 0.7017\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0323 - accuracy: 0.9880 - val_loss: 2.9259 - val_accuracy: 0.6919\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0543 - accuracy: 0.9838 - val_loss: 3.0181 - val_accuracy: 0.6919\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0499 - accuracy: 0.9805 - val_loss: 3.2100 - val_accuracy: 0.6895\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0465 - accuracy: 0.9842 - val_loss: 3.4563 - val_accuracy: 0.6919\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0471 - accuracy: 0.9791 - val_loss: 3.6485 - val_accuracy: 0.6944\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0390 - accuracy: 0.9862 - val_loss: 3.7590 - val_accuracy: 0.6895\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0488 - accuracy: 0.9787 - val_loss: 3.6615 - val_accuracy: 0.6944\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0402 - accuracy: 0.9849 - val_loss: 3.4956 - val_accuracy: 0.6919\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0481 - accuracy: 0.9813 - val_loss: 3.3497 - val_accuracy: 0.6870\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0625 - accuracy: 0.9749 - val_loss: 3.3056 - val_accuracy: 0.6895\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0476 - accuracy: 0.9804 - val_loss: 3.2761 - val_accuracy: 0.6895\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0536 - accuracy: 0.9783 - val_loss: 3.2308 - val_accuracy: 0.6699\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0512 - accuracy: 0.9799 - val_loss: 3.2014 - val_accuracy: 0.6773\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0327 - accuracy: 0.9894 - val_loss: 3.2437 - val_accuracy: 0.6748\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0533 - accuracy: 0.9783 - val_loss: 3.2697 - val_accuracy: 0.6699\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0464 - accuracy: 0.9803 - val_loss: 3.2705 - val_accuracy: 0.6748\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 0.9879 - val_loss: 3.3145 - val_accuracy: 0.6870\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0393 - accuracy: 0.9880 - val_loss: 3.2852 - val_accuracy: 0.6748\n",
      "Epoch 515/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0352 - accuracy: 0.9861 - val_loss: 3.2393 - val_accuracy: 0.6748\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0276 - accuracy: 0.9850 - val_loss: 3.3185 - val_accuracy: 0.6773\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0360 - accuracy: 0.9883 - val_loss: 3.4859 - val_accuracy: 0.6822\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0313 - accuracy: 0.9892 - val_loss: 3.6120 - val_accuracy: 0.6944\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0439 - accuracy: 0.9796 - val_loss: 3.9660 - val_accuracy: 0.6968\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0310 - accuracy: 0.9897 - val_loss: 4.2925 - val_accuracy: 0.7090\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0570 - accuracy: 0.9782 - val_loss: 3.8735 - val_accuracy: 0.6822\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0589 - accuracy: 0.9796 - val_loss: 4.0131 - val_accuracy: 0.6528\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.1042 - accuracy: 0.9671 - val_loss: 3.6452 - val_accuracy: 0.6919\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0376 - accuracy: 0.9866 - val_loss: 4.0724 - val_accuracy: 0.6944\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0837 - accuracy: 0.9712 - val_loss: 3.6387 - val_accuracy: 0.6968\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0559 - accuracy: 0.9752 - val_loss: 3.2626 - val_accuracy: 0.6822\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0505 - accuracy: 0.9785 - val_loss: 3.1874 - val_accuracy: 0.6797\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0502 - accuracy: 0.9776 - val_loss: 3.0610 - val_accuracy: 0.6895\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0405 - accuracy: 0.9849 - val_loss: 3.0759 - val_accuracy: 0.6919\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0550 - accuracy: 0.9719 - val_loss: 3.1136 - val_accuracy: 0.6968\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0226 - accuracy: 0.9915 - val_loss: 3.3218 - val_accuracy: 0.6944\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0345 - accuracy: 0.9871 - val_loss: 3.6099 - val_accuracy: 0.6846\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0618 - accuracy: 0.9782 - val_loss: 3.6635 - val_accuracy: 0.6870\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0479 - accuracy: 0.9788 - val_loss: 3.4524 - val_accuracy: 0.7042\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0350 - accuracy: 0.9833 - val_loss: 3.3306 - val_accuracy: 0.6944\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0493 - accuracy: 0.9780 - val_loss: 3.2223 - val_accuracy: 0.6968\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0709 - accuracy: 0.9739 - val_loss: 3.1525 - val_accuracy: 0.6944\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0424 - accuracy: 0.9827 - val_loss: 3.1841 - val_accuracy: 0.6919\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0299 - accuracy: 0.9891 - val_loss: 3.2725 - val_accuracy: 0.6993\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0422 - accuracy: 0.9841 - val_loss: 3.3859 - val_accuracy: 0.7017\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0335 - accuracy: 0.9882 - val_loss: 3.5082 - val_accuracy: 0.7017\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0468 - accuracy: 0.9837 - val_loss: 3.5568 - val_accuracy: 0.7115\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0304 - accuracy: 0.9872 - val_loss: 3.5782 - val_accuracy: 0.7017\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0356 - accuracy: 0.9881 - val_loss: 3.6021 - val_accuracy: 0.7042\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0471 - accuracy: 0.9758 - val_loss: 3.5781 - val_accuracy: 0.7042\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0273 - accuracy: 0.9878 - val_loss: 3.7112 - val_accuracy: 0.6919\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0375 - accuracy: 0.9871 - val_loss: 3.9323 - val_accuracy: 0.6846\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0392 - accuracy: 0.9836 - val_loss: 4.3086 - val_accuracy: 0.6895\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0455 - accuracy: 0.9829 - val_loss: 4.5714 - val_accuracy: 0.6846\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0389 - accuracy: 0.9853 - val_loss: 4.4077 - val_accuracy: 0.6822\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0413 - accuracy: 0.9837 - val_loss: 4.0348 - val_accuracy: 0.6944\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0489 - accuracy: 0.9783 - val_loss: 3.9327 - val_accuracy: 0.6822\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0419 - accuracy: 0.9812 - val_loss: 4.0889 - val_accuracy: 0.6822\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0480 - accuracy: 0.9743 - val_loss: 4.5077 - val_accuracy: 0.6944\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0373 - accuracy: 0.9817 - val_loss: 4.6749 - val_accuracy: 0.6993\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0428 - accuracy: 0.9820 - val_loss: 4.4296 - val_accuracy: 0.6944\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0379 - accuracy: 0.9848 - val_loss: 4.4146 - val_accuracy: 0.6626\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0684 - accuracy: 0.9752 - val_loss: 4.1750 - val_accuracy: 0.6822\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0665 - accuracy: 0.9682 - val_loss: 4.2907 - val_accuracy: 0.6699\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0663 - accuracy: 0.9772 - val_loss: 4.2307 - val_accuracy: 0.6919\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0386 - accuracy: 0.9840 - val_loss: 4.0959 - val_accuracy: 0.6870\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0535 - accuracy: 0.9793 - val_loss: 3.9702 - val_accuracy: 0.6870\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0414 - accuracy: 0.9830 - val_loss: 3.9288 - val_accuracy: 0.6870\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0410 - accuracy: 0.9850 - val_loss: 3.9624 - val_accuracy: 0.6895\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0462 - accuracy: 0.9845 - val_loss: 3.6769 - val_accuracy: 0.6822\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0467 - accuracy: 0.9774 - val_loss: 3.2958 - val_accuracy: 0.6797\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0424 - accuracy: 0.9792 - val_loss: 3.1406 - val_accuracy: 0.6773\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0472 - accuracy: 0.9833 - val_loss: 3.0966 - val_accuracy: 0.6895\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0326 - accuracy: 0.9873 - val_loss: 3.0676 - val_accuracy: 0.6846\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0332 - accuracy: 0.9850 - val_loss: 3.2189 - val_accuracy: 0.6748\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0457 - accuracy: 0.9818 - val_loss: 3.1694 - val_accuracy: 0.6773\n",
      "Epoch 572/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0505 - accuracy: 0.9788 - val_loss: 3.1400 - val_accuracy: 0.7139\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0547 - accuracy: 0.9760 - val_loss: 3.0574 - val_accuracy: 0.6895\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0502 - accuracy: 0.9792 - val_loss: 3.0659 - val_accuracy: 0.6528\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0585 - accuracy: 0.9761 - val_loss: 3.2155 - val_accuracy: 0.6650\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0451 - accuracy: 0.9815 - val_loss: 3.1845 - val_accuracy: 0.6504\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0449 - accuracy: 0.9825 - val_loss: 3.0890 - val_accuracy: 0.6846\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0505 - accuracy: 0.9789 - val_loss: 3.2593 - val_accuracy: 0.6895\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0443 - accuracy: 0.9825 - val_loss: 3.4749 - val_accuracy: 0.6968\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0445 - accuracy: 0.9757 - val_loss: 3.5437 - val_accuracy: 0.6870\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0374 - accuracy: 0.9879 - val_loss: 3.6716 - val_accuracy: 0.6919\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0475 - accuracy: 0.9809 - val_loss: 3.6689 - val_accuracy: 0.6846\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0462 - accuracy: 0.9815 - val_loss: 3.7081 - val_accuracy: 0.6993\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0281 - accuracy: 0.9875 - val_loss: 3.9695 - val_accuracy: 0.6968\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0368 - accuracy: 0.9830 - val_loss: 4.0221 - val_accuracy: 0.6968\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0531 - accuracy: 0.9779 - val_loss: 4.3273 - val_accuracy: 0.6993\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0511 - accuracy: 0.9786 - val_loss: 4.3207 - val_accuracy: 0.6944\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0369 - accuracy: 0.9844 - val_loss: 4.1585 - val_accuracy: 0.6993\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0445 - accuracy: 0.9812 - val_loss: 3.6420 - val_accuracy: 0.6968\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0365 - accuracy: 0.9863 - val_loss: 3.4883 - val_accuracy: 0.6919\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0419 - accuracy: 0.9841 - val_loss: 3.5710 - val_accuracy: 0.6944\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0465 - accuracy: 0.9796 - val_loss: 3.4693 - val_accuracy: 0.6822\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 84ms/step - loss: 0.0347 - accuracy: 0.9883 - val_loss: 3.4802 - val_accuracy: 0.6919\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0404 - accuracy: 0.9824 - val_loss: 3.5244 - val_accuracy: 0.6846\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0588 - accuracy: 0.9773 - val_loss: 3.4679 - val_accuracy: 0.6773\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0292 - accuracy: 0.9885 - val_loss: 3.4518 - val_accuracy: 0.6748\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0299 - accuracy: 0.9908 - val_loss: 3.5729 - val_accuracy: 0.6773\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0330 - accuracy: 0.9870 - val_loss: 3.6585 - val_accuracy: 0.6748\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0366 - accuracy: 0.9827 - val_loss: 3.6672 - val_accuracy: 0.6822\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0318 - accuracy: 0.9891 - val_loss: 3.6457 - val_accuracy: 0.6919\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0518 - accuracy: 0.9765 - val_loss: 3.5779 - val_accuracy: 0.6944\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0429 - accuracy: 0.9841 - val_loss: 3.6211 - val_accuracy: 0.6773\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0476 - accuracy: 0.9787 - val_loss: 3.5520 - val_accuracy: 0.6699\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0410 - accuracy: 0.9863 - val_loss: 3.4205 - val_accuracy: 0.6895\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0372 - accuracy: 0.9861 - val_loss: 3.3727 - val_accuracy: 0.7042\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0389 - accuracy: 0.9894 - val_loss: 3.2764 - val_accuracy: 0.7066\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0432 - accuracy: 0.9822 - val_loss: 3.1205 - val_accuracy: 0.6846\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0439 - accuracy: 0.9802 - val_loss: 3.0431 - val_accuracy: 0.6797\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0420 - accuracy: 0.9833 - val_loss: 2.9573 - val_accuracy: 0.6895\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0398 - accuracy: 0.9866 - val_loss: 3.0297 - val_accuracy: 0.6724\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0369 - accuracy: 0.9846 - val_loss: 3.1161 - val_accuracy: 0.6724\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0261 - accuracy: 0.9908 - val_loss: 3.2655 - val_accuracy: 0.6919\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0383 - accuracy: 0.9856 - val_loss: 3.3946 - val_accuracy: 0.7042\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0593 - accuracy: 0.9739 - val_loss: 3.4286 - val_accuracy: 0.6944\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0422 - accuracy: 0.9871 - val_loss: 3.3546 - val_accuracy: 0.6919\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0410 - accuracy: 0.9853 - val_loss: 3.3208 - val_accuracy: 0.6919\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0555 - accuracy: 0.9738 - val_loss: 3.3768 - val_accuracy: 0.6944\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0410 - accuracy: 0.9802 - val_loss: 3.3492 - val_accuracy: 0.6919\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0405 - accuracy: 0.9851 - val_loss: 3.4380 - val_accuracy: 0.6944\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0262 - accuracy: 0.9865 - val_loss: 3.6113 - val_accuracy: 0.6797\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0389 - accuracy: 0.9831 - val_loss: 3.6423 - val_accuracy: 0.6895\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0376 - accuracy: 0.9879 - val_loss: 3.7103 - val_accuracy: 0.6895\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0396 - accuracy: 0.9858 - val_loss: 3.4772 - val_accuracy: 0.6919\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 0.9881 - val_loss: 3.2682 - val_accuracy: 0.6724\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0361 - accuracy: 0.9850 - val_loss: 3.1758 - val_accuracy: 0.6773\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0551 - accuracy: 0.9791 - val_loss: 3.0019 - val_accuracy: 0.6822\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0387 - accuracy: 0.9818 - val_loss: 2.9716 - val_accuracy: 0.6993\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0280 - accuracy: 0.9883 - val_loss: 3.0389 - val_accuracy: 0.7066\n",
      "Epoch 629/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0470 - accuracy: 0.9821 - val_loss: 3.0510 - val_accuracy: 0.6870\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0370 - accuracy: 0.9839 - val_loss: 2.9964 - val_accuracy: 0.6846\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0356 - accuracy: 0.9869 - val_loss: 2.9093 - val_accuracy: 0.6846\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0427 - accuracy: 0.9827 - val_loss: 3.0051 - val_accuracy: 0.6822\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0451 - accuracy: 0.9811 - val_loss: 3.1523 - val_accuracy: 0.6797\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0419 - accuracy: 0.9841 - val_loss: 3.3788 - val_accuracy: 0.6968\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0269 - accuracy: 0.9869 - val_loss: 3.6119 - val_accuracy: 0.6944\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0399 - accuracy: 0.9830 - val_loss: 3.7920 - val_accuracy: 0.6919\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0366 - accuracy: 0.9840 - val_loss: 3.8723 - val_accuracy: 0.6895\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0519 - accuracy: 0.9809 - val_loss: 3.7707 - val_accuracy: 0.6797\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0375 - accuracy: 0.9844 - val_loss: 3.6296 - val_accuracy: 0.6650\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0504 - accuracy: 0.9829 - val_loss: 3.3441 - val_accuracy: 0.6675\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0569 - accuracy: 0.9751 - val_loss: 3.2396 - val_accuracy: 0.6846\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0404 - accuracy: 0.9866 - val_loss: 3.3469 - val_accuracy: 0.6773\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0332 - accuracy: 0.9910 - val_loss: 3.6170 - val_accuracy: 0.6993\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0389 - accuracy: 0.9840 - val_loss: 3.8924 - val_accuracy: 0.6968\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0399 - accuracy: 0.9853 - val_loss: 3.8363 - val_accuracy: 0.7017\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0564 - accuracy: 0.9739 - val_loss: 3.3519 - val_accuracy: 0.6993\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0430 - accuracy: 0.9823 - val_loss: 3.0114 - val_accuracy: 0.6895\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0601 - accuracy: 0.9846 - val_loss: 2.7702 - val_accuracy: 0.6919\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0504 - accuracy: 0.9808 - val_loss: 2.9187 - val_accuracy: 0.6895\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 95ms/step - loss: 0.0408 - accuracy: 0.9831 - val_loss: 3.1728 - val_accuracy: 0.6773\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0490 - accuracy: 0.9814 - val_loss: 3.1896 - val_accuracy: 0.6773\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0383 - accuracy: 0.9849 - val_loss: 3.3738 - val_accuracy: 0.6699\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0464 - accuracy: 0.9789 - val_loss: 3.4990 - val_accuracy: 0.6724\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0590 - accuracy: 0.9780 - val_loss: 3.4129 - val_accuracy: 0.6870\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0336 - accuracy: 0.9879 - val_loss: 3.3685 - val_accuracy: 0.6870\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0425 - accuracy: 0.9830 - val_loss: 3.2311 - val_accuracy: 0.6870\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0340 - accuracy: 0.9897 - val_loss: 3.1921 - val_accuracy: 0.6773\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0463 - accuracy: 0.9836 - val_loss: 3.2899 - val_accuracy: 0.6797\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0378 - accuracy: 0.9832 - val_loss: 3.7116 - val_accuracy: 0.6968\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0398 - accuracy: 0.9878 - val_loss: 4.1049 - val_accuracy: 0.6895\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0405 - accuracy: 0.9837 - val_loss: 3.9837 - val_accuracy: 0.6846\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0443 - accuracy: 0.9864 - val_loss: 3.5826 - val_accuracy: 0.6919\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0310 - accuracy: 0.9883 - val_loss: 3.4360 - val_accuracy: 0.6968\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0429 - accuracy: 0.9876 - val_loss: 3.4534 - val_accuracy: 0.6919\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0455 - accuracy: 0.9825 - val_loss: 3.5229 - val_accuracy: 0.6993\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0303 - accuracy: 0.9902 - val_loss: 3.5963 - val_accuracy: 0.6993\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0344 - accuracy: 0.9865 - val_loss: 3.7216 - val_accuracy: 0.6944\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0399 - accuracy: 0.9849 - val_loss: 3.7303 - val_accuracy: 0.6993\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0236 - accuracy: 0.9901 - val_loss: 3.6484 - val_accuracy: 0.6822\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0424 - accuracy: 0.9871 - val_loss: 3.6333 - val_accuracy: 0.6895\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0395 - accuracy: 0.9880 - val_loss: 3.6892 - val_accuracy: 0.6870\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0330 - accuracy: 0.9930 - val_loss: 3.7482 - val_accuracy: 0.6944\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0297 - accuracy: 0.9888 - val_loss: 3.6762 - val_accuracy: 0.6968\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0420 - accuracy: 0.9849 - val_loss: 3.5174 - val_accuracy: 0.7017\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0282 - accuracy: 0.9901 - val_loss: 3.3953 - val_accuracy: 0.6895\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0563 - accuracy: 0.9814 - val_loss: 3.1186 - val_accuracy: 0.6846\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0367 - accuracy: 0.9820 - val_loss: 3.0547 - val_accuracy: 0.6968\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0496 - accuracy: 0.9806 - val_loss: 3.0984 - val_accuracy: 0.7115\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0659 - accuracy: 0.9823 - val_loss: 2.9244 - val_accuracy: 0.7066\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0373 - accuracy: 0.9848 - val_loss: 2.5795 - val_accuracy: 0.7042\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0362 - accuracy: 0.9906 - val_loss: 2.4351 - val_accuracy: 0.6968\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0482 - accuracy: 0.9822 - val_loss: 2.4238 - val_accuracy: 0.6968\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0283 - accuracy: 0.9892 - val_loss: 2.5308 - val_accuracy: 0.6944\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0328 - accuracy: 0.9862 - val_loss: 2.6165 - val_accuracy: 0.7017\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.0369 - accuracy: 0.9818 - val_loss: 2.7171 - val_accuracy: 0.6944\n",
      "Epoch 686/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0346 - accuracy: 0.9863 - val_loss: 2.8211 - val_accuracy: 0.6968\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.0428 - accuracy: 0.9865 - val_loss: 2.7611 - val_accuracy: 0.6993\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0238 - accuracy: 0.9906 - val_loss: 2.8417 - val_accuracy: 0.6944\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0473 - accuracy: 0.9865 - val_loss: 2.9088 - val_accuracy: 0.6895\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0203 - accuracy: 0.9928 - val_loss: 3.0584 - val_accuracy: 0.6919\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.0288 - accuracy: 0.9878 - val_loss: 3.2663 - val_accuracy: 0.6944\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0398 - accuracy: 0.9853 - val_loss: 3.4359 - val_accuracy: 0.6895\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0354 - accuracy: 0.9873 - val_loss: 3.4718 - val_accuracy: 0.6919\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0206 - accuracy: 0.9935 - val_loss: 3.4878 - val_accuracy: 0.6919\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0172 - accuracy: 0.9957 - val_loss: 3.4617 - val_accuracy: 0.6993\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0378 - accuracy: 0.9857 - val_loss: 3.3459 - val_accuracy: 0.6895\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0270 - accuracy: 0.9902 - val_loss: 3.2972 - val_accuracy: 0.6968\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.0258 - accuracy: 0.9901 - val_loss: 3.2816 - val_accuracy: 0.6846\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 83ms/step - loss: 0.0428 - accuracy: 0.9878 - val_loss: 3.2151 - val_accuracy: 0.6822\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0346 - accuracy: 0.9859 - val_loss: 3.2691 - val_accuracy: 0.7017\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0307 - accuracy: 0.9892 - val_loss: 3.2882 - val_accuracy: 0.7188\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0329 - accuracy: 0.9906 - val_loss: 3.1711 - val_accuracy: 0.7115\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0308 - accuracy: 0.9896 - val_loss: 3.0724 - val_accuracy: 0.6993\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0296 - accuracy: 0.9909 - val_loss: 2.9915 - val_accuracy: 0.6895\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0278 - accuracy: 0.9924 - val_loss: 2.8466 - val_accuracy: 0.6919\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0231 - accuracy: 0.9912 - val_loss: 2.8258 - val_accuracy: 0.6870\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0236 - accuracy: 0.9932 - val_loss: 2.9336 - val_accuracy: 0.6919\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0242 - accuracy: 0.9921 - val_loss: 3.1753 - val_accuracy: 0.6993\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0221 - accuracy: 0.9918 - val_loss: 3.3967 - val_accuracy: 0.6919\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0332 - accuracy: 0.9850 - val_loss: 3.5894 - val_accuracy: 0.6993\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0295 - accuracy: 0.9912 - val_loss: 3.6917 - val_accuracy: 0.7066\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0311 - accuracy: 0.9902 - val_loss: 3.6966 - val_accuracy: 0.7017\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0308 - accuracy: 0.9866 - val_loss: 3.7161 - val_accuracy: 0.6919\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0256 - accuracy: 0.9875 - val_loss: 3.7869 - val_accuracy: 0.6944\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0337 - accuracy: 0.9831 - val_loss: 3.7856 - val_accuracy: 0.6968\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0237 - accuracy: 0.9907 - val_loss: 3.7690 - val_accuracy: 0.6968\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0200 - accuracy: 0.9929 - val_loss: 3.7266 - val_accuracy: 0.6968\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0199 - accuracy: 0.9920 - val_loss: 3.7413 - val_accuracy: 0.6944\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0241 - accuracy: 0.9912 - val_loss: 3.8099 - val_accuracy: 0.6919\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0254 - accuracy: 0.9905 - val_loss: 3.8978 - val_accuracy: 0.6895\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0232 - accuracy: 0.9914 - val_loss: 3.9881 - val_accuracy: 0.6870\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0315 - accuracy: 0.9921 - val_loss: 3.9301 - val_accuracy: 0.6895\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0296 - accuracy: 0.9886 - val_loss: 3.8601 - val_accuracy: 0.6944\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0280 - accuracy: 0.9915 - val_loss: 3.8379 - val_accuracy: 0.6895\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0212 - accuracy: 0.9949 - val_loss: 3.7847 - val_accuracy: 0.6870\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0334 - accuracy: 0.9888 - val_loss: 3.7581 - val_accuracy: 0.6870\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0221 - accuracy: 0.9935 - val_loss: 3.7724 - val_accuracy: 0.6944\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0420 - accuracy: 0.9910 - val_loss: 3.3113 - val_accuracy: 0.7017\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0305 - accuracy: 0.9901 - val_loss: 3.0279 - val_accuracy: 0.7042\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0478 - accuracy: 0.9880 - val_loss: 2.9238 - val_accuracy: 0.6773\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0297 - accuracy: 0.9876 - val_loss: 2.9456 - val_accuracy: 0.6870\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0292 - accuracy: 0.9903 - val_loss: 3.0499 - val_accuracy: 0.6895\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0369 - accuracy: 0.9835 - val_loss: 3.0911 - val_accuracy: 0.6846\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0354 - accuracy: 0.9850 - val_loss: 3.2015 - val_accuracy: 0.6846\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0269 - accuracy: 0.9907 - val_loss: 3.3971 - val_accuracy: 0.6797\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0260 - accuracy: 0.9923 - val_loss: 3.6332 - val_accuracy: 0.6773\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.0263 - accuracy: 0.9914 - val_loss: 3.7731 - val_accuracy: 0.6773\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0382 - accuracy: 0.9813 - val_loss: 3.8360 - val_accuracy: 0.6846\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0329 - accuracy: 0.9897 - val_loss: 3.9015 - val_accuracy: 0.6773\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0288 - accuracy: 0.9888 - val_loss: 3.9221 - val_accuracy: 0.6822\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0274 - accuracy: 0.9917 - val_loss: 3.9646 - val_accuracy: 0.6797\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0301 - accuracy: 0.9901 - val_loss: 4.0029 - val_accuracy: 0.6773\n",
      "Epoch 743/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0284 - accuracy: 0.9906 - val_loss: 4.0067 - val_accuracy: 0.6870\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0336 - accuracy: 0.9896 - val_loss: 3.9798 - val_accuracy: 0.6919\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0472 - accuracy: 0.9837 - val_loss: 3.6977 - val_accuracy: 0.6993\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0444 - accuracy: 0.9843 - val_loss: 3.5629 - val_accuracy: 0.6919\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0430 - accuracy: 0.9848 - val_loss: 3.4698 - val_accuracy: 0.7090\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0251 - accuracy: 0.9900 - val_loss: 3.4908 - val_accuracy: 0.7090\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0330 - accuracy: 0.9860 - val_loss: 3.4239 - val_accuracy: 0.7042\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0283 - accuracy: 0.9885 - val_loss: 3.1962 - val_accuracy: 0.7066\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0379 - accuracy: 0.9874 - val_loss: 3.0745 - val_accuracy: 0.6944\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0403 - accuracy: 0.9870 - val_loss: 2.9579 - val_accuracy: 0.6968\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0384 - accuracy: 0.9879 - val_loss: 2.9096 - val_accuracy: 0.6919\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0322 - accuracy: 0.9857 - val_loss: 2.8814 - val_accuracy: 0.6846\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0402 - accuracy: 0.9849 - val_loss: 2.9274 - val_accuracy: 0.6919\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0268 - accuracy: 0.9874 - val_loss: 2.9699 - val_accuracy: 0.6944\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0252 - accuracy: 0.9899 - val_loss: 3.1250 - val_accuracy: 0.7017\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0247 - accuracy: 0.9921 - val_loss: 3.2992 - val_accuracy: 0.6993\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0401 - accuracy: 0.9819 - val_loss: 3.3594 - val_accuracy: 0.7017\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0388 - accuracy: 0.9835 - val_loss: 3.2967 - val_accuracy: 0.6944\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0304 - accuracy: 0.9897 - val_loss: 3.1808 - val_accuracy: 0.6968\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0200 - accuracy: 0.9932 - val_loss: 3.1657 - val_accuracy: 0.6968\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 0.0256 - accuracy: 0.9905 - val_loss: 3.2725 - val_accuracy: 0.7017\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0309 - accuracy: 0.9888 - val_loss: 3.3631 - val_accuracy: 0.6895\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0447 - accuracy: 0.9819 - val_loss: 3.3245 - val_accuracy: 0.6895\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 3.3085 - val_accuracy: 0.6919\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0213 - accuracy: 0.9934 - val_loss: 3.3600 - val_accuracy: 0.6944\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0226 - accuracy: 0.9971 - val_loss: 3.4250 - val_accuracy: 0.6919\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0232 - accuracy: 0.9888 - val_loss: 3.4750 - val_accuracy: 0.6968\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0216 - accuracy: 0.9924 - val_loss: 3.5148 - val_accuracy: 0.6968\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0425 - accuracy: 0.9893 - val_loss: 3.4446 - val_accuracy: 0.6919\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0150 - accuracy: 0.9949 - val_loss: 3.4820 - val_accuracy: 0.6846\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0290 - accuracy: 0.9878 - val_loss: 3.3882 - val_accuracy: 0.6944\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0189 - accuracy: 0.9919 - val_loss: 3.3845 - val_accuracy: 0.6944\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0496 - accuracy: 0.9838 - val_loss: 3.3523 - val_accuracy: 0.6724\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0248 - accuracy: 0.9910 - val_loss: 3.1538 - val_accuracy: 0.6748\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0384 - accuracy: 0.9873 - val_loss: 2.7839 - val_accuracy: 0.6870\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0286 - accuracy: 0.9907 - val_loss: 2.7469 - val_accuracy: 0.6993\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0288 - accuracy: 0.9891 - val_loss: 2.7723 - val_accuracy: 0.7115\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0177 - accuracy: 0.9954 - val_loss: 2.8605 - val_accuracy: 0.6895\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0338 - accuracy: 0.9894 - val_loss: 2.8877 - val_accuracy: 0.7042\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0364 - accuracy: 0.9882 - val_loss: 2.8498 - val_accuracy: 0.7115\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0272 - accuracy: 0.9905 - val_loss: 2.8028 - val_accuracy: 0.6895\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0191 - accuracy: 0.9950 - val_loss: 2.9007 - val_accuracy: 0.6822\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0422 - accuracy: 0.9819 - val_loss: 2.9567 - val_accuracy: 0.6724\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0296 - accuracy: 0.9900 - val_loss: 3.0652 - val_accuracy: 0.6993\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0578 - accuracy: 0.9747 - val_loss: 3.0760 - val_accuracy: 0.7139\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0286 - accuracy: 0.9883 - val_loss: 3.1836 - val_accuracy: 0.6993\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0353 - accuracy: 0.9883 - val_loss: 3.1926 - val_accuracy: 0.6919\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0535 - accuracy: 0.9845 - val_loss: 3.0019 - val_accuracy: 0.6846\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0363 - accuracy: 0.9862 - val_loss: 2.7039 - val_accuracy: 0.7017\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 0.9871 - val_loss: 2.4784 - val_accuracy: 0.6993\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0242 - accuracy: 0.9952 - val_loss: 2.5839 - val_accuracy: 0.7042\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0304 - accuracy: 0.9878 - val_loss: 2.8272 - val_accuracy: 0.6993\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0302 - accuracy: 0.9871 - val_loss: 3.0902 - val_accuracy: 0.7042\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0216 - accuracy: 0.9916 - val_loss: 3.2475 - val_accuracy: 0.6919\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0353 - accuracy: 0.9858 - val_loss: 3.1806 - val_accuracy: 0.6944\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0293 - accuracy: 0.9919 - val_loss: 3.0453 - val_accuracy: 0.6895\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.0300 - accuracy: 0.9853 - val_loss: 3.0451 - val_accuracy: 0.6968\n",
      "Epoch 800/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 37ms/step - loss: 0.0369 - accuracy: 0.9896 - val_loss: 3.0227 - val_accuracy: 0.7042\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0338 - accuracy: 0.9895 - val_loss: 3.1323 - val_accuracy: 0.6944\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0278 - accuracy: 0.9902 - val_loss: 3.1473 - val_accuracy: 0.6968\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0361 - accuracy: 0.9854 - val_loss: 3.0772 - val_accuracy: 0.7066\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0237 - accuracy: 0.9902 - val_loss: 3.1098 - val_accuracy: 0.7066\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0194 - accuracy: 0.9939 - val_loss: 3.0762 - val_accuracy: 0.7042\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0252 - accuracy: 0.9888 - val_loss: 2.9191 - val_accuracy: 0.7066\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0366 - accuracy: 0.9873 - val_loss: 3.0331 - val_accuracy: 0.6919\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0446 - accuracy: 0.9805 - val_loss: 3.0623 - val_accuracy: 0.7042\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0299 - accuracy: 0.9915 - val_loss: 3.2287 - val_accuracy: 0.7066\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0235 - accuracy: 0.9885 - val_loss: 3.3394 - val_accuracy: 0.6919\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0245 - accuracy: 0.9893 - val_loss: 3.4743 - val_accuracy: 0.6822\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.0416 - accuracy: 0.9844 - val_loss: 3.5538 - val_accuracy: 0.6968\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0293 - accuracy: 0.9915 - val_loss: 3.4405 - val_accuracy: 0.6968\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0337 - accuracy: 0.9896 - val_loss: 3.3576 - val_accuracy: 0.6650\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0209 - accuracy: 0.9967 - val_loss: 3.2690 - val_accuracy: 0.6675\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0403 - accuracy: 0.9874 - val_loss: 2.9284 - val_accuracy: 0.6846\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0380 - accuracy: 0.9852 - val_loss: 2.8204 - val_accuracy: 0.6968\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0309 - accuracy: 0.9887 - val_loss: 2.9051 - val_accuracy: 0.6944\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0386 - accuracy: 0.9875 - val_loss: 2.9265 - val_accuracy: 0.6797\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0191 - accuracy: 0.9914 - val_loss: 2.9904 - val_accuracy: 0.6846\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0307 - accuracy: 0.9906 - val_loss: 2.9579 - val_accuracy: 0.6797\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0332 - accuracy: 0.9906 - val_loss: 2.9596 - val_accuracy: 0.6822\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0176 - accuracy: 0.9922 - val_loss: 3.0670 - val_accuracy: 0.6944\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0243 - accuracy: 0.9933 - val_loss: 3.1521 - val_accuracy: 0.6968\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0222 - accuracy: 0.9922 - val_loss: 3.2747 - val_accuracy: 0.7042\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0144 - accuracy: 0.9960 - val_loss: 3.3933 - val_accuracy: 0.7066\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0171 - accuracy: 0.9938 - val_loss: 3.5344 - val_accuracy: 0.7017\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0148 - accuracy: 0.9961 - val_loss: 3.6783 - val_accuracy: 0.6919\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0234 - accuracy: 0.9931 - val_loss: 3.9092 - val_accuracy: 0.6944\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0437 - accuracy: 0.9848 - val_loss: 3.6930 - val_accuracy: 0.6895\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0346 - accuracy: 0.9888 - val_loss: 3.3077 - val_accuracy: 0.6748\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0235 - accuracy: 0.9943 - val_loss: 2.8119 - val_accuracy: 0.6993\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0305 - accuracy: 0.9872 - val_loss: 2.4367 - val_accuracy: 0.7017\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - ETA: 0s - loss: 0.0493 - accuracy: 0.97 - 0s 22ms/step - loss: 0.0416 - accuracy: 0.9820 - val_loss: 2.2064 - val_accuracy: 0.6968\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0376 - accuracy: 0.9860 - val_loss: 2.1747 - val_accuracy: 0.6870\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0429 - accuracy: 0.9891 - val_loss: 2.2084 - val_accuracy: 0.6846\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0317 - accuracy: 0.9879 - val_loss: 2.2602 - val_accuracy: 0.6846\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0325 - accuracy: 0.9894 - val_loss: 2.4439 - val_accuracy: 0.7017\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0328 - accuracy: 0.9873 - val_loss: 2.6610 - val_accuracy: 0.6919\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0316 - accuracy: 0.9883 - val_loss: 2.8044 - val_accuracy: 0.6968\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0280 - accuracy: 0.9918 - val_loss: 3.0656 - val_accuracy: 0.6870\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 80ms/step - loss: 0.0318 - accuracy: 0.9889 - val_loss: 3.2546 - val_accuracy: 0.6895\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0246 - accuracy: 0.9928 - val_loss: 3.3140 - val_accuracy: 0.6993\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0481 - accuracy: 0.9848 - val_loss: 3.2031 - val_accuracy: 0.6993\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0388 - accuracy: 0.9866 - val_loss: 3.1876 - val_accuracy: 0.6968\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0236 - accuracy: 0.9906 - val_loss: 3.1623 - val_accuracy: 0.6919\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0183 - accuracy: 0.9919 - val_loss: 3.1733 - val_accuracy: 0.6944\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0178 - accuracy: 0.9919 - val_loss: 3.3853 - val_accuracy: 0.6748\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0321 - accuracy: 0.9873 - val_loss: 3.4037 - val_accuracy: 0.6748\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0368 - accuracy: 0.9845 - val_loss: 3.2035 - val_accuracy: 0.6846\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0148 - accuracy: 0.9955 - val_loss: 3.1585 - val_accuracy: 0.6822\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0197 - accuracy: 0.9932 - val_loss: 3.1148 - val_accuracy: 0.6870\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0232 - accuracy: 0.9901 - val_loss: 3.0099 - val_accuracy: 0.6797\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0238 - accuracy: 0.9918 - val_loss: 3.0922 - val_accuracy: 0.6724\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0244 - accuracy: 0.9922 - val_loss: 3.1885 - val_accuracy: 0.6870\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0258 - accuracy: 0.9872 - val_loss: 3.3230 - val_accuracy: 0.6919\n",
      "Epoch 857/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0266 - accuracy: 0.9895 - val_loss: 3.3431 - val_accuracy: 0.7066\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0272 - accuracy: 0.9923 - val_loss: 3.1488 - val_accuracy: 0.6944\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0224 - accuracy: 0.9889 - val_loss: 3.0326 - val_accuracy: 0.6919\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0167 - accuracy: 0.9942 - val_loss: 2.9887 - val_accuracy: 0.6919\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0323 - accuracy: 0.9866 - val_loss: 2.9828 - val_accuracy: 0.6846\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0203 - accuracy: 0.9941 - val_loss: 2.9460 - val_accuracy: 0.6748\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0240 - accuracy: 0.9893 - val_loss: 3.0274 - val_accuracy: 0.6870\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0208 - accuracy: 0.9919 - val_loss: 3.0757 - val_accuracy: 0.6993\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0253 - accuracy: 0.9920 - val_loss: 3.0694 - val_accuracy: 0.6846\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0249 - accuracy: 0.9932 - val_loss: 3.1533 - val_accuracy: 0.6870\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0222 - accuracy: 0.9951 - val_loss: 3.1923 - val_accuracy: 0.6870\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0245 - accuracy: 0.9923 - val_loss: 3.1716 - val_accuracy: 0.6919\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0138 - accuracy: 0.9967 - val_loss: 3.2898 - val_accuracy: 0.7042\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0386 - accuracy: 0.9865 - val_loss: 3.1898 - val_accuracy: 0.7042\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0197 - accuracy: 0.9916 - val_loss: 3.1162 - val_accuracy: 0.6944\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0175 - accuracy: 0.9946 - val_loss: 3.1466 - val_accuracy: 0.6919\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 0.9950 - val_loss: 3.1900 - val_accuracy: 0.6993\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0172 - accuracy: 0.9960 - val_loss: 3.2287 - val_accuracy: 0.6944\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0218 - accuracy: 0.9937 - val_loss: 3.2580 - val_accuracy: 0.6968\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0261 - accuracy: 0.9946 - val_loss: 3.1974 - val_accuracy: 0.6968\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 3.1803 - val_accuracy: 0.6944\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0179 - accuracy: 0.9933 - val_loss: 3.1992 - val_accuracy: 0.6944\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0225 - accuracy: 0.9914 - val_loss: 3.2639 - val_accuracy: 0.7017\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0177 - accuracy: 0.9919 - val_loss: 3.4125 - val_accuracy: 0.6895\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0147 - accuracy: 0.9940 - val_loss: 3.5512 - val_accuracy: 0.6919\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0173 - accuracy: 0.9948 - val_loss: 3.6081 - val_accuracy: 0.7017\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0130 - accuracy: 0.9940 - val_loss: 3.6222 - val_accuracy: 0.6993\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0298 - accuracy: 0.9892 - val_loss: 3.4739 - val_accuracy: 0.7017\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0223 - accuracy: 0.9914 - val_loss: 3.3340 - val_accuracy: 0.6895\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0296 - accuracy: 0.9910 - val_loss: 3.1204 - val_accuracy: 0.6870\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0226 - accuracy: 0.9911 - val_loss: 2.8959 - val_accuracy: 0.7066\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0205 - accuracy: 0.9914 - val_loss: 2.8836 - val_accuracy: 0.6944\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0252 - accuracy: 0.9898 - val_loss: 2.8936 - val_accuracy: 0.7042\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0255 - accuracy: 0.9909 - val_loss: 2.8403 - val_accuracy: 0.6968\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0236 - accuracy: 0.9906 - val_loss: 2.7338 - val_accuracy: 0.7066\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0234 - accuracy: 0.9903 - val_loss: 2.6625 - val_accuracy: 0.7066\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0428 - accuracy: 0.9880 - val_loss: 2.4440 - val_accuracy: 0.7042\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0197 - accuracy: 0.9929 - val_loss: 2.4744 - val_accuracy: 0.6993\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0240 - accuracy: 0.9899 - val_loss: 2.5846 - val_accuracy: 0.6895\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0230 - accuracy: 0.9924 - val_loss: 2.7406 - val_accuracy: 0.6968\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0183 - accuracy: 0.9919 - val_loss: 2.9517 - val_accuracy: 0.6919\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0295 - accuracy: 0.9867 - val_loss: 3.0396 - val_accuracy: 0.6870\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0336 - accuracy: 0.9919 - val_loss: 2.9683 - val_accuracy: 0.6895\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0194 - accuracy: 0.9926 - val_loss: 2.9989 - val_accuracy: 0.6895\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0240 - accuracy: 0.9913 - val_loss: 3.0946 - val_accuracy: 0.6870\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.0306 - accuracy: 0.9890 - val_loss: 3.1057 - val_accuracy: 0.6944\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0263 - accuracy: 0.9919 - val_loss: 3.1084 - val_accuracy: 0.7017\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0216 - accuracy: 0.9896 - val_loss: 2.9997 - val_accuracy: 0.6993\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0191 - accuracy: 0.9941 - val_loss: 2.9801 - val_accuracy: 0.7066\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0169 - accuracy: 0.9910 - val_loss: 3.0176 - val_accuracy: 0.7042\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0196 - accuracy: 0.9924 - val_loss: 3.0492 - val_accuracy: 0.7066\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0242 - accuracy: 0.9929 - val_loss: 3.1177 - val_accuracy: 0.7042\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0174 - accuracy: 0.9930 - val_loss: 3.2768 - val_accuracy: 0.6968\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0222 - accuracy: 0.9928 - val_loss: 3.4007 - val_accuracy: 0.6895\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0248 - accuracy: 0.9906 - val_loss: 3.4770 - val_accuracy: 0.6993\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0152 - accuracy: 0.9954 - val_loss: 3.6212 - val_accuracy: 0.6968\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0254 - accuracy: 0.9928 - val_loss: 3.7516 - val_accuracy: 0.7090\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0117 - accuracy: 0.9962 - val_loss: 3.8503 - val_accuracy: 0.7066\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0163 - accuracy: 0.9943 - val_loss: 3.8191 - val_accuracy: 0.7066\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0224 - accuracy: 0.9929 - val_loss: 3.6624 - val_accuracy: 0.6968\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0282 - accuracy: 0.9904 - val_loss: 3.5586 - val_accuracy: 0.6870\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0246 - accuracy: 0.9892 - val_loss: 3.4924 - val_accuracy: 0.6870\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0159 - accuracy: 0.9935 - val_loss: 3.4073 - val_accuracy: 0.7066\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0314 - accuracy: 0.9896 - val_loss: 3.3863 - val_accuracy: 0.7066\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.0221 - accuracy: 0.9945 - val_loss: 3.3181 - val_accuracy: 0.6895\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0219 - accuracy: 0.9950 - val_loss: 3.3176 - val_accuracy: 0.6895\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0122 - accuracy: 0.9949 - val_loss: 3.3406 - val_accuracy: 0.6822\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0213 - accuracy: 0.9909 - val_loss: 3.2479 - val_accuracy: 0.6944\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.0234 - accuracy: 0.9929 - val_loss: 3.1735 - val_accuracy: 0.7090\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0226 - accuracy: 0.9947 - val_loss: 3.2418 - val_accuracy: 0.6944\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0281 - accuracy: 0.9906 - val_loss: 3.2247 - val_accuracy: 0.7017\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0213 - accuracy: 0.9936 - val_loss: 3.0869 - val_accuracy: 0.7042\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0254 - accuracy: 0.9889 - val_loss: 3.0792 - val_accuracy: 0.7042\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0111 - accuracy: 0.9950 - val_loss: 3.2093 - val_accuracy: 0.6724\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0303 - accuracy: 0.9881 - val_loss: 2.9707 - val_accuracy: 0.6846\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0250 - accuracy: 0.9892 - val_loss: 2.9605 - val_accuracy: 0.6870\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0174 - accuracy: 0.9919 - val_loss: 3.0293 - val_accuracy: 0.6968\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0279 - accuracy: 0.9879 - val_loss: 3.0931 - val_accuracy: 0.6968\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0134 - accuracy: 0.9948 - val_loss: 3.2112 - val_accuracy: 0.6993\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0215 - accuracy: 0.9923 - val_loss: 3.3541 - val_accuracy: 0.6919\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0167 - accuracy: 0.9953 - val_loss: 3.4387 - val_accuracy: 0.6919\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0206 - accuracy: 0.9906 - val_loss: 3.4681 - val_accuracy: 0.7017\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0215 - accuracy: 0.9884 - val_loss: 3.5598 - val_accuracy: 0.7042\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.0341 - accuracy: 0.9849 - val_loss: 3.6421 - val_accuracy: 0.6895\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0152 - accuracy: 0.9936 - val_loss: 3.7733 - val_accuracy: 0.6773\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0245 - accuracy: 0.9890 - val_loss: 3.7001 - val_accuracy: 0.6870\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0227 - accuracy: 0.9909 - val_loss: 3.6122 - val_accuracy: 0.6968\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0182 - accuracy: 0.9922 - val_loss: 3.5753 - val_accuracy: 0.6968\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0298 - accuracy: 0.9897 - val_loss: 3.4620 - val_accuracy: 0.7066\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0155 - accuracy: 0.9945 - val_loss: 3.4032 - val_accuracy: 0.6993\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0157 - accuracy: 0.9949 - val_loss: 3.4634 - val_accuracy: 0.7017\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0225 - accuracy: 0.9927 - val_loss: 3.4545 - val_accuracy: 0.6968\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0243 - accuracy: 0.9919 - val_loss: 3.4115 - val_accuracy: 0.6968\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0184 - accuracy: 0.9948 - val_loss: 3.4082 - val_accuracy: 0.6944\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0250 - accuracy: 0.9918 - val_loss: 3.3606 - val_accuracy: 0.6968\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 81ms/step - loss: 0.0191 - accuracy: 0.9935 - val_loss: 3.3752 - val_accuracy: 0.6797\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0155 - accuracy: 0.9949 - val_loss: 3.5079 - val_accuracy: 0.6797\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0266 - accuracy: 0.9917 - val_loss: 3.4979 - val_accuracy: 0.6797\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0122 - accuracy: 0.9932 - val_loss: 3.4898 - val_accuracy: 0.6944\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0212 - accuracy: 0.9900 - val_loss: 3.5557 - val_accuracy: 0.6895\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0187 - accuracy: 0.9909 - val_loss: 3.6297 - val_accuracy: 0.6846\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0164 - accuracy: 0.9939 - val_loss: 3.6146 - val_accuracy: 0.6895\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0202 - accuracy: 0.9904 - val_loss: 3.5085 - val_accuracy: 0.7017\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0110 - accuracy: 0.9958 - val_loss: 3.4515 - val_accuracy: 0.7042\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0166 - accuracy: 0.9937 - val_loss: 3.4504 - val_accuracy: 0.6944\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0169 - accuracy: 0.9891 - val_loss: 3.4931 - val_accuracy: 0.6944\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0108 - accuracy: 0.9960 - val_loss: 3.5689 - val_accuracy: 0.6822\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0252 - accuracy: 0.9932 - val_loss: 3.5587 - val_accuracy: 0.6870\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0293 - accuracy: 0.9909 - val_loss: 3.5751 - val_accuracy: 0.6895\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0262 - accuracy: 0.9896 - val_loss: 3.6104 - val_accuracy: 0.7090\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0411 - accuracy: 0.9892 - val_loss: 2.9506 - val_accuracy: 0.6870\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0269 - accuracy: 0.9914 - val_loss: 2.9416 - val_accuracy: 0.6773\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0246 - accuracy: 0.9919 - val_loss: 2.7356 - val_accuracy: 0.6748\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0365 - accuracy: 0.9840 - val_loss: 2.4901 - val_accuracy: 0.6895\n",
      "Epoch 971/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0233 - accuracy: 0.9894 - val_loss: 2.5717 - val_accuracy: 0.6968\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0165 - accuracy: 0.9947 - val_loss: 2.7021 - val_accuracy: 0.6968\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0241 - accuracy: 0.9922 - val_loss: 2.8278 - val_accuracy: 0.6919\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0143 - accuracy: 0.9970 - val_loss: 3.0837 - val_accuracy: 0.6895\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0304 - accuracy: 0.9902 - val_loss: 3.0600 - val_accuracy: 0.6944\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0182 - accuracy: 0.9907 - val_loss: 3.1097 - val_accuracy: 0.7042\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0162 - accuracy: 0.9920 - val_loss: 3.2788 - val_accuracy: 0.6944\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0247 - accuracy: 0.9906 - val_loss: 3.3112 - val_accuracy: 0.6968\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0153 - accuracy: 0.9929 - val_loss: 3.3824 - val_accuracy: 0.6919\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0305 - accuracy: 0.9931 - val_loss: 3.2649 - val_accuracy: 0.6968\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0112 - accuracy: 0.9963 - val_loss: 3.1636 - val_accuracy: 0.6870\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0196 - accuracy: 0.9931 - val_loss: 3.1521 - val_accuracy: 0.6822\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0325 - accuracy: 0.9878 - val_loss: 2.9439 - val_accuracy: 0.6846\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0216 - accuracy: 0.9897 - val_loss: 2.7692 - val_accuracy: 0.6870\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0191 - accuracy: 0.9925 - val_loss: 2.7275 - val_accuracy: 0.6919\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0144 - accuracy: 0.9942 - val_loss: 2.7755 - val_accuracy: 0.6919\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0309 - accuracy: 0.9892 - val_loss: 2.8911 - val_accuracy: 0.6870\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0137 - accuracy: 0.9955 - val_loss: 3.1233 - val_accuracy: 0.6822\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0276 - accuracy: 0.9869 - val_loss: 3.3750 - val_accuracy: 0.6748\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0132 - accuracy: 0.9958 - val_loss: 3.5252 - val_accuracy: 0.6675\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.0229 - accuracy: 0.9939 - val_loss: 3.3732 - val_accuracy: 0.6846\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0259 - accuracy: 0.9917 - val_loss: 3.0432 - val_accuracy: 0.6944\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.0455 - accuracy: 0.9889 - val_loss: 2.6814 - val_accuracy: 0.6968\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.0275 - accuracy: 0.9923 - val_loss: 2.4543 - val_accuracy: 0.6895\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0244 - accuracy: 0.9892 - val_loss: 2.5165 - val_accuracy: 0.6822\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0211 - accuracy: 0.9924 - val_loss: 2.6753 - val_accuracy: 0.6895\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0195 - accuracy: 0.9955 - val_loss: 2.9434 - val_accuracy: 0.6846\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0177 - accuracy: 0.9919 - val_loss: 3.2667 - val_accuracy: 0.6797\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.0203 - accuracy: 0.9926 - val_loss: 3.4806 - val_accuracy: 0.6822\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.0164 - accuracy: 0.9945 - val_loss: 3.6759 - val_accuracy: 0.6797\n",
      "Runtime of the program is 56.60707879066467\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'hidden_layers': 4, 'learning_rate': 0.1}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6585266351699829\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time.time()\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "# program body ends\n",
    "bestNN=create_modelWithDropBatch(hidden_layers= 2, learning_rate= 0.05)\n",
    "history1000 = bestNN.fit(\n",
    "     xtrain_tfidf_ngram, y_train,\n",
    "    validation_data=(xvalid_tfidf_ngram,y_cv),\n",
    "    batch_size=512,\n",
    "    epochs=1000,\n",
    "#     callbacks=[early_stopping],\n",
    ")\n",
    "\n",
    "# end time\n",
    "end = time.time()\n",
    "\n",
    "# total time taken\n",
    "print(f\"Runtime of the program is {end - start}\")\n",
    "history_Batch_drop_relu.best_params_\n",
    "\n",
    "print(history_Batch_drop_relu.best_score_)\n",
    "# print(grid.best_params_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "history1000DF = pd.DataFrame(history1000.history)\n",
    "history1000DF.to_csv(\"BackProphistory1000epochs_df.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Score: 67.97066014669927 %\n",
      "precision_score: 55.2 %\n",
      "recall_score: 47.91666666666667 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy_Score: 82.72208638956805 %\n",
      "Training Recall: 81.03448275862068 %\n",
      "Training precision_score: 75.2 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training F1 Score: 78.00829875518671 %\n"
     ]
    }
   ],
   "source": [
    "# y_pred_SVM = gridNN_Batch_drop_relu.predict(xvalid_tfidf_ngram)\n",
    "\n",
    "# conf_mat_svm = metrics.confusion_matrix(y_cv['label'], y_pred_SVM)\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.heatmap(conf_mat_svm,annot=True)\n",
    "# plt.title(\"Confusion_matrix\")\n",
    "# plt.xlabel(\"Predicted Class\")\n",
    "# plt.ylabel(\"Actual class\")\n",
    "# plt.show()\n",
    "# print('Confusion matrix: \\n', conf_mat_svm)\n",
    "# print('TP: ', conf_mat_svm[1,1])\n",
    "# print('TN: ', conf_mat_svm[0,0])\n",
    "# print('FP: ', conf_mat_svm[0,1])\n",
    "# print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "\n",
    "# # print('Confusion matrix: \\n', cm)\n",
    "# print('TP: ', conf_mat_svm[1,1])\n",
    "# print('TN: ', conf_mat_svm[0,0])\n",
    "# print('FP: ', conf_mat_svm[0,1])\n",
    "# print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_test, model))\n",
    "print('Accuracy_Score:',metrics.accuracy_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "\n",
    "print('precision_score:',metrics.precision_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, gridNN_Batch_drop_relu.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Cross-entropy'}>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history1000DF.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "3/3 [==============================] - 1s 102ms/step - loss: 0.7247 - accuracy: 0.5224 - val_loss: 0.6937 - val_accuracy: 0.6479\n",
      "Epoch 2/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6416 - accuracy: 0.6241 - val_loss: 0.6442 - val_accuracy: 0.6479\n",
      "Epoch 3/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6279 - accuracy: 0.6229 - val_loss: 0.6091 - val_accuracy: 0.6479\n",
      "Epoch 4/200\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6144 - accuracy: 0.6191 - val_loss: 0.6360 - val_accuracy: 0.6333\n",
      "Epoch 5/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6163 - accuracy: 0.6214 - val_loss: 0.6355 - val_accuracy: 0.6455\n",
      "Epoch 6/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.6109 - accuracy: 0.6241 - val_loss: 0.6210 - val_accuracy: 0.6479\n",
      "Epoch 7/200\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.5973 - accuracy: 0.6131 - val_loss: 0.6092 - val_accuracy: 0.6479\n",
      "Epoch 8/200\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 0.5866 - accuracy: 0.6347 - val_loss: 0.6048 - val_accuracy: 0.6479\n",
      "Epoch 9/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5815 - accuracy: 0.6381 - val_loss: 0.6041 - val_accuracy: 0.6479\n",
      "Epoch 10/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5731 - accuracy: 0.6281 - val_loss: 0.6018 - val_accuracy: 0.6724\n",
      "Epoch 11/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5692 - accuracy: 0.6527 - val_loss: 0.5944 - val_accuracy: 0.6797\n",
      "Epoch 12/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5441 - accuracy: 0.6847 - val_loss: 0.6125 - val_accuracy: 0.6553\n",
      "Epoch 13/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5464 - accuracy: 0.6768 - val_loss: 0.7061 - val_accuracy: 0.6479\n",
      "Epoch 14/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5286 - accuracy: 0.6869 - val_loss: 0.7407 - val_accuracy: 0.6479\n",
      "Epoch 15/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5514 - accuracy: 0.6793 - val_loss: 0.6744 - val_accuracy: 0.6479\n",
      "Epoch 16/200\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 0.5285 - accuracy: 0.6961 - val_loss: 0.7389 - val_accuracy: 0.6479\n"
     ]
    }
   ],
   "source": [
    "early_stopping = keras.callbacks.EarlyStopping(\n",
    "    patience=5,\n",
    "    min_delta=0.0001,\n",
    "    restore_best_weights=True,\n",
    ")\n",
    "# modelwithDropout = keras.Sequential([\n",
    "#     layers.Dense(256, activation='relu', input_shape=input_shape),\n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.5),\n",
    "    \n",
    "#     layers.Dense(256, activation='relu'),    \n",
    "#     layers.BatchNormalization(),\n",
    "#     layers.Dropout(0.5),\n",
    "    \n",
    "#     layers.Dense(1, activation='sigmoid'),\n",
    "# ])\n",
    "\n",
    "# modelwithDropout.compile(\n",
    "#     optimizer='adam',\n",
    "#     loss='binary_crossentropy',\n",
    "#     metrics=['binary_accuracy'],\n",
    "# )\n",
    "\n",
    "bestNNearly=create_modelWithDropBatch(hidden_layers= 2, learning_rate= 0.05)\n",
    "history3 = bestNNearly.fit(\n",
    "     xtrain_tfidf_ngram, y_train,\n",
    "    validation_data=(xvalid_tfidf_ngram,y_cv),\n",
    "    batch_size=512,\n",
    "    epochs=200,\n",
    "    callbacks=[early_stopping],\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Cross-entropy'}>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Accuracy'}>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history3.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Cross-entropy'}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'Accuracy'}>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "history_df = pd.DataFrame(history3.history)\n",
    "history_df.loc[:, ['loss', 'val_loss']].plot(title=\"Cross-entropy\")\n",
    "history_df.loc[:, ['accuracy', 'val_accuracy']].plot(title=\"Accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41353747],\n",
       "       [0.34362417],\n",
       "       [0.47660562],\n",
       "       [0.22995162],\n",
       "       [0.21296689],\n",
       "       [0.19385788],\n",
       "       [0.41663736],\n",
       "       [0.1985963 ],\n",
       "       [0.48841858],\n",
       "       [0.48649865],\n",
       "       [0.41757494],\n",
       "       [0.31103337],\n",
       "       [0.4303911 ],\n",
       "       [0.16950324],\n",
       "       [0.27224004],\n",
       "       [0.398345  ],\n",
       "       [0.48848602],\n",
       "       [0.46686375],\n",
       "       [0.39566785],\n",
       "       [0.5757847 ],\n",
       "       [0.14449161],\n",
       "       [0.49948817],\n",
       "       [0.4891785 ],\n",
       "       [0.4936868 ],\n",
       "       [0.53590775],\n",
       "       [0.21124128],\n",
       "       [0.1921106 ],\n",
       "       [0.17537072],\n",
       "       [0.5335649 ],\n",
       "       [0.08613992],\n",
       "       [0.04206991],\n",
       "       [0.2673775 ],\n",
       "       [0.27738547],\n",
       "       [0.40787625],\n",
       "       [0.46325195],\n",
       "       [0.53123486],\n",
       "       [0.14152682],\n",
       "       [0.27931678],\n",
       "       [0.10808516],\n",
       "       [0.29324764],\n",
       "       [0.48032802],\n",
       "       [0.4943213 ],\n",
       "       [0.40526938],\n",
       "       [0.47522414],\n",
       "       [0.46262732],\n",
       "       [0.4327659 ],\n",
       "       [0.44762442],\n",
       "       [0.17616242],\n",
       "       [0.47245842],\n",
       "       [0.3796617 ],\n",
       "       [0.16268387],\n",
       "       [0.44833258],\n",
       "       [0.38794833],\n",
       "       [0.37343192],\n",
       "       [0.04476321],\n",
       "       [0.4601348 ],\n",
       "       [0.29844046],\n",
       "       [0.41134685],\n",
       "       [0.04079956],\n",
       "       [0.3688619 ],\n",
       "       [0.4525144 ],\n",
       "       [0.5581228 ],\n",
       "       [0.2867049 ],\n",
       "       [0.49756366],\n",
       "       [0.42931393],\n",
       "       [0.4080593 ],\n",
       "       [0.4879845 ],\n",
       "       [0.4167746 ],\n",
       "       [0.2450197 ],\n",
       "       [0.4322464 ],\n",
       "       [0.48325244],\n",
       "       [0.20992437],\n",
       "       [0.16801956],\n",
       "       [0.1682789 ],\n",
       "       [0.583986  ],\n",
       "       [0.41397113],\n",
       "       [0.12327781],\n",
       "       [0.3627739 ],\n",
       "       [0.51063055],\n",
       "       [0.47773996],\n",
       "       [0.48024482],\n",
       "       [0.46620348],\n",
       "       [0.46717   ],\n",
       "       [0.40190023],\n",
       "       [0.44455218],\n",
       "       [0.41732052],\n",
       "       [0.484732  ],\n",
       "       [0.25328797],\n",
       "       [0.43032822],\n",
       "       [0.5027647 ],\n",
       "       [0.4011334 ],\n",
       "       [0.3516387 ],\n",
       "       [0.4295265 ],\n",
       "       [0.32993525],\n",
       "       [0.44847694],\n",
       "       [0.3605407 ],\n",
       "       [0.49304807],\n",
       "       [0.40061405],\n",
       "       [0.47611699],\n",
       "       [0.3169117 ],\n",
       "       [0.3997905 ],\n",
       "       [0.49237657],\n",
       "       [0.41210186],\n",
       "       [0.42877704],\n",
       "       [0.4655524 ],\n",
       "       [0.1756092 ],\n",
       "       [0.4327584 ],\n",
       "       [0.29452527],\n",
       "       [0.3704722 ],\n",
       "       [0.37087235],\n",
       "       [0.3142953 ],\n",
       "       [0.4814239 ],\n",
       "       [0.3885914 ],\n",
       "       [0.3008865 ],\n",
       "       [0.21017033],\n",
       "       [0.35914153],\n",
       "       [0.32944027],\n",
       "       [0.35652217],\n",
       "       [0.18061045],\n",
       "       [0.39113384],\n",
       "       [0.26725775],\n",
       "       [0.24196887],\n",
       "       [0.14429131],\n",
       "       [0.46267557],\n",
       "       [0.40344495],\n",
       "       [0.35451156],\n",
       "       [0.31291306],\n",
       "       [0.44587642],\n",
       "       [0.31061673],\n",
       "       [0.38442725],\n",
       "       [0.55156994],\n",
       "       [0.18947405],\n",
       "       [0.24690872],\n",
       "       [0.43065724],\n",
       "       [0.44586825],\n",
       "       [0.39613402],\n",
       "       [0.4876988 ],\n",
       "       [0.40205395],\n",
       "       [0.47116175],\n",
       "       [0.487669  ],\n",
       "       [0.3197726 ],\n",
       "       [0.3984104 ],\n",
       "       [0.25237763],\n",
       "       [0.38477114],\n",
       "       [0.47763333],\n",
       "       [0.3716609 ],\n",
       "       [0.06488165],\n",
       "       [0.48033997],\n",
       "       [0.2579133 ],\n",
       "       [0.5043563 ],\n",
       "       [0.44509214],\n",
       "       [0.26765725],\n",
       "       [0.4260171 ],\n",
       "       [0.2812955 ],\n",
       "       [0.50374794],\n",
       "       [0.28257763],\n",
       "       [0.13624293],\n",
       "       [0.42849204],\n",
       "       [0.31779313],\n",
       "       [0.4797491 ],\n",
       "       [0.4876271 ],\n",
       "       [0.4309919 ],\n",
       "       [0.39615571],\n",
       "       [0.41290307],\n",
       "       [0.4560113 ],\n",
       "       [0.3470867 ],\n",
       "       [0.4450013 ],\n",
       "       [0.4936418 ],\n",
       "       [0.03898194],\n",
       "       [0.17532447],\n",
       "       [0.24940863],\n",
       "       [0.40195048],\n",
       "       [0.45974132],\n",
       "       [0.35002047],\n",
       "       [0.40911192],\n",
       "       [0.4939961 ],\n",
       "       [0.4772862 ],\n",
       "       [0.20437342],\n",
       "       [0.15742972],\n",
       "       [0.4340366 ],\n",
       "       [0.2647038 ],\n",
       "       [0.28131098],\n",
       "       [0.43507195],\n",
       "       [0.3751572 ],\n",
       "       [0.04247895],\n",
       "       [0.3502059 ],\n",
       "       [0.25447237],\n",
       "       [0.49076924],\n",
       "       [0.17910177],\n",
       "       [0.47448242],\n",
       "       [0.36382216],\n",
       "       [0.33476683],\n",
       "       [0.42980018],\n",
       "       [0.44889966],\n",
       "       [0.35055435],\n",
       "       [0.44045213],\n",
       "       [0.2667942 ],\n",
       "       [0.442937  ],\n",
       "       [0.378908  ],\n",
       "       [0.3776732 ],\n",
       "       [0.48473674],\n",
       "       [0.47815138],\n",
       "       [0.53038955],\n",
       "       [0.36453086],\n",
       "       [0.08633301],\n",
       "       [0.23008981],\n",
       "       [0.2694678 ],\n",
       "       [0.29706708],\n",
       "       [0.2987398 ],\n",
       "       [0.33446276],\n",
       "       [0.4306091 ],\n",
       "       [0.48080257],\n",
       "       [0.37993944],\n",
       "       [0.20415401],\n",
       "       [0.28200018],\n",
       "       [0.41774535],\n",
       "       [0.18469977],\n",
       "       [0.03270596],\n",
       "       [0.18386331],\n",
       "       [0.33977535],\n",
       "       [0.34488386],\n",
       "       [0.4034986 ],\n",
       "       [0.04126063],\n",
       "       [0.49095735],\n",
       "       [0.38085026],\n",
       "       [0.41453636],\n",
       "       [0.43392825],\n",
       "       [0.45223826],\n",
       "       [0.4814115 ],\n",
       "       [0.40205395],\n",
       "       [0.35089314],\n",
       "       [0.42605194],\n",
       "       [0.46776295],\n",
       "       [0.43613645],\n",
       "       [0.43617374],\n",
       "       [0.15239245],\n",
       "       [0.40478978],\n",
       "       [0.2183013 ],\n",
       "       [0.52663726],\n",
       "       [0.26436156],\n",
       "       [0.43891248],\n",
       "       [0.37939292],\n",
       "       [0.32037532],\n",
       "       [0.46847078],\n",
       "       [0.5056146 ],\n",
       "       [0.39432782],\n",
       "       [0.21816266],\n",
       "       [0.46830896],\n",
       "       [0.47409183],\n",
       "       [0.36122355],\n",
       "       [0.43299916],\n",
       "       [0.3361564 ],\n",
       "       [0.08359611],\n",
       "       [0.49664682],\n",
       "       [0.5372196 ],\n",
       "       [0.43191722],\n",
       "       [0.08375546],\n",
       "       [0.08719799],\n",
       "       [0.45745894],\n",
       "       [0.37523043],\n",
       "       [0.31151247],\n",
       "       [0.39281178],\n",
       "       [0.45585474],\n",
       "       [0.5517563 ],\n",
       "       [0.46875298],\n",
       "       [0.25511748],\n",
       "       [0.17440724],\n",
       "       [0.38335517],\n",
       "       [0.34853962],\n",
       "       [0.1772134 ],\n",
       "       [0.5244595 ],\n",
       "       [0.35652217],\n",
       "       [0.43338785],\n",
       "       [0.21188274],\n",
       "       [0.26237863],\n",
       "       [0.48172843],\n",
       "       [0.41609982],\n",
       "       [0.25183547],\n",
       "       [0.42662266],\n",
       "       [0.28451425],\n",
       "       [0.27041095],\n",
       "       [0.2700001 ],\n",
       "       [0.4776864 ],\n",
       "       [0.45740283],\n",
       "       [0.4659186 ],\n",
       "       [0.36135328],\n",
       "       [0.393722  ],\n",
       "       [0.51500016],\n",
       "       [0.3474692 ],\n",
       "       [0.4806223 ],\n",
       "       [0.436618  ],\n",
       "       [0.47960794],\n",
       "       [0.37209153],\n",
       "       [0.43527445],\n",
       "       [0.4408623 ],\n",
       "       [0.29266816],\n",
       "       [0.4987074 ],\n",
       "       [0.4825882 ],\n",
       "       [0.43778074],\n",
       "       [0.07122484],\n",
       "       [0.47661853],\n",
       "       [0.28616035],\n",
       "       [0.3869941 ],\n",
       "       [0.20385018],\n",
       "       [0.39430654],\n",
       "       [0.32770246],\n",
       "       [0.24579835],\n",
       "       [0.46490884],\n",
       "       [0.32237947],\n",
       "       [0.44541448],\n",
       "       [0.4880406 ],\n",
       "       [0.16728318],\n",
       "       [0.40930405],\n",
       "       [0.34746316],\n",
       "       [0.52059066],\n",
       "       [0.18978232],\n",
       "       [0.34651986],\n",
       "       [0.39178452],\n",
       "       [0.30771995],\n",
       "       [0.4217085 ],\n",
       "       [0.4556937 ],\n",
       "       [0.25216794],\n",
       "       [0.4718988 ],\n",
       "       [0.30667827],\n",
       "       [0.48977387],\n",
       "       [0.38711604],\n",
       "       [0.33056617],\n",
       "       [0.4757999 ],\n",
       "       [0.4065597 ],\n",
       "       [0.31252578],\n",
       "       [0.44701514],\n",
       "       [0.35089314],\n",
       "       [0.16936302],\n",
       "       [0.42894754],\n",
       "       [0.43262854],\n",
       "       [0.49050483],\n",
       "       [0.25071505],\n",
       "       [0.49239576],\n",
       "       [0.43552   ],\n",
       "       [0.38162765],\n",
       "       [0.46311256],\n",
       "       [0.54149806],\n",
       "       [0.22880575],\n",
       "       [0.26704705],\n",
       "       [0.3163212 ],\n",
       "       [0.52059066],\n",
       "       [0.4094923 ],\n",
       "       [0.10527283],\n",
       "       [0.36872065],\n",
       "       [0.33382875],\n",
       "       [0.48093867],\n",
       "       [0.40857577],\n",
       "       [0.3224597 ],\n",
       "       [0.47327778],\n",
       "       [0.47218472],\n",
       "       [0.24256769],\n",
       "       [0.2802742 ],\n",
       "       [0.30172223],\n",
       "       [0.27426815],\n",
       "       [0.48841742],\n",
       "       [0.3297863 ],\n",
       "       [0.36671323],\n",
       "       [0.04435429],\n",
       "       [0.40685514],\n",
       "       [0.52059066],\n",
       "       [0.3475842 ],\n",
       "       [0.3905917 ],\n",
       "       [0.4343709 ],\n",
       "       [0.331685  ],\n",
       "       [0.3859594 ],\n",
       "       [0.35698193],\n",
       "       [0.03916717],\n",
       "       [0.21818316],\n",
       "       [0.5378758 ],\n",
       "       [0.40975887],\n",
       "       [0.49007213],\n",
       "       [0.3761919 ],\n",
       "       [0.35207492],\n",
       "       [0.41467255],\n",
       "       [0.47473592],\n",
       "       [0.415416  ],\n",
       "       [0.29706395],\n",
       "       [0.45668325],\n",
       "       [0.43265212],\n",
       "       [0.33253738],\n",
       "       [0.16386569],\n",
       "       [0.3194198 ],\n",
       "       [0.45532128],\n",
       "       [0.37343192],\n",
       "       [0.40510592],\n",
       "       [0.4322425 ],\n",
       "       [0.36377102],\n",
       "       [0.34871292],\n",
       "       [0.23431492],\n",
       "       [0.4367892 ],\n",
       "       [0.46872687],\n",
       "       [0.31843078],\n",
       "       [0.40048206],\n",
       "       [0.46865872],\n",
       "       [0.48535952],\n",
       "       [0.33796245],\n",
       "       [0.46565896],\n",
       "       [0.4601348 ],\n",
       "       [0.4644357 ],\n",
       "       [0.24613208],\n",
       "       [0.33056617],\n",
       "       [0.42880753],\n",
       "       [0.38576925],\n",
       "       [0.44320363]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred_SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows  1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     label\n",
       "0        0\n",
       "1        1\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "..     ...\n",
       "404      0\n",
       "405      0\n",
       "406      0\n",
       "407      0\n",
       "408      1\n",
       "\n",
       "[409 rows x 1 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.5327334e-04],\n",
       "       [9.1738880e-01],\n",
       "       [9.9999923e-01],\n",
       "       ...,\n",
       "       [1.5739978e-08],\n",
       "       [8.8838277e-08],\n",
       "       [9.9999601e-01]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestNN.predict(xtrain_tfidf_ngram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy_Score: 67.97066014669927 %\n",
      "precision_score: 76.0 %\n",
      "recall_score: 13.194444444444445 %\n",
      "Training Accuracy_Score: 64.54767726161369 %\n",
      "Training Recall: 10.991379310344827 %\n",
      "Training precision_score: 69.86301369863014 %\n",
      "Training F1 Score: 18.994413407821227 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    }
   ],
   "source": [
    "y_pred_SVM = bestNNearly.predict_classes(xvalid_tfidf_ngram)\n",
    "\n",
    "# conf_mat_svm = metrics.confusion_matrix(y_cv['label'], y_pred_SVM)\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.heatmap(conf_mat_svm,annot=True)\n",
    "# plt.title(\"Confusion_matrix\")\n",
    "# plt.xlabel(\"Predicted Class\")\n",
    "# plt.ylabel(\"Actual class\")\n",
    "# plt.show()\n",
    "# print('Confusion matrix: \\n', conf_mat_svm)\n",
    "# print('TP: ', conf_mat_svm[1,1])\n",
    "# print('TN: ', conf_mat_svm[0,0])\n",
    "# print('FP: ', conf_mat_svm[0,1])\n",
    "# print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_test, model))\n",
    "print('Accuracy_Score:',metrics.accuracy_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "\n",
    "print('precision_score:',metrics.precision_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv['label'], y_pred_SVM)*100,'%')\n",
    "\n",
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, bestNNearly.predict_classes(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, bestNNearly.predict_classes(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, bestNNearly.predict_classes(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, bestNNearly.predict_classes(xtrain_tfidf_ngram))*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=pd.read_csv(\"TEXT_X_test.csv\")\n",
    "\n",
    "# x_cv=pd.read_csv(\"TEXT_X_V.csv\")\n",
    "# y_cv=pd.read_csv(\"TEXTlabel_V.csv\")\n",
    "# y_train=pd.read_csv(\"TEXTlabel_train.csv\")\n",
    "y_test =pd.read_csv(\"TEXTlabel_test .csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest_tfidf_ngram=np.load(\"xtest_tfidf_ngram.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>404</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>405</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>407</th>\n",
       "      <td>407</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>408</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>409 rows  2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  label\n",
       "0             0      1\n",
       "1             1      0\n",
       "2             2      1\n",
       "3             3      0\n",
       "4             4      0\n",
       "..          ...    ...\n",
       "404         404      0\n",
       "405         405      0\n",
       "406         406      0\n",
       "407         407      0\n",
       "408         408      0\n",
       "\n",
       "[409 rows x 2 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n",
      "/home/dheekshitha-vibha/miniconda3/envs/myenv/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing Accuracy_Score: 62.8361858190709 %\n",
      "testing Recall: 5.47945205479452 %\n",
      "testing precision_score: 36.36363636363637 %\n",
      "testing F1 Score: 9.523809523809524 %\n"
     ]
    }
   ],
   "source": [
    "print('testing Accuracy_Score:',metrics.accuracy_score(y_test['label'], bestNNearly.predict_classes(xtest_tfidf_ngram))*100,'%')\n",
    "print('testing Recall:',metrics.recall_score(y_test['label'], bestNNearly.predict_classes(xtest_tfidf_ngram))*100,'%')\n",
    "print('testing precision_score:',metrics.precision_score(y_test['label'], bestNNearly.predict_classes(xtest_tfidf_ngram))*100,'%')\n",
    "print('testing F1 Score:',metrics.f1_score(y_test['label'], bestNNearly.predict_classes(xtest_tfidf_ngram))*100,'%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(ahfhfkj)\n",
    "# y_train_res=y_train_res_01.map({ 1:'Existing Customer',  0:'Attrited Customer'})\n",
    "\n",
    "parameter_xgb= [0.3,0.4,0.5,0.6,0.7,0.8]\n",
    "\n",
    "from sklearn.model_selection import validation_curve\n",
    "#https://www.scikit-yb.org/en/latest/api/model_selection/validation_curve.html\n",
    "training_scores,testing_scores = validation_curve(\n",
    "   xgb.XGBClassifier(learning_rate=0.1, n_estimators=50,booster='dart',\n",
    "#                              subsample= 1.0,\n",
    "              max_depth= 3, gamma= 0.5, \n",
    "#                      colsample_bytree= 1.0,\n",
    "                            \n",
    "                            nthread=1, use_label_encoder=False, eval_metric=[\"error\", \"logloss\"]), xtrain_tfidf_ngram, y_train['label'],\n",
    "    param_range=parameter_xgb,  scoring=\"precision\",param_name=\"subsample\",cv=5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_scores_mean = np.mean(training_scores, axis=1)\n",
    "train_scores_std = np.std(training_scores, axis=1)\n",
    "test_scores_mean = np.mean(testing_scores, axis=1)\n",
    "test_scores_std = np.std(testing_scores, axis=1)\n",
    "param_range=parameter_xgb\n",
    "plt.title(\"Validation Curve with XGB\")\n",
    "plt.xlabel(\"subsample\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "# lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.model_selection import learning_curve\n",
    "\n",
    "sizes, training_scores, testing_scores = learning_curve(SVC(C=10,gamma=0.1,kernel='rbf'),xtrain_tfidf_ngram, y_train['label'])\n",
    "\n",
    "# Mean and Standard Deviation of training scores \n",
    "mean_training = np.mean(training_scores, axis=1) \n",
    "Standard_Deviation_training = np.std(training_scores, axis=1) \n",
    "  \n",
    "# Mean and Standard Deviation of testing scores \n",
    "mean_testing = np.mean(testing_scores, axis=1) \n",
    "Standard_Deviation_testing = np.std(testing_scores, axis=1) \n",
    "  \n",
    "# dotted blue line is for training scores and green line is for cross-validation score \n",
    "plt.plot(sizes, mean_training, '--', color=\"b\",  label=\"Training score\") \n",
    "plt.plot(sizes, mean_testing, color=\"g\", label=\"Cross-validation score\") \n",
    "  \n",
    "# Drawing plot \n",
    "plt.title(\"LEARNING CURVE FOR SVM Classifier\") \n",
    "plt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\") \n",
    "plt.tight_layout() \n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In contrast, for small amounts of data, the training score of the SVM is much greater than the validation score. Adding more training samples will most likely increase generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    C: Inverse of the strength of regularization.\n",
    "\n",
    "Behavior: As the value of c increases the model gets overfits.\n",
    "\n",
    "As the value of c decreases the model underfits.\n",
    "\n",
    "2.  : Gamma (used only for RBF kernel)\n",
    "\n",
    "Behavior: As the value of   increases the model gets overfits.\n",
    "\n",
    "As the value of   decreases the model underfits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n",
    "              'kernel': ['rbf','linear','poly']}  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.0001,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_scores_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The gamma parameter is not large but still the model is still overfitting. Hence we are going to tune C parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_svm = np.arange(0.0001,0.1,0.01)\n",
    "from sklearn.model_selection import validation_curve\n",
    "#https://www.scikit-yb.org/en/latest/api/model_selection/validation_curve.html\n",
    "training_scores,testing_scores = validation_curve(\n",
    "    SVC(gamma=0.1,kernel='rbf'), xtrain_tfidf_ngram, y_train['label'],\n",
    "    param_range=parameter_svm,  scoring=\"accuracy\",param_name=\"C\",cv=5\n",
    ")\n",
    "\n",
    "\n",
    "train_scores_mean = np.mean(training_scores, axis=1)\n",
    "train_scores_std = np.std(training_scores, axis=1)\n",
    "test_scores_mean = np.mean(testing_scores, axis=1)\n",
    "test_scores_std = np.std(testing_scores, axis=1)\n",
    "param_range=parameter_svm\n",
    "plt.title(\"Validation Curve with SVM varying C\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "parameter_svm = np.arange(0.0001,0.1,0.01)\n",
    "from sklearn.model_selection import validation_curve\n",
    "#https://www.scikit-yb.org/en/latest/api/model_selection/validation_curve.html\n",
    "training_scores,testing_scores = validation_curve(\n",
    "    SVC(gamma=0.1,kernel='rbf'), xtrain_tfidf_ngram, y_train['label'],\n",
    "    param_range=parameter_svm,  scoring=\"precision\",param_name=\"C\",cv=5\n",
    ")\n",
    "\n",
    "\n",
    "train_scores_mean = np.mean(training_scores, axis=1)\n",
    "train_scores_std = np.std(training_scores, axis=1)\n",
    "test_scores_mean = np.mean(testing_scores, axis=1)\n",
    "test_scores_std = np.std(testing_scores, axis=1)\n",
    "param_range=parameter_svm\n",
    "plt.title(\"Validation Curve with SVM varying C\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is underfitting when the C value is reduced and overfitting when the values are not too high. From learning curve and validation curve results, it is clear that adding more data can only help increase the performance of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    " np.arange(0.001,0.1,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_svm = np.arange(0.001,0.1,0.01)\n",
    "from sklearn.model_selection import validation_curve\n",
    "#https://www.scikit-yb.org/en/latest/api/model_selection/validation_curve.html\n",
    "training_scores,testing_scores = validation_curve(\n",
    "    SVC(gamma=0.1,kernel='rbf'), xtrain_tfidf_ngram, y_train['label'],\n",
    "    param_range=parameter_svm,  scoring=\"accuracy\",param_name=\"C\",cv=5\n",
    ")\n",
    "\n",
    "\n",
    "train_scores_mean = np.mean(training_scores, axis=1)\n",
    "train_scores_std = np.std(training_scores, axis=1)\n",
    "test_scores_mean = np.mean(testing_scores, axis=1)\n",
    "test_scores_std = np.std(testing_scores, axis=1)\n",
    "param_range=parameter_svm\n",
    "plt.title(\"Validation Curve with SVM varying C\")\n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "gridKNN= {\n",
    "    'n_neighbors':list(range(1,10,2)),\n",
    "    'weights':['uniform','distance'],\n",
    "    'metric':['euclidean','manhattan']\n",
    "}\n",
    "\n",
    "knn = GridSearchCV(\n",
    "KNeighborsClassifier(),\n",
    "gridKNN,\n",
    "verbose=1,\n",
    "cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn.fit(xtrain_tfidf_ngram, y_train['label']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "joblib.dump(knn, 'KNN_gridsearch_NLP.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knnModel=knn\n",
    "knnModel.best_params_\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train_res=y_train_res_01.map({ 1:'Existing Customer',  0:'Attrited Customer'})\n",
    "\n",
    "parameter_knn= [3,4,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "from sklearn.model_selection import validation_curve\n",
    "#https://www.scikit-yb.org/en/latest/api/model_selection/validation_curve.html\n",
    "training_scores,testing_scores = validation_curve(\n",
    "    KNeighborsClassifier(metric= 'manhattan',weights= 'distance'), xtrain_tfidf_ngram, y_train['label'],\n",
    "    param_range=parameter_knn,  scoring=\"precision\",param_name=\"n_neighbors\",cv=5\n",
    ")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scores_mean = np.mean(training_scores, axis=1)\n",
    "train_scores_std = np.std(training_scores, axis=1)\n",
    "test_scores_mean = np.mean(testing_scores, axis=1)\n",
    "test_scores_std = np.std(testing_scores, axis=1)\n",
    "param_range= [3,4,7,8,9,10,11,12,13,14,15,16,17,18,19]\n",
    "plt.title(\"Validation Curve with KNN\")\n",
    "plt.xlabel(\"K\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "# lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_predictions1 = knnModel.best_estimator_.predict(xvalid_tfidf_ngram)\n",
    "# knn_predictions1 = np.round(knn_predictions1)\n",
    "print('knnoost Test Set')\n",
    "print('Accuracy: %.2f' % ((knn_predictions1 == y_cv['label']).mean()*100))\n",
    "\n",
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, knnModel.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, knnModel.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, knnModel.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, knnModel.best_estimator_.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "\n",
    "\n",
    "# # print('Confusion matrix: \\n', cm)\n",
    "# print('TP: ', conf_mat_svm[1,1])\n",
    "# print('TN: ', conf_mat_svm[0,0])\n",
    "# print('FP: ', conf_mat_svm[0,1])\n",
    "# print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_cv['label'], model))\n",
    "print('Accuracy_Score:',metrics.accuracy_score(y_cv['label'], knn_predictions1)*100,'%')\n",
    "\n",
    "\n",
    "print('precision_score:',metrics.precision_score(y_cv['label'], knn_predictions1,)*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv['label'], knn_predictions1)*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the graph, it is evident that the model performs the best at K=3. However, we notice that training and precision is 99 whereas validation precision is 76. This is clear case of overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# gridKNN= {\n",
    "#     'n_neighbors':list(range(1,10,2)),\n",
    "#     'weights':['uniform','distance'],\n",
    "#     'metric':['euclidean','manhattan']\n",
    "# }\n",
    "\n",
    "knn7 = KNeighborsClassifier(\n",
    "n_neighbors=7,\n",
    "    metric='euclidean', weights= 'distance')\n",
    "\n",
    "# knn = KNeighborsClassifier(n_neighbors=2)\n",
    "knn7.fit(xtrain_tfidf_ngram, y_train['label']) \n",
    "\n",
    "\n",
    "\n",
    "joblib.dump(knn7, 'KNN_gridsearch_NLP_K7.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn_predictions7 = knn7.predict(xvalid_tfidf_ngram)\n",
    "# knn_predictions1 = np.round(knn_predictions1)\n",
    "print('knnoost Test Set')\n",
    "print('Accuracy: %.2f' % ((knn_predictions1 == y_cv['label']).mean()*100))\n",
    "\n",
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, knn7.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, knn7.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, knn7.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, knn7.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "\n",
    "\n",
    "# # print('Confusion matrix: \\n', cm)\n",
    "# print('TP: ', conf_mat_svm[1,1])\n",
    "# print('TN: ', conf_mat_svm[0,0])\n",
    "# print('FP: ', conf_mat_svm[0,1])\n",
    "# print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_cv['label'], model))\n",
    "print('Accuracy_Score:',metrics.accuracy_score(y_cv['label'], knn_predictions7)*100,'%')\n",
    "\n",
    "\n",
    "print('precision_score:',metrics.precision_score(y_cv['label'], knn_predictions7,)*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv['label'], knn_predictions7)*100,'%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Gradient Boosting "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [5, 6, 7, 8],\n",
    "        }\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(learning_rate=0.3, n_estimators=600, objective='binary:logistic',\n",
    "                            nthread=1, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state = 25)\n",
    "\n",
    "search = RandomizedSearchCV(xgb_clf, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(x_train, y_train), random_state=25)\n",
    "\n",
    "search.fit(xtrain_tfidf_ngram, y_train)\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "print(search.best_params_)\n",
    "\n",
    "joblib.dump(xgb_clf, 'xgb_gridsearchNLP.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "params = {\n",
    "        'min_child_weight': 1,\n",
    "        'gamma': 2,\n",
    "        'subsample': 1, #prevents overfitting\n",
    "        'colsample_bytree': 0.8,\n",
    "        'max_depth': 8,\n",
    "        }\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(learning_rate=0.3, n_estimators=600, objective='binary:logistic',\n",
    "                            \n",
    "                            nthread=1, use_label_encoder=False, eval_metric=[\"error\", \"logloss\"])\n",
    "\n",
    "xgb_clf.fit(xtrain_tfidf_ngram, y_train,eval_set = [(xtrain_tfidf_ngram, y_train), (xvalid_tfidf_ngram, y_cv)])\n",
    "# print('Best hyperparameters:')\n",
    "# print(search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # print('Confusion matrix: \\n', cm)\n",
    "# print('TP: ', conf_mat_svm[1,1])\n",
    "# print('TN: ', conf_mat_svm[0,0])\n",
    "# print('FP: ', conf_mat_svm[0,1])\n",
    "# print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_test, model))\n",
    "xgb_predictions = xgb_clf.predict(xvalid_tfidf_ngram)\n",
    "xgb_predictions = np.round(xgb_predictions)\n",
    "print('Accuracy_Score:',metrics.accuracy_score(y_cv, xgb_predictions)*100,'%')\n",
    "\n",
    "\n",
    "print('precision_score:',metrics.precision_score(y_cv, xgb_predictions)*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv, xgb_predictions)*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print('XGBoost Test Set')\n",
    "print('Accuracy: %.2f' % ((xgb_predictions == y_cv['label']).mean()*100))\n",
    "\n",
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, xgb_clf.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, xgb_clf.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, xgb_clf.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, xgb_clf.predict(xtrain_tfidf_ngram))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_cv, xgb_predictions)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "fprTrain, tprTrain, thresholdTrain = metrics.roc_curve(y_train, xgb_clf.predict(xtrain_tfidf_ngram))\n",
    "roc_aucTrain = metrics.auc(fprTrain, tprTrain)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Test AUC = %0.2f' % roc_auc,color=\"orange\")\n",
    "# plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.plot(fprTrain, tprTrain, 'b', label = 'AUC Train = %0.2f' % roc_aucTrain)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# # method II: ggplot\n",
    "# from ggplot import *\n",
    "# df = pd.DataFrame(dict(fpr = fpr, tpr = tpr))\n",
    "# ggplot(df, aes(x = 'fpr', y = 'tpr')) + geom_line() + geom_abline(linetype = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBOOST\n",
    "\n",
    "import xgboost as xgb\n",
    "\n",
    "\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [5, 6, 7, 8],\n",
    "    'n_estimators' : range(50, 400, 50)\n",
    "        }\n",
    "\n",
    "xgb_clf3 = xgb.XGBClassifier(learning_rate=0.3,  objective='binary:logistic',\n",
    "                            nthread=1, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "\n",
    "\n",
    "folds = 3\n",
    "param_comb = 5\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle=True, random_state = 25)\n",
    "\n",
    "search2 = RandomizedSearchCV(xgb_clf3, param_distributions=params, n_iter=param_comb, scoring='precision', n_jobs=4, cv=skf.split(x_train, y_train), random_state=25)\n",
    "\n",
    "search2.fit(xtrain_tfidf_ngram, y_train)\n",
    "\n",
    "print('Best hyperparameters:')\n",
    "print(search2.best_params_)\n",
    "\n",
    "joblib.dump(xgb_clf3, 'xgb_gridsearchNLP_Precision_estimators.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf3.get_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://stats.stackexchange.com/questions/443259/how-to-avoid-overfitting-in-xgboost-model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params={'subsample'= 1.0, 'n_estimators'= 50, 'min_child_weight'= 1, 'max_depth'= 5, 'gamma'= 0.5, 'colsample_bytree'= 1.0}\n",
    "\n",
    "xgb_clf4 = xgb.XGBClassifier(learning_rate=0.3, \n",
    "                             subsample= 1.0, n_estimators= 50, min_child_weight= 1, max_depth= 5, gamma= 0.5, colsample_bytree= 1.0,\n",
    "                            \n",
    "                            nthread=1, use_label_encoder=False, eval_metric=[\"error\", \"logloss\"])\n",
    "\n",
    "xgb_clf4.fit(xtrain_tfidf_ngram, y_train,eval_set = [(xtrain_tfidf_ngram, y_train), (xvalid_tfidf_ngram, y_cv)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # print('Confusion matrix: \\n', cm)\n",
    "# print('TP: ', conf_mat_svm[1,1])\n",
    "# print('TN: ', conf_mat_svm[0,0])\n",
    "# print('FP: ', conf_mat_svm[0,1])\n",
    "# print('FN: ', conf_mat_svm[1,0])\n",
    "\n",
    "# print('Classification report: \\n', metrics.classification_report(y_test, model))\n",
    "xgb_predictions4 = xgb_clf4.predict(xvalid_tfidf_ngram)\n",
    "xgb_predictions4 = np.round(xgb_predictions4)\n",
    "print('Accuracy_Score:',metrics.accuracy_score(y_cv, xgb_predictions4)*100,'%')\n",
    "\n",
    "\n",
    "print('precision_score:',metrics.precision_score(y_cv, xgb_predictions4)*100,'%')\n",
    "\n",
    "print('recall_score:',metrics.recall_score(y_cv, xgb_predictions4)*100,'%')\n",
    "\n",
    "xgb_predictions4 = xgb_clf4.predict(xvalid_tfidf_ngram)\n",
    "xgb_predictions4 = np.round(xgb_predictions4)\n",
    "print('XGBoost Test Set')\n",
    "print('Accuracy: %.2f' % ((xgb_predictions4 == y_cv['label']).mean()*100))\n",
    "\n",
    "print('Training Accuracy_Score:',metrics.accuracy_score(y_train, xgb_clf4.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training Recall:',metrics.recall_score(y_train, xgb_clf4.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training precision_score:',metrics.precision_score(y_train, xgb_clf4.predict(xtrain_tfidf_ngram))*100,'%')\n",
    "print('Training F1 Score:',metrics.f1_score(y_train, xgb_clf4.predict(xtrain_tfidf_ngram))*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, threshold = metrics.roc_curve(y_cv, xgb_predictions4)\n",
    "roc_auc = metrics.auc(fpr, tpr)\n",
    "fprTrain, tprTrain, thresholdTrain = metrics.roc_curve(y_train, xgb_clf4.predict(xtrain_tfidf_ngram))\n",
    "roc_aucTrain = metrics.auc(fprTrain, tprTrain)\n",
    "\n",
    "# method I: plt\n",
    "import matplotlib.pyplot as plt\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(fpr, tpr, 'b', label = 'Test AUC = %0.2f' % roc_auc,color=\"orange\")\n",
    "# plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.plot(fprTrain, tprTrain, 'b', label = 'AUC Train = %0.2f' % roc_aucTrain)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.show()\n",
    "\n",
    "# # method II: ggplot\n",
    "# from ggplot import *\n",
    "# df = pd.DataFrame(dict(fpr = fpr, tpr = tpr))\n",
    "# ggplot(df, aes(x = 'fpr', y = 'tpr')) + geom_line() + geom_abline(linetype = 'dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_clf.get_params"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tuning parameter learning_rate and max_depth as the model is overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(0.1, 0.4, 0.1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# y_train_res=y_train_res_01.map({ 1:'Existing Customer',  0:'Attrited Customer'})\n",
    "\n",
    "parameter_xgb=  range(50, 400, 50)\n",
    "from sklearn.model_selection import validation_curve\n",
    "#https://www.scikit-yb.org/en/latest/api/model_selection/validation_curve.html\n",
    "training_scores,testing_scores = validation_curve(\n",
    "   xgb.XGBClassifier(learning_rate=0.1, \n",
    "                             subsample= 1.0,  min_child_weight= 1, max_depth= 5, gamma= 0.5, colsample_bytree= 1.0,\n",
    "                            \n",
    "                            nthread=1, use_label_encoder=False, eval_metric=[\"error\", \"logloss\"]), xtrain_tfidf_ngram, y_train['label'],\n",
    "    param_range=parameter_xgb,  scoring=\"precision\",param_name=\"n_estimators\",cv=5\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_scores_mean = np.mean(training_scores, axis=1)\n",
    "train_scores_std = np.std(training_scores, axis=1)\n",
    "test_scores_mean = np.mean(testing_scores, axis=1)\n",
    "test_scores_std = np.std(testing_scores, axis=1)\n",
    "param_range= range(50, 400, 50)\n",
    "plt.title(\"Validation Curve with XGB\")\n",
    "plt.xlabel(\"n_estimators\")\n",
    "plt.ylabel(\"Score\")\n",
    "plt.ylim(0.0, 1.1)\n",
    "# lw = 2\n",
    "plt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n",
    "             color=\"darkorange\", lw=lw)\n",
    "plt.fill_between(param_range, train_scores_mean - train_scores_std,\n",
    "                 train_scores_mean + train_scores_std, alpha=0.2,\n",
    "                 color=\"darkorange\", lw=lw)\n",
    "plt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n",
    "             color=\"navy\", lw=lw)\n",
    "plt.fill_between(param_range, test_scores_mean - test_scores_std,\n",
    "                 test_scores_mean + test_scores_std, alpha=0.2,\n",
    "                 color=\"navy\", lw=lw)\n",
    "plt.legend(loc=\"best\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
